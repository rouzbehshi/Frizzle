{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "import numpy as np\n",
    "\n",
    "from DataProcessing import DataProcessingPipeline\n",
    "from DataCleaning import DataCleaningPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:51:23.377152Z",
     "start_time": "2024-09-02T12:51:23.335821Z"
    }
   },
   "id": "da14b0d9c7e0c811"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# DataCleaningPipeline Parameters\n",
    "path = ('data/data.csv')\n",
    "\n",
    "# DataProcessingPipeline Parameters\n",
    "variable = 'wind_speed'\n",
    "latitude = 40.5112  # Latitude of the specific location\n",
    "longitude = 16.3723  # Longitude of the specific location"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:48:37.959085Z",
     "start_time": "2024-09-02T12:48:37.948295Z"
    }
   },
   "id": "ceb0d6db09fe3a61"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Data Cleaning Pipeline\n",
    "pipeline_cleaning = DataCleaningPipeline(path)\n",
    "df = pipeline_cleaning.run_pipeline()\n",
    "\n",
    "# Data Processing Pipeline\n",
    "pipeline_processing = DataProcessingPipeline(df, variable, latitude, longitude)\n",
    "X_train, y_train, X_test, y_test = pipeline_processing.run_pipeline()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:48:41.128661Z",
     "start_time": "2024-09-02T12:48:40.064307Z"
    }
   },
   "id": "45629d413b306349"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 365  # Number of samples in each training window\n",
    "step_size = 180  # Number of samples to move the window by each iteration\n",
    "\n",
    "# Total number of windows\n",
    "total_windows = (len(X_train) - window_size) // step_size + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T16:19:29.183580Z",
     "start_time": "2024-07-06T16:19:29.169383Z"
    }
   },
   "id": "3c9d47988722fb74"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(60, activation=LeakyReLU(), input_shape=(input_shape,),\n",
    "              kernel_regularizer=l2(0.01)),\n",
    "        Dense(24)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='mae')\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T16:19:29.766828Z",
     "start_time": "2024-07-06T16:19:29.753060Z"
    }
   },
   "id": "5c1ed716c0a0c9bf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0783 - val_loss: 3.3931\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 1.9064 - val_loss: 2.1615\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 1.3995 - val_loss: 1.4695\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 1.1803 - val_loss: 1.1658\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 1.1007 - val_loss: 1.2273\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 1.0682 - val_loss: 1.2121\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 739us/step - loss: 1.0263 - val_loss: 1.0908\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 1.0235 - val_loss: 1.1842\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 714us/step - loss: 1.0065 - val_loss: 1.0649\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.9711 - val_loss: 1.0731\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.9482 - val_loss: 1.0388\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.9375 - val_loss: 1.0904\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.9297 - val_loss: 0.9918\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.9026 - val_loss: 1.0547\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.9060 - val_loss: 1.0501\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.8878 - val_loss: 1.0120\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 707us/step - loss: 0.8704 - val_loss: 1.0345\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.8499 - val_loss: 0.8999\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.8688 - val_loss: 0.9402\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.8206 - val_loss: 0.9028\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 793us/step - loss: 0.8200 - val_loss: 0.8949\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.8098 - val_loss: 0.8750\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.7979 - val_loss: 0.8807\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.7750 - val_loss: 0.9081\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.7796 - val_loss: 0.8278\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.7624 - val_loss: 0.8916\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.7458 - val_loss: 0.8404\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.7431 - val_loss: 0.7985\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.7439 - val_loss: 0.8163\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.7260 - val_loss: 0.8087\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.7176 - val_loss: 0.8309\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.7209 - val_loss: 0.8104\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.7185 - val_loss: 0.8304\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.7129 - val_loss: 0.7713\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.7002 - val_loss: 0.7802\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.7044 - val_loss: 0.7870\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.6907 - val_loss: 0.7871\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6832 - val_loss: 0.7718\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6847 - val_loss: 0.7540\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6964 - val_loss: 0.7618\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6790 - val_loss: 0.7388\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6613 - val_loss: 0.7747\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.6653 - val_loss: 0.7355\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6714 - val_loss: 0.7241\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6755 - val_loss: 0.7259\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.6793 - val_loss: 0.7297\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6658 - val_loss: 0.7173\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6527 - val_loss: 0.7216\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6417 - val_loss: 0.7179\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.6492 - val_loss: 0.7075\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.6552 - val_loss: 0.7065\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.6423 - val_loss: 0.6988\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.6415 - val_loss: 0.7064\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6502 - val_loss: 0.7090\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6524 - val_loss: 0.7282\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6285 - val_loss: 0.7071\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6406 - val_loss: 0.7055\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6321 - val_loss: 0.6656\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6192 - val_loss: 0.6834\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6254 - val_loss: 0.7099\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.6426 - val_loss: 0.6748\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6181 - val_loss: 0.6700\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.6225 - val_loss: 0.6830\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6212 - val_loss: 0.6683\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6075 - val_loss: 0.6673\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6122 - val_loss: 0.6821\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5986 - val_loss: 0.6960\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5982 - val_loss: 0.6521\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6066 - val_loss: 0.6685\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6027 - val_loss: 0.6499\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5976 - val_loss: 0.6722\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5942 - val_loss: 0.6794\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6016 - val_loss: 0.6717\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5973 - val_loss: 0.6537\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6045 - val_loss: 0.6757\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6102 - val_loss: 0.6662\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5963 - val_loss: 0.6605\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5919 - val_loss: 0.6697\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5973 - val_loss: 0.6614\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5928 - val_loss: 0.6465\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5949 - val_loss: 0.6499\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6030 - val_loss: 0.6569\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.6113 - val_loss: 0.6265\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5923 - val_loss: 0.6480\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5838 - val_loss: 0.6584\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5914 - val_loss: 0.6489\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5905 - val_loss: 0.6383\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5779 - val_loss: 0.6303\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5810 - val_loss: 0.6236\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5900 - val_loss: 0.6264\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5889 - val_loss: 0.6208\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5784 - val_loss: 0.6218\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5750 - val_loss: 0.7092\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6019 - val_loss: 0.6265\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5761 - val_loss: 0.6289\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5898 - val_loss: 0.6395\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5833 - val_loss: 0.6415\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5844 - val_loss: 0.6470\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5838 - val_loss: 0.6210\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5780 - val_loss: 0.6225\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5762 - val_loss: 0.6154\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5812 - val_loss: 0.6327\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6025 - val_loss: 0.6556\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5828 - val_loss: 0.6197\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5865 - val_loss: 0.6296\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5667 - val_loss: 0.6473\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5757 - val_loss: 0.6244\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5797 - val_loss: 0.6248\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5769 - val_loss: 0.5986\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5705 - val_loss: 0.6614\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5840 - val_loss: 0.6303\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5857 - val_loss: 0.6316\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5591 - val_loss: 0.6409\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 702us/step - loss: 0.5740 - val_loss: 0.6235\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5649 - val_loss: 0.5959\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5662 - val_loss: 0.6729\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.6058 - val_loss: 0.6200\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5863 - val_loss: 0.6078\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6040 - val_loss: 0.6421\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5759 - val_loss: 0.6330\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5659 - val_loss: 0.6281\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5629 - val_loss: 0.6134\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5656 - val_loss: 0.6757\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 846us/step - loss: 0.5645 - val_loss: 0.6086\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5911 - val_loss: 0.6437\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 842us/step - loss: 0.5737 - val_loss: 0.6203\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 793us/step - loss: 0.5651 - val_loss: 0.6130\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5644 - val_loss: 0.6422\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 722us/step - loss: 0.5827 - val_loss: 0.7084\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 719us/step - loss: 0.5805 - val_loss: 0.6083\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 774us/step - loss: 0.5513 - val_loss: 0.6192\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 757us/step - loss: 0.5526 - val_loss: 0.6031\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 745us/step - loss: 0.5550 - val_loss: 0.6102\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5625 - val_loss: 0.6124\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 852us/step - loss: 0.5632 - val_loss: 0.6067\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5628 - val_loss: 0.5903\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.6509\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5574 - val_loss: 0.6205\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 850us/step - loss: 0.5511 - val_loss: 0.6103\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 738us/step - loss: 0.5464 - val_loss: 0.6556\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5580 - val_loss: 0.6188\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 744us/step - loss: 0.5541 - val_loss: 0.6581\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 736us/step - loss: 0.5475 - val_loss: 0.6205\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 744us/step - loss: 0.5629 - val_loss: 0.6134\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5567 - val_loss: 0.6319\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5605 - val_loss: 0.6141\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5507 - val_loss: 0.6099\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5528 - val_loss: 0.6088\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5623 - val_loss: 0.6232\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5520 - val_loss: 0.6179\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5616 - val_loss: 0.6101\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5573 - val_loss: 0.6057\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5495 - val_loss: 0.6025\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5509 - val_loss: 0.6197\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5580 - val_loss: 0.6224\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5555 - val_loss: 0.6105\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5435 - val_loss: 0.6305\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5451 - val_loss: 0.6042\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5592 - val_loss: 0.6240\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5617 - val_loss: 0.6012\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5589 - val_loss: 0.6151\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5546 - val_loss: 0.6106\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5439 - val_loss: 0.6169\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5649 - val_loss: 0.6123\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 870us/step - loss: 0.5438 - val_loss: 0.6018\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5577 - val_loss: 0.6162\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5594 - val_loss: 0.6252\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5672 - val_loss: 0.6226\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5586 - val_loss: 0.6120\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5503 - val_loss: 0.5999\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5386 - val_loss: 0.5952\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5453 - val_loss: 0.6055\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5427 - val_loss: 0.6111\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5381 - val_loss: 0.5953\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5568 - val_loss: 0.6071\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5474 - val_loss: 0.6159\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7670 - val_loss: 2.2964\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 1.8012 - val_loss: 1.4666\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 1.2880 - val_loss: 1.1555\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 1.1306 - val_loss: 0.9592\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 1.0658 - val_loss: 0.9117\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 1.0203 - val_loss: 0.8906\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 1.0310 - val_loss: 0.8812\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.9855 - val_loss: 0.8483\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.9701 - val_loss: 0.8389\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.9539 - val_loss: 0.8137\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.9419 - val_loss: 0.8021\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.9304 - val_loss: 0.8303\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.9034 - val_loss: 0.7740\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.8843 - val_loss: 0.7596\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.8672 - val_loss: 0.7261\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.8854 - val_loss: 0.7756\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.8685 - val_loss: 0.7546\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.8393 - val_loss: 0.7349\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.8362 - val_loss: 0.7302\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.8261 - val_loss: 0.7305\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.8179 - val_loss: 0.7401\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.8033 - val_loss: 0.7316\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.8041 - val_loss: 0.7805\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.7847 - val_loss: 0.6998\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.7663 - val_loss: 0.7166\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.7596 - val_loss: 0.8027\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.7686 - val_loss: 0.7449\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.7615 - val_loss: 0.7891\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.7540 - val_loss: 0.6981\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.7450 - val_loss: 0.6793\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.7359 - val_loss: 0.7311\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.7403 - val_loss: 0.6659\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.7267 - val_loss: 0.7680\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.7289 - val_loss: 0.6754\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.7089 - val_loss: 0.6490\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6980 - val_loss: 0.6348\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.7004 - val_loss: 0.7762\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.7007 - val_loss: 0.7192\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6890 - val_loss: 0.6873\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.6922 - val_loss: 0.6595\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.6872 - val_loss: 0.6726\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.6843 - val_loss: 0.7224\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6989 - val_loss: 0.6462\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.6713 - val_loss: 0.6323\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 761us/step - loss: 0.6790 - val_loss: 0.6574\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.6669 - val_loss: 0.6296\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.6784 - val_loss: 0.6713\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6581 - val_loss: 0.6355\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6609 - val_loss: 0.6054\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6514 - val_loss: 0.6441\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6540 - val_loss: 0.6125\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6423 - val_loss: 0.6049\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6446 - val_loss: 0.6474\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.6566 - val_loss: 0.6127\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6421 - val_loss: 0.6107\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6422 - val_loss: 0.6084\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6379 - val_loss: 0.6123\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6409 - val_loss: 0.6335\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 793us/step - loss: 0.6433 - val_loss: 0.5832\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.6553 - val_loss: 0.7101\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.6537 - val_loss: 0.6008\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6333 - val_loss: 0.6242\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6304 - val_loss: 0.6344\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6221 - val_loss: 0.5882\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6411 - val_loss: 0.6134\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.6149 - val_loss: 0.5624\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.6208 - val_loss: 0.6120\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6283 - val_loss: 0.6299\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.6223 - val_loss: 0.5893\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6196 - val_loss: 0.6447\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6231 - val_loss: 0.5888\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6359 - val_loss: 0.6260\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6299 - val_loss: 0.6909\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6232 - val_loss: 0.5829\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6134 - val_loss: 0.5960\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.6034 - val_loss: 0.5864\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6260 - val_loss: 0.5698\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6173 - val_loss: 0.6264\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6315 - val_loss: 0.5848\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6066 - val_loss: 0.5613\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6159 - val_loss: 0.6063\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6322 - val_loss: 0.6760\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6145 - val_loss: 0.5733\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6082 - val_loss: 0.6187\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.6242 - val_loss: 0.5911\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5994 - val_loss: 0.5570\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5940 - val_loss: 0.5686\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.6068 - val_loss: 0.5823\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6120 - val_loss: 0.5567\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5924 - val_loss: 0.5510\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5958 - val_loss: 0.5671\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5931 - val_loss: 0.5740\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5971 - val_loss: 0.6293\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6006 - val_loss: 0.5767\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6002 - val_loss: 0.5817\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6003 - val_loss: 0.5764\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5942 - val_loss: 0.5702\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5906 - val_loss: 0.5930\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5988 - val_loss: 0.5934\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5923 - val_loss: 0.5910\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5993 - val_loss: 0.5485\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5827 - val_loss: 0.5419\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5875 - val_loss: 0.6066\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6009 - val_loss: 0.5455\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6040 - val_loss: 0.5578\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5858 - val_loss: 0.5516\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5969 - val_loss: 0.5895\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5928 - val_loss: 0.5667\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.5884 - val_loss: 0.5627\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5869 - val_loss: 0.5695\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5950 - val_loss: 0.5519\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5940 - val_loss: 0.6143\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6040 - val_loss: 0.5569\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5901 - val_loss: 0.6115\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5948 - val_loss: 0.5643\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5953 - val_loss: 0.5653\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5786 - val_loss: 0.5444\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5853 - val_loss: 0.5493\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5828 - val_loss: 0.5631\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5816 - val_loss: 0.5324\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5859 - val_loss: 0.6219\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5784 - val_loss: 0.5482\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5995 - val_loss: 0.6607\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5853 - val_loss: 0.5528\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5748 - val_loss: 0.5767\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5845 - val_loss: 0.5834\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5721 - val_loss: 0.5483\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5771 - val_loss: 0.5363\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5723 - val_loss: 0.5739\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5780 - val_loss: 0.5527\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5796 - val_loss: 0.5326\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5847 - val_loss: 0.6225\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5822 - val_loss: 0.5706\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5744 - val_loss: 0.5458\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5744 - val_loss: 0.5428\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5719 - val_loss: 0.5772\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5830 - val_loss: 0.5544\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5707 - val_loss: 0.5472\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5730 - val_loss: 0.5577\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5700 - val_loss: 0.5475\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5673 - val_loss: 0.5517\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5745 - val_loss: 0.5370\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5773 - val_loss: 0.5475\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5700 - val_loss: 0.5300\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5722 - val_loss: 0.5533\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5693 - val_loss: 0.5453\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5742 - val_loss: 0.5260\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5752 - val_loss: 0.5668\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5844 - val_loss: 0.5453\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5642 - val_loss: 0.5422\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5698 - val_loss: 0.6251\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5884 - val_loss: 0.5414\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5709 - val_loss: 0.5347\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5683 - val_loss: 0.5331\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5635 - val_loss: 0.5462\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 724us/step - loss: 0.5630 - val_loss: 0.5248\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5651 - val_loss: 0.5904\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5711 - val_loss: 0.5686\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5704 - val_loss: 0.5814\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5653 - val_loss: 0.5163\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5577 - val_loss: 0.5578\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5590 - val_loss: 0.5531\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5624 - val_loss: 0.5377\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5700 - val_loss: 0.5329\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5589 - val_loss: 0.5279\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5560 - val_loss: 0.5318\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5510 - val_loss: 0.5202\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5633 - val_loss: 0.5222\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5563 - val_loss: 0.5705\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5709 - val_loss: 0.5584\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5591 - val_loss: 0.5351\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5627 - val_loss: 0.5484\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5602 - val_loss: 0.5149\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5657 - val_loss: 0.5670\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5589 - val_loss: 0.5328\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5569 - val_loss: 0.5332\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5529 - val_loss: 0.5420\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5651 - val_loss: 0.5605\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5643 - val_loss: 0.5525\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5571 - val_loss: 0.5400\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5589 - val_loss: 0.5228\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5590 - val_loss: 0.5262\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5544 - val_loss: 0.5549\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5527 - val_loss: 0.5375\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5564 - val_loss: 0.5317\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5634 - val_loss: 0.5444\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5643 - val_loss: 0.5335\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5604 - val_loss: 0.5379\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5542 - val_loss: 0.5278\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5513 - val_loss: 0.5342\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5562 - val_loss: 0.5265\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5572 - val_loss: 0.5525\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5555 - val_loss: 0.5097\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5598 - val_loss: 0.5297\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5489 - val_loss: 0.5351\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5634 - val_loss: 0.5410\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5648 - val_loss: 0.5215\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5555 - val_loss: 0.5521\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5541 - val_loss: 0.5293\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5409 - val_loss: 0.5184\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5609 - val_loss: 0.5465\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5515 - val_loss: 0.5710\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5667 - val_loss: 0.5212\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5446 - val_loss: 0.5046\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5521 - val_loss: 0.5393\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5573 - val_loss: 0.5378\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5480 - val_loss: 0.5189\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5518 - val_loss: 0.5361\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5491 - val_loss: 0.5468\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5460 - val_loss: 0.4987\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5475 - val_loss: 0.5189\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5498 - val_loss: 0.5486\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5516 - val_loss: 0.5172\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5604 - val_loss: 0.5472\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5498 - val_loss: 0.5220\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5457 - val_loss: 0.5015\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5439 - val_loss: 0.5627\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5497 - val_loss: 0.5195\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5583 - val_loss: 0.5408\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 0.5448 - val_loss: 0.4982\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5504 - val_loss: 0.5101\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5546 - val_loss: 0.5297\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5467 - val_loss: 0.5137\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5414 - val_loss: 0.5032\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5485 - val_loss: 0.5132\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5494 - val_loss: 0.5503\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5465 - val_loss: 0.5376\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5459 - val_loss: 0.5511\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5489 - val_loss: 0.5444\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5407 - val_loss: 0.5233\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5371 - val_loss: 0.5101\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5512 - val_loss: 0.5155\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5469 - val_loss: 0.5126\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5453 - val_loss: 0.5378\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5395 - val_loss: 0.5106\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5374 - val_loss: 0.5101\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5434 - val_loss: 0.5106\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5412 - val_loss: 0.5387\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5388 - val_loss: 0.5237\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5436 - val_loss: 0.5119\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5499 - val_loss: 0.5328\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.5387 - val_loss: 0.5363\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5429 - val_loss: 0.5218\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5398 - val_loss: 0.5692\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5519 - val_loss: 0.5059\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5468 - val_loss: 0.5277\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5407 - val_loss: 0.5327\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5525 - val_loss: 0.5051\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5353 - val_loss: 0.5104\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5483 - val_loss: 0.5153\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5400 - val_loss: 0.5271\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5500 - val_loss: 0.5161\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5387 - val_loss: 0.5039\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5447 - val_loss: 0.5193\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5456 - val_loss: 0.5071\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5433 - val_loss: 0.5302\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5445 - val_loss: 0.5319\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 913us/step - loss: 0.5373 - val_loss: 0.5160\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5387 - val_loss: 0.5033\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5357 - val_loss: 0.5449\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 9.2853 - val_loss: 5.4551\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 2.8582 - val_loss: 2.2570\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 1.5572 - val_loss: 1.3638\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 1.2321 - val_loss: 1.1445\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 1.1103 - val_loss: 1.1932\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 1.0554 - val_loss: 1.0551\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 1.0227 - val_loss: 0.9574\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.9911 - val_loss: 1.0324\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.9515 - val_loss: 1.0121\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.9304 - val_loss: 0.8999\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.9330 - val_loss: 0.9906\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.9033 - val_loss: 0.9248\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.8931 - val_loss: 0.8127\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.8831 - val_loss: 0.8588\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.8694 - val_loss: 0.8410\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.8596 - val_loss: 0.7815\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.8310 - val_loss: 0.8847\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.8264 - val_loss: 0.7725\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.8202 - val_loss: 0.8532\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.8090 - val_loss: 0.7872\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.7880 - val_loss: 0.7567\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.8010 - val_loss: 0.7804\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.7864 - val_loss: 0.7674\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.7962 - val_loss: 0.7376\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.7634 - val_loss: 0.6995\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.7525 - val_loss: 0.7359\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.7468 - val_loss: 0.7295\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.7441 - val_loss: 0.7305\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.7499 - val_loss: 0.6841\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.7317 - val_loss: 0.6839\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.7121 - val_loss: 0.7254\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.7102 - val_loss: 0.6814\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.7045 - val_loss: 0.7605\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6976 - val_loss: 0.7277\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.7050 - val_loss: 0.7201\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6827 - val_loss: 0.7626\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.6770 - val_loss: 0.6700\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6868 - val_loss: 0.6955\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6835 - val_loss: 0.6401\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6968 - val_loss: 0.7193\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6594 - val_loss: 0.6832\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.6543 - val_loss: 0.6857\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.6673 - val_loss: 0.6396\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6486 - val_loss: 0.6275\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6548 - val_loss: 0.6849\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6523 - val_loss: 0.7370\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.6358 - val_loss: 0.6699\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.6420 - val_loss: 0.6494\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.6397 - val_loss: 0.6393\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6526 - val_loss: 0.6448\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6480 - val_loss: 0.6986\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.6355 - val_loss: 0.6968\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6323 - val_loss: 0.6037\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6352 - val_loss: 0.6272\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6288 - val_loss: 0.6028\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6422 - val_loss: 0.6433\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6270 - val_loss: 0.6335\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6247 - val_loss: 0.6263\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.6187 - val_loss: 0.6512\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6056 - val_loss: 0.6125\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6217 - val_loss: 0.7102\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6262 - val_loss: 0.6059\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6060 - val_loss: 0.6034\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.6084 - val_loss: 0.6552\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6063 - val_loss: 0.5972\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6051 - val_loss: 0.6402\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.6036 - val_loss: 0.5911\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6069 - val_loss: 0.6121\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5952 - val_loss: 0.6587\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.6069 - val_loss: 0.5894\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6067 - val_loss: 0.5994\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.6165 - val_loss: 0.6135\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5947 - val_loss: 0.6124\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5962 - val_loss: 0.6187\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5993 - val_loss: 0.6009\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5912 - val_loss: 0.5976\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5890 - val_loss: 0.6064\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5920 - val_loss: 0.5605\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5975 - val_loss: 0.6550\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5942 - val_loss: 0.6920\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5959 - val_loss: 0.6350\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.6024 - val_loss: 0.5869\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 713us/step - loss: 0.6045 - val_loss: 0.5796\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 734us/step - loss: 0.5876 - val_loss: 0.6045\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.5965 - val_loss: 0.5761\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 785us/step - loss: 0.5815 - val_loss: 0.5757\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 724us/step - loss: 0.5829 - val_loss: 0.6023\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.5969 - val_loss: 0.6216\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5824 - val_loss: 0.5801\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 716us/step - loss: 0.5793 - val_loss: 0.5825\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5788 - val_loss: 0.6129\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 722us/step - loss: 0.5734 - val_loss: 0.5844\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5864 - val_loss: 0.5831\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5775 - val_loss: 0.6425\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5748 - val_loss: 0.6070\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 723us/step - loss: 0.5774 - val_loss: 0.5654\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5801 - val_loss: 0.6115\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5761 - val_loss: 0.6076\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5818 - val_loss: 0.5790\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5762 - val_loss: 0.5889\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5721 - val_loss: 0.6026\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5719 - val_loss: 0.5672\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5784 - val_loss: 0.6055\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5680 - val_loss: 0.5804\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5778 - val_loss: 0.6209\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5727 - val_loss: 0.6051\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5736 - val_loss: 0.5942\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5688 - val_loss: 0.6117\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5674 - val_loss: 0.5537\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5746 - val_loss: 0.6022\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5610 - val_loss: 0.6058\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5691 - val_loss: 0.5619\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5693 - val_loss: 0.5647\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5690 - val_loss: 0.6364\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5724 - val_loss: 0.5716\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5634 - val_loss: 0.5471\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5756 - val_loss: 0.6000\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5692 - val_loss: 0.6131\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5763 - val_loss: 0.5993\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5705 - val_loss: 0.5751\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5650 - val_loss: 0.5783\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5788 - val_loss: 0.6113\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5641 - val_loss: 0.5927\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5705 - val_loss: 0.5748\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5711 - val_loss: 0.6596\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5702 - val_loss: 0.6127\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5579 - val_loss: 0.5876\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5637 - val_loss: 0.5961\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 711us/step - loss: 0.5672 - val_loss: 0.5571\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5626 - val_loss: 0.5804\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 713us/step - loss: 0.5750 - val_loss: 0.5618\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 906us/step - loss: 0.5758 - val_loss: 0.6462\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 791us/step - loss: 0.5661 - val_loss: 0.5934\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.5666 - val_loss: 0.5946\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.5692 - val_loss: 0.5469\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5549 - val_loss: 0.5829\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5572 - val_loss: 0.5878\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5614 - val_loss: 0.6723\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5603 - val_loss: 0.5904\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5592 - val_loss: 0.5825\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5650 - val_loss: 0.5910\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5486 - val_loss: 0.5751\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5527 - val_loss: 0.5658\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5630 - val_loss: 0.5951\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5504 - val_loss: 0.5720\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5466 - val_loss: 0.5486\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5542 - val_loss: 0.5532\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5534 - val_loss: 0.5247\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5614 - val_loss: 0.5775\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5479 - val_loss: 0.5715\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5624 - val_loss: 0.5513\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5562 - val_loss: 0.5554\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5465 - val_loss: 0.5986\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5582 - val_loss: 0.5498\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5468 - val_loss: 0.5695\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5462 - val_loss: 0.5281\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5545 - val_loss: 0.5624\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5537 - val_loss: 0.5632\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5493 - val_loss: 0.6035\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5529 - val_loss: 0.5474\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5403 - val_loss: 0.5879\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5472 - val_loss: 0.5348\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5494 - val_loss: 0.5523\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5507 - val_loss: 0.5359\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5530 - val_loss: 0.5487\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5419 - val_loss: 0.5357\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5433 - val_loss: 0.6350\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5560 - val_loss: 0.5786\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5553 - val_loss: 0.5230\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5400 - val_loss: 0.5177\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5501 - val_loss: 0.5315\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5493 - val_loss: 0.5431\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 764us/step - loss: 0.5409 - val_loss: 0.5552\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5435 - val_loss: 0.5718\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5475 - val_loss: 0.5583\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5486 - val_loss: 0.5672\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5369 - val_loss: 0.5042\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5357 - val_loss: 0.5727\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5454 - val_loss: 0.5512\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5366 - val_loss: 0.5603\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5435 - val_loss: 0.5791\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5303 - val_loss: 0.5519\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5405 - val_loss: 0.5476\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5364 - val_loss: 0.5973\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5421 - val_loss: 0.5570\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 771us/step - loss: 0.5365 - val_loss: 0.5361\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5342 - val_loss: 0.5366\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5361 - val_loss: 0.5319\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5316 - val_loss: 0.5257\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5431 - val_loss: 0.5410\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5382 - val_loss: 0.5533\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5345 - val_loss: 0.5438\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5270 - val_loss: 0.5213\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5276 - val_loss: 0.5155\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5308 - val_loss: 0.5377\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5341 - val_loss: 0.5401\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5261 - val_loss: 0.5314\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5271 - val_loss: 0.5616\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5333 - val_loss: 0.5024\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5343 - val_loss: 0.5391\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5319 - val_loss: 0.5213\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5316 - val_loss: 0.5735\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5302 - val_loss: 0.6054\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5373 - val_loss: 0.5423\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5263 - val_loss: 0.5985\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5332 - val_loss: 0.5182\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5317 - val_loss: 0.5670\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5182 - val_loss: 0.6044\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5496 - val_loss: 0.5280\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5392 - val_loss: 0.5307\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5235 - val_loss: 0.5433\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 716us/step - loss: 0.5305 - val_loss: 0.5471\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5299 - val_loss: 0.5000\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5234 - val_loss: 0.5581\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5509\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 889us/step - loss: 0.5322 - val_loss: 0.5373\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.5177 - val_loss: 0.5200\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.5198 - val_loss: 0.5634\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5342 - val_loss: 0.5011\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 763us/step - loss: 0.5370 - val_loss: 0.5091\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 715us/step - loss: 0.5348 - val_loss: 0.5141\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5242 - val_loss: 0.5193\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5206 - val_loss: 0.5520\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5235 - val_loss: 0.5076\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5304 - val_loss: 0.5258\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5182 - val_loss: 0.5556\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5276 - val_loss: 0.5287\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 817us/step - loss: 0.5183 - val_loss: 0.5373\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5253 - val_loss: 0.5318\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5271 - val_loss: 0.5999\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5350 - val_loss: 0.5324\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5316 - val_loss: 0.5064\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5181 - val_loss: 0.5507\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5303 - val_loss: 0.5213\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5201 - val_loss: 0.5261\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5197 - val_loss: 0.5418\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5225 - val_loss: 0.5266\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5169 - val_loss: 0.5132\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5273 - val_loss: 0.5130\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5220 - val_loss: 0.5215\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5347 - val_loss: 0.5170\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5164 - val_loss: 0.5501\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5305 - val_loss: 0.5760\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5250 - val_loss: 0.5279\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.5133 - val_loss: 0.5554\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5131 - val_loss: 0.5067\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5183 - val_loss: 0.5527\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5217 - val_loss: 0.4917\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5152 - val_loss: 0.5250\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5181 - val_loss: 0.5460\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5131 - val_loss: 0.5256\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5204 - val_loss: 0.5271\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5153 - val_loss: 0.5302\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5230 - val_loss: 0.5189\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5139 - val_loss: 0.4969\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5179 - val_loss: 0.5441\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.5208 - val_loss: 0.5218\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5326 - val_loss: 0.4843\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5191 - val_loss: 0.5168\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.5202 - val_loss: 0.5714\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5222 - val_loss: 0.5053\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5124 - val_loss: 0.5568\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5368 - val_loss: 0.5447\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5206 - val_loss: 0.5158\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5080 - val_loss: 0.4879\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5151 - val_loss: 0.5124\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5153 - val_loss: 0.5217\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5177 - val_loss: 0.5033\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5339 - val_loss: 0.5314\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5162 - val_loss: 0.5290\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5240 - val_loss: 0.5719\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5199 - val_loss: 0.5085\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5108 - val_loss: 0.5068\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5103 - val_loss: 0.5941\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5200 - val_loss: 0.4783\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5091 - val_loss: 0.4945\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5228 - val_loss: 0.4989\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5116 - val_loss: 0.5188\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.5077 - val_loss: 0.5276\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5149 - val_loss: 0.4848\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5151 - val_loss: 0.5701\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5215 - val_loss: 0.4865\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5147 - val_loss: 0.5189\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5179 - val_loss: 0.4937\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5078 - val_loss: 0.4901\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5093 - val_loss: 0.4850\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5078 - val_loss: 0.5043\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5118 - val_loss: 0.5218\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5144 - val_loss: 0.5028\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5218 - val_loss: 0.5375\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5124 - val_loss: 0.5229\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5164 - val_loss: 0.5141\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5137 - val_loss: 0.5011\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5079 - val_loss: 0.5121\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5129 - val_loss: 0.4989\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5087 - val_loss: 0.5433\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5001 - val_loss: 0.4858\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5127 - val_loss: 0.5728\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5261 - val_loss: 0.5152\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5168 - val_loss: 0.5064\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5151 - val_loss: 0.4744\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5025 - val_loss: 0.5077\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.5104 - val_loss: 0.5392\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5097 - val_loss: 0.5211\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5090 - val_loss: 0.4797\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5143 - val_loss: 0.4950\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5166 - val_loss: 0.4941\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5028 - val_loss: 0.4966\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5075 - val_loss: 0.4973\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5238 - val_loss: 0.5110\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5087 - val_loss: 0.5024\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5086 - val_loss: 0.4988\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5058 - val_loss: 0.5143\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5027 - val_loss: 0.4788\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5037 - val_loss: 0.4725\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5214 - val_loss: 0.5001\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5129 - val_loss: 0.4881\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5115 - val_loss: 0.4832\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5107 - val_loss: 0.5099\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5009 - val_loss: 0.5021\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5064 - val_loss: 0.4757\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4989 - val_loss: 0.5048\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5146 - val_loss: 0.5117\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5125 - val_loss: 0.5145\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5030 - val_loss: 0.4667\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5118 - val_loss: 0.4614\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5079 - val_loss: 0.4998\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.4996 - val_loss: 0.5484\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5041 - val_loss: 0.4829\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5062 - val_loss: 0.5247\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5031 - val_loss: 0.4798\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5082 - val_loss: 0.4896\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5029 - val_loss: 0.4679\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5051 - val_loss: 0.4607\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5049 - val_loss: 0.4922\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5063 - val_loss: 0.4712\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5017 - val_loss: 0.4814\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5057 - val_loss: 0.4834\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5122 - val_loss: 0.4693\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5079 - val_loss: 0.4994\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4973 - val_loss: 0.4492\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.5074 - val_loss: 0.4786\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5084 - val_loss: 0.4800\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4992 - val_loss: 0.5204\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5037 - val_loss: 0.5210\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5079 - val_loss: 0.5019\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5041 - val_loss: 0.4646\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5123 - val_loss: 0.4486\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5176 - val_loss: 0.4856\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5028 - val_loss: 0.4969\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.4980 - val_loss: 0.4591\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5044 - val_loss: 0.4939\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5111 - val_loss: 0.4674\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5227 - val_loss: 0.5180\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5107 - val_loss: 0.4854\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5107 - val_loss: 0.5515\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5024 - val_loss: 0.4728\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5012 - val_loss: 0.4941\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5018 - val_loss: 0.4960\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5002 - val_loss: 0.4799\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5053 - val_loss: 0.4713\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5025 - val_loss: 0.5262\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5172 - val_loss: 0.4680\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 721us/step - loss: 0.5067 - val_loss: 0.4948\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.4960 - val_loss: 0.4892\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5049 - val_loss: 0.5012\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5066 - val_loss: 0.4930\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5112 - val_loss: 0.5114\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5077 - val_loss: 0.4940\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5085 - val_loss: 0.5030\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5087 - val_loss: 0.5254\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5084 - val_loss: 0.5194\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5005 - val_loss: 0.4619\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.4994 - val_loss: 0.4765\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5012 - val_loss: 0.4914\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4944 - val_loss: 0.5054\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.4963 - val_loss: 0.4665\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.4893 - val_loss: 0.5258\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 774us/step - loss: 0.5066 - val_loss: 0.4793\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 734us/step - loss: 0.4968 - val_loss: 0.4928\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5067 - val_loss: 0.5019\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5046 - val_loss: 0.5135\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.4916 - val_loss: 0.4492\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.4899 - val_loss: 0.5040\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5009 - val_loss: 0.4593\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4930 - val_loss: 0.4864\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.4972 - val_loss: 0.4701\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4999 - val_loss: 0.4813\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1809 - val_loss: 4.2340\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 1.9875 - val_loss: 1.7503\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 1.3456 - val_loss: 1.3381\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 1.1280 - val_loss: 1.1192\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 1.0317 - val_loss: 1.1510\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.9911 - val_loss: 1.0193\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.9700 - val_loss: 1.0682\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.9263 - val_loss: 0.9422\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.9056 - val_loss: 0.9784\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.9032 - val_loss: 0.9515\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.8907 - val_loss: 0.9582\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.8761 - val_loss: 1.0491\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.8616 - val_loss: 1.0295\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8501 - val_loss: 0.9050\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.8351 - val_loss: 0.9573\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.8373 - val_loss: 0.8891\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.8283 - val_loss: 0.8781\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.8224 - val_loss: 0.8844\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.8206 - val_loss: 0.8611\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.8144 - val_loss: 0.8950\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8039 - val_loss: 0.9174\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8012 - val_loss: 0.8233\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8034 - val_loss: 0.9517\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 746us/step - loss: 0.7918 - val_loss: 0.8423\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.7789 - val_loss: 0.8330\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.7747 - val_loss: 0.7951\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.7654 - val_loss: 0.8712\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.7629 - val_loss: 0.7884\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.7445 - val_loss: 0.7963\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.7538 - val_loss: 0.8005\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.7441 - val_loss: 0.7754\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.7256 - val_loss: 0.7690\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.7370 - val_loss: 0.7766\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.7163 - val_loss: 0.7938\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.7063 - val_loss: 0.8085\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.7234 - val_loss: 0.7927\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.7028 - val_loss: 0.7347\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.7084 - val_loss: 0.7634\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.6942 - val_loss: 0.7815\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.6957 - val_loss: 0.7919\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.6806 - val_loss: 0.7531\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 724us/step - loss: 0.6805 - val_loss: 0.7477\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.6872 - val_loss: 0.7548\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6723 - val_loss: 0.7083\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6634 - val_loss: 0.8195\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.6782 - val_loss: 0.8487\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.6580 - val_loss: 0.7631\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6414 - val_loss: 0.6816\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6415 - val_loss: 0.6847\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.6325 - val_loss: 0.7150\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6335 - val_loss: 0.7512\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6496 - val_loss: 0.7109\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6295 - val_loss: 0.6885\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6188 - val_loss: 0.6903\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6184 - val_loss: 0.7040\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6109 - val_loss: 0.6789\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6132 - val_loss: 0.7049\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6175 - val_loss: 0.6718\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5960 - val_loss: 0.6601\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.6121 - val_loss: 0.7062\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6127 - val_loss: 0.6862\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6013 - val_loss: 0.6585\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5963 - val_loss: 0.6477\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5965 - val_loss: 0.6275\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5969 - val_loss: 0.6449\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.6007 - val_loss: 0.6998\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 755us/step - loss: 0.6148 - val_loss: 0.6817\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 0.5870 - val_loss: 0.6359\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5896 - val_loss: 0.7527\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 722us/step - loss: 0.6167 - val_loss: 0.6542\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 747us/step - loss: 0.5974 - val_loss: 0.6357\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 702us/step - loss: 0.5903 - val_loss: 0.6394\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5764 - val_loss: 0.6303\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5809 - val_loss: 0.6285\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 717us/step - loss: 0.5730 - val_loss: 0.6477\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 856us/step - loss: 0.5685 - val_loss: 0.6311\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5746 - val_loss: 0.6392\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 0.6213\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 805us/step - loss: 0.5713 - val_loss: 0.6676\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 775us/step - loss: 0.5826 - val_loss: 0.6288\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 900us/step - loss: 0.5681 - val_loss: 0.6454\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 773us/step - loss: 0.5613 - val_loss: 0.6148\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 782us/step - loss: 0.5589 - val_loss: 0.7572\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5927 - val_loss: 0.6105\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 716us/step - loss: 0.5567 - val_loss: 0.6035\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5563 - val_loss: 0.6235\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5623 - val_loss: 0.6499\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5530 - val_loss: 0.6418\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5614 - val_loss: 0.6322\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5600 - val_loss: 0.6458\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5639 - val_loss: 0.6142\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5515 - val_loss: 0.5864\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5426 - val_loss: 0.5692\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5464 - val_loss: 0.6661\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5467 - val_loss: 0.6207\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5673 - val_loss: 0.7283\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5671 - val_loss: 0.6297\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5473 - val_loss: 0.6425\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5475 - val_loss: 0.6195\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5550 - val_loss: 0.5858\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5539 - val_loss: 0.6833\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5524 - val_loss: 0.6345\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5512 - val_loss: 0.7084\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5481 - val_loss: 0.6190\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 853us/step - loss: 0.5412 - val_loss: 0.6589\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5578 - val_loss: 0.6305\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5351 - val_loss: 0.6064\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5371 - val_loss: 0.5745\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5370 - val_loss: 0.5921\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5488 - val_loss: 0.6367\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 0.5413 - val_loss: 0.5732\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 986us/step - loss: 0.5332 - val_loss: 0.5883\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 945us/step - loss: 0.5286 - val_loss: 0.6227\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 976us/step - loss: 0.5327 - val_loss: 0.5870\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 715us/step - loss: 0.5367 - val_loss: 0.6213\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5435 - val_loss: 0.5595\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5428 - val_loss: 0.5933\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5324 - val_loss: 0.5970\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5341 - val_loss: 0.5886\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5351 - val_loss: 0.6431\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.5351 - val_loss: 0.6591\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5382 - val_loss: 0.6223\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5290 - val_loss: 0.5895\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5360 - val_loss: 0.5968\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5389 - val_loss: 0.5608\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 702us/step - loss: 0.5292 - val_loss: 0.6452\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.5247 - val_loss: 0.5679\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5279 - val_loss: 0.5687\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5776\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.5302 - val_loss: 0.5886\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5301 - val_loss: 0.5748\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5294 - val_loss: 0.5611\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 0.5289 - val_loss: 0.5530\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5303 - val_loss: 0.6053\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5228 - val_loss: 0.5914\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5284 - val_loss: 0.5637\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5250 - val_loss: 0.5682\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 703us/step - loss: 0.5133 - val_loss: 0.6083\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5267 - val_loss: 0.6451\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5261 - val_loss: 0.6042\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 703us/step - loss: 0.5237 - val_loss: 0.5733\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5114 - val_loss: 0.6022\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 908us/step - loss: 0.5236 - val_loss: 0.6637\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 0.5707\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5164 - val_loss: 0.5534\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5131 - val_loss: 0.5653\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5203 - val_loss: 0.5796\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5194 - val_loss: 0.5598\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 893us/step - loss: 0.5198 - val_loss: 0.5507\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5185 - val_loss: 0.5812\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5115 - val_loss: 0.5551\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5043 - val_loss: 0.5928\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5194 - val_loss: 0.5362\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5163 - val_loss: 0.5722\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5134 - val_loss: 0.5711\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5161 - val_loss: 0.5436\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5217 - val_loss: 0.5794\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5196 - val_loss: 0.6231\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5152 - val_loss: 0.5733\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5116 - val_loss: 0.5692\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 800us/step - loss: 0.5106 - val_loss: 0.5553\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5068 - val_loss: 0.5483\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5079 - val_loss: 0.5582\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5046 - val_loss: 0.5782\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5090 - val_loss: 0.5463\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5193 - val_loss: 0.5799\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5153 - val_loss: 0.5838\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5149 - val_loss: 0.5482\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5084 - val_loss: 0.5543\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5036 - val_loss: 0.5547\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5191 - val_loss: 0.5539\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5065 - val_loss: 0.5453\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5084 - val_loss: 0.5564\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5166 - val_loss: 0.5523\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5087 - val_loss: 0.5713\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5199 - val_loss: 0.5612\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5029 - val_loss: 0.5802\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5016 - val_loss: 0.5586\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5050 - val_loss: 0.5755\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5073 - val_loss: 0.5592\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5089 - val_loss: 0.5374\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.5070 - val_loss: 0.5512\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5062 - val_loss: 0.5438\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5006 - val_loss: 0.5558\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5023 - val_loss: 0.5438\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5128 - val_loss: 0.5426\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5193 - val_loss: 0.5355\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5011 - val_loss: 0.5491\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5028 - val_loss: 0.5765\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5036 - val_loss: 0.5579\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.4996 - val_loss: 0.5636\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5002 - val_loss: 0.5492\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4992 - val_loss: 0.5464\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5017 - val_loss: 0.5878\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5091 - val_loss: 0.5536\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5075 - val_loss: 0.5637\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5059 - val_loss: 0.5557\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5126 - val_loss: 0.5778\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5028 - val_loss: 0.5413\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5009 - val_loss: 0.5251\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5023 - val_loss: 0.6393\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5162 - val_loss: 0.5515\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4998 - val_loss: 0.5551\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5024 - val_loss: 0.5675\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4898 - val_loss: 0.5236\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.4940 - val_loss: 0.5705\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4877 - val_loss: 0.5276\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5003 - val_loss: 0.5324\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5008 - val_loss: 0.5518\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.4958 - val_loss: 0.5231\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.4937 - val_loss: 0.5474\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.4919 - val_loss: 0.5534\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4935 - val_loss: 0.5562\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5043 - val_loss: 0.5445\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.4911 - val_loss: 0.5681\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.4940 - val_loss: 0.5190\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.4907 - val_loss: 0.5394\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.4965 - val_loss: 0.5607\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.4999 - val_loss: 0.5488\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4909 - val_loss: 0.5445\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4907 - val_loss: 0.5352\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.4978 - val_loss: 0.5589\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5108 - val_loss: 0.5661\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5029 - val_loss: 0.5839\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4973 - val_loss: 0.5322\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.4919 - val_loss: 0.5671\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4912 - val_loss: 0.5775\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5025 - val_loss: 0.5472\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4893 - val_loss: 0.5673\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.4919 - val_loss: 0.5619\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4920 - val_loss: 0.5757\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.4890 - val_loss: 0.5391\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.4888 - val_loss: 0.5349\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.4947 - val_loss: 0.5246\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4986 - val_loss: 0.5155\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.4932 - val_loss: 0.5519\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.4918 - val_loss: 0.5275\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4902 - val_loss: 0.5708\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.4944 - val_loss: 0.5480\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.4861 - val_loss: 0.5486\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 750us/step - loss: 0.4865 - val_loss: 0.5420\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.4966 - val_loss: 0.5644\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5006 - val_loss: 0.5342\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4882 - val_loss: 0.5606\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.4922 - val_loss: 0.5542\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.4876 - val_loss: 0.5714\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4907 - val_loss: 0.5226\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.4872 - val_loss: 0.5531\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4882 - val_loss: 0.5422\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.4845 - val_loss: 0.5481\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4882 - val_loss: 0.5477\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.4895 - val_loss: 0.5346\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.4863 - val_loss: 0.5305\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4800 - val_loss: 0.5184\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.4975 - val_loss: 0.5240\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4804 - val_loss: 0.5399\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.4863 - val_loss: 0.5685\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4841 - val_loss: 0.5130\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.4892 - val_loss: 0.5217\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4898 - val_loss: 0.5553\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.4858 - val_loss: 0.5444\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.4811 - val_loss: 0.5287\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4854 - val_loss: 0.5407\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.4908 - val_loss: 0.5650\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.4889 - val_loss: 0.5299\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4863 - val_loss: 0.5705\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.4849 - val_loss: 0.5179\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4884 - val_loss: 0.5558\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4838 - val_loss: 0.5400\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4907 - val_loss: 0.5316\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4956 - val_loss: 0.5260\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.4836 - val_loss: 0.5305\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.4800 - val_loss: 0.5245\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.4847 - val_loss: 0.5448\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.4807 - val_loss: 0.5474\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4786 - val_loss: 0.5259\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4811 - val_loss: 0.5220\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4883 - val_loss: 0.5177\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4814 - val_loss: 0.5646\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.4889 - val_loss: 0.5629\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.4812 - val_loss: 0.5861\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.4910 - val_loss: 0.5362\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4842 - val_loss: 0.5437\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4838 - val_loss: 0.5127\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.4805 - val_loss: 0.5579\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.4927 - val_loss: 0.5168\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4840 - val_loss: 0.5353\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.4831 - val_loss: 0.5274\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.4717 - val_loss: 0.5750\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4786 - val_loss: 0.5307\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4812 - val_loss: 0.5106\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.4827 - val_loss: 0.5239\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4817 - val_loss: 0.5341\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.4832 - val_loss: 0.5300\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4816 - val_loss: 0.5606\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4856 - val_loss: 0.5290\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.4805 - val_loss: 0.5393\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4761 - val_loss: 0.5425\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.4823 - val_loss: 0.5620\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.4860 - val_loss: 0.5587\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4932 - val_loss: 0.5425\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.4871 - val_loss: 0.5233\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.4798 - val_loss: 0.5110\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.4765 - val_loss: 0.5230\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4792 - val_loss: 0.5504\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4795 - val_loss: 0.5326\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.4807 - val_loss: 0.5161\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4716 - val_loss: 0.5320\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4743 - val_loss: 0.5221\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.4805 - val_loss: 0.5071\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4823 - val_loss: 0.5218\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.4739 - val_loss: 0.5199\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.4786 - val_loss: 0.5112\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.4847 - val_loss: 0.6071\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.4865 - val_loss: 0.5635\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4800 - val_loss: 0.5336\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4806 - val_loss: 0.5739\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.4857 - val_loss: 0.5755\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.4789 - val_loss: 0.5179\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4796 - val_loss: 0.5384\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 707us/step - loss: 0.4796 - val_loss: 0.5135\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4713 - val_loss: 0.5194\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.4768 - val_loss: 0.5522\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4914 - val_loss: 0.5462\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4707 - val_loss: 0.5217\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4774 - val_loss: 0.5066\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4782 - val_loss: 0.5799\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4740 - val_loss: 0.5262\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.4726 - val_loss: 0.5280\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.4788 - val_loss: 0.5136\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.4749 - val_loss: 0.5161\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.4770 - val_loss: 0.5110\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.4697 - val_loss: 0.5313\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4796 - val_loss: 0.5466\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.4789 - val_loss: 0.5394\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.4863 - val_loss: 0.5519\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.4805 - val_loss: 0.5428\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.4719 - val_loss: 0.5046\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4711 - val_loss: 0.5335\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.4831 - val_loss: 0.5588\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4860 - val_loss: 0.5972\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4916 - val_loss: 0.5237\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4724 - val_loss: 0.5384\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4947 - val_loss: 0.5173\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.4698 - val_loss: 0.5327\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.4678 - val_loss: 0.5082\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.4721 - val_loss: 0.5183\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.4663 - val_loss: 0.5484\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.4695 - val_loss: 0.4968\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.4775 - val_loss: 0.5604\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.4801 - val_loss: 0.5107\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4776 - val_loss: 0.5501\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4743 - val_loss: 0.5318\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4712 - val_loss: 0.5305\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.4651 - val_loss: 0.5218\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4701 - val_loss: 0.5669\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.4958 - val_loss: 0.5306\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4666 - val_loss: 0.5319\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4761 - val_loss: 0.5270\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.4704 - val_loss: 0.5407\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4806 - val_loss: 0.5220\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.4711 - val_loss: 0.5213\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4793 - val_loss: 0.5072\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.4702 - val_loss: 0.5175\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4690 - val_loss: 0.5297\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.4708 - val_loss: 0.5457\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.4691 - val_loss: 0.5219\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4721 - val_loss: 0.5135\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.4703 - val_loss: 0.5716\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.4806 - val_loss: 0.4997\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4715 - val_loss: 0.5430\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.4715 - val_loss: 0.5163\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.4673 - val_loss: 0.4985\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4725 - val_loss: 0.5088\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.4639 - val_loss: 0.4992\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.4743 - val_loss: 0.5115\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.4679 - val_loss: 0.5242\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.4670 - val_loss: 0.5222\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4690 - val_loss: 0.5047\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.4713 - val_loss: 0.5198\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.4693 - val_loss: 0.5259\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.4671 - val_loss: 0.5144\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4827 - val_loss: 0.5395\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4678 - val_loss: 0.5194\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4674 - val_loss: 0.5192\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.4756 - val_loss: 0.5471\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4769 - val_loss: 0.5013\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4698 - val_loss: 0.5223\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.4646 - val_loss: 0.5127\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 4.7654 - val_loss: 3.1403\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 1.7476 - val_loss: 1.8746\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 1.2354 - val_loss: 1.3020\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 1.1219 - val_loss: 1.2450\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 1.0623 - val_loss: 1.2183\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 1.0183 - val_loss: 1.1427\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.9795 - val_loss: 1.1313\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.9711 - val_loss: 1.1172\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 789us/step - loss: 0.9654 - val_loss: 1.1068\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 749us/step - loss: 0.9415 - val_loss: 1.0928\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.9185 - val_loss: 1.0474\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 760us/step - loss: 0.9211 - val_loss: 1.0286\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 717us/step - loss: 0.9024 - val_loss: 1.0270\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 0.8822 - val_loss: 0.9828\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 722us/step - loss: 0.8768 - val_loss: 0.9838\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 713us/step - loss: 0.8574 - val_loss: 0.9444\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.8536 - val_loss: 0.9557\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8402 - val_loss: 0.9342\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8352 - val_loss: 0.9230\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8201 - val_loss: 0.8855\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 767us/step - loss: 0.7922 - val_loss: 0.8955\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.7808 - val_loss: 0.8889\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 743us/step - loss: 0.7781 - val_loss: 0.8496\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 734us/step - loss: 0.7680 - val_loss: 0.8354\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 743us/step - loss: 0.7679 - val_loss: 0.8424\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.7580 - val_loss: 0.8064\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.7448 - val_loss: 0.9210\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.7455 - val_loss: 0.7880\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.7279 - val_loss: 0.8140\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.7211 - val_loss: 0.7621\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.7172 - val_loss: 0.7913\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.7196 - val_loss: 0.7553\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.7095 - val_loss: 0.7591\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6940 - val_loss: 0.7381\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.6792 - val_loss: 0.7311\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6761 - val_loss: 0.7392\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.6781 - val_loss: 0.7321\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6693 - val_loss: 0.6997\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6521 - val_loss: 0.6986\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.6442 - val_loss: 0.6977\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6582 - val_loss: 0.6870\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.6430 - val_loss: 0.6938\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.6421 - val_loss: 0.6966\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.6426 - val_loss: 0.6809\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6345 - val_loss: 0.7163\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6344 - val_loss: 0.6775\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6305 - val_loss: 0.6924\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.6367 - val_loss: 0.6971\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6291 - val_loss: 0.6787\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6303 - val_loss: 0.7054\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 985us/step - loss: 0.6186 - val_loss: 0.6580\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.6166 - val_loss: 0.6700\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.6082 - val_loss: 0.6526\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.6080 - val_loss: 0.6597\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6321 - val_loss: 0.6728\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6179 - val_loss: 0.6690\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.6179 - val_loss: 0.6557\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.6052 - val_loss: 0.6557\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6000 - val_loss: 0.6543\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6025 - val_loss: 0.6495\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.6060 - val_loss: 0.6400\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6097 - val_loss: 0.6367\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6082 - val_loss: 0.6913\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6080 - val_loss: 0.6567\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.6055 - val_loss: 0.6657\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.6018 - val_loss: 0.6543\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5976 - val_loss: 0.6361\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5914 - val_loss: 0.6613\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5888 - val_loss: 0.6353\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6103 - val_loss: 0.6369\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6045 - val_loss: 0.6372\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5822 - val_loss: 0.6261\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5903 - val_loss: 0.6281\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5877 - val_loss: 0.6243\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 703us/step - loss: 0.6007 - val_loss: 0.6388\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5940 - val_loss: 0.6342\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5903 - val_loss: 0.6291\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5921 - val_loss: 0.6194\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5914 - val_loss: 0.6224\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5823 - val_loss: 0.6174\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5846 - val_loss: 0.6185\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5762 - val_loss: 0.6142\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5829 - val_loss: 0.6123\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5904 - val_loss: 0.6253\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6021 - val_loss: 0.6201\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 787us/step - loss: 0.5761 - val_loss: 0.6100\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5716 - val_loss: 0.6121\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5722 - val_loss: 0.6323\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5778 - val_loss: 0.6221\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5729 - val_loss: 0.6160\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5721 - val_loss: 0.5992\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5632 - val_loss: 0.6307\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5781 - val_loss: 0.6324\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5790 - val_loss: 0.6163\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5772 - val_loss: 0.6097\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 721us/step - loss: 0.5680 - val_loss: 0.6110\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.5866 - val_loss: 0.6079\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5811 - val_loss: 0.6216\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5847 - val_loss: 0.6111\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5792 - val_loss: 0.6050\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5653 - val_loss: 0.6073\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5689 - val_loss: 0.6149\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5674 - val_loss: 0.5961\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5658 - val_loss: 0.6129\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5717 - val_loss: 0.6122\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5701 - val_loss: 0.5992\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5645 - val_loss: 0.6074\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5644 - val_loss: 0.5971\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5606 - val_loss: 0.5885\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5631 - val_loss: 0.5990\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5673 - val_loss: 0.5962\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5662 - val_loss: 0.6026\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5624 - val_loss: 0.5996\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5630 - val_loss: 0.5982\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5681 - val_loss: 0.5971\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5697 - val_loss: 0.5940\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5653 - val_loss: 0.5866\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5603 - val_loss: 0.5971\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5626 - val_loss: 0.6114\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5522 - val_loss: 0.5873\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5535 - val_loss: 0.5938\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5713 - val_loss: 0.6022\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5648 - val_loss: 0.5993\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5579 - val_loss: 0.5867\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5512 - val_loss: 0.6016\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5689 - val_loss: 0.5889\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5756 - val_loss: 0.6119\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5585 - val_loss: 0.5927\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5659 - val_loss: 0.5878\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5457 - val_loss: 0.5881\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5689 - val_loss: 0.6088\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5523 - val_loss: 0.5781\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5493 - val_loss: 0.5847\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.5474 - val_loss: 0.5991\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5598 - val_loss: 0.5838\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5613 - val_loss: 0.6048\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5584 - val_loss: 0.5870\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.5436 - val_loss: 0.5813\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5466 - val_loss: 0.5888\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5568 - val_loss: 0.5847\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5686 - val_loss: 0.5884\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5471 - val_loss: 0.5937\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5472 - val_loss: 0.5848\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5564 - val_loss: 0.5974\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5608 - val_loss: 0.6046\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5528 - val_loss: 0.5824\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5576 - val_loss: 0.5926\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5445 - val_loss: 0.5779\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5391 - val_loss: 0.5808\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5551 - val_loss: 0.5992\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5432 - val_loss: 0.5742\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5446 - val_loss: 0.5787\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5512 - val_loss: 0.5769\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5362 - val_loss: 0.5790\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5355 - val_loss: 0.5844\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5579 - val_loss: 0.5751\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5482 - val_loss: 0.5861\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5492 - val_loss: 0.5747\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5425 - val_loss: 0.5814\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5380 - val_loss: 0.5648\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5421 - val_loss: 0.5759\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5399 - val_loss: 0.5853\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5406 - val_loss: 0.5811\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5552 - val_loss: 0.5742\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5396 - val_loss: 0.5848\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5381 - val_loss: 0.5755\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5377 - val_loss: 0.5691\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5365 - val_loss: 0.5947\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5521 - val_loss: 0.5757\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5363 - val_loss: 0.5796\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5410 - val_loss: 0.5819\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.5475 - val_loss: 0.5858\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5386 - val_loss: 0.5770\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5447 - val_loss: 0.5726\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5378 - val_loss: 0.5853\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5411 - val_loss: 0.5713\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5282 - val_loss: 0.5734\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5463 - val_loss: 0.5787\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5342 - val_loss: 0.5599\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5318 - val_loss: 0.5629\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5317 - val_loss: 0.5876\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5511 - val_loss: 0.5608\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5395 - val_loss: 0.5776\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5329 - val_loss: 0.5566\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5401 - val_loss: 0.5671\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5414 - val_loss: 0.5654\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5312 - val_loss: 0.5795\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5385 - val_loss: 0.5695\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5302 - val_loss: 0.5671\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5313 - val_loss: 0.5877\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5396 - val_loss: 0.5666\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5286 - val_loss: 0.5701\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5388 - val_loss: 0.5618\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5314 - val_loss: 0.5837\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5361 - val_loss: 0.5579\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5335 - val_loss: 0.5683\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5375 - val_loss: 0.5658\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5473 - val_loss: 0.5607\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5356 - val_loss: 0.5695\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5344 - val_loss: 0.5770\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5271 - val_loss: 0.5677\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5286 - val_loss: 0.5603\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5262 - val_loss: 0.5730\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5412 - val_loss: 0.5559\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5324 - val_loss: 0.5625\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5281 - val_loss: 0.5759\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5316 - val_loss: 0.5663\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5364 - val_loss: 0.5786\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5297 - val_loss: 0.5596\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5197 - val_loss: 0.5576\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5307 - val_loss: 0.5761\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5316 - val_loss: 0.5732\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5262 - val_loss: 0.5595\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5236 - val_loss: 0.5527\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5208 - val_loss: 0.5564\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5236 - val_loss: 0.5551\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5331 - val_loss: 0.5700\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5290 - val_loss: 0.5645\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5242 - val_loss: 0.5612\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5313 - val_loss: 0.5577\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5313 - val_loss: 0.5571\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5196 - val_loss: 0.5656\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5340 - val_loss: 0.5718\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5305 - val_loss: 0.5605\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5182 - val_loss: 0.5715\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5337 - val_loss: 0.5845\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5392 - val_loss: 0.5594\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5300 - val_loss: 0.5578\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5188 - val_loss: 0.5639\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5265 - val_loss: 0.5551\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5200 - val_loss: 0.5431\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5224 - val_loss: 0.5554\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5231 - val_loss: 0.5596\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5229 - val_loss: 0.5578\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5185 - val_loss: 0.5563\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5255 - val_loss: 0.5638\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5275 - val_loss: 0.5538\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5194 - val_loss: 0.5491\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5228 - val_loss: 0.5748\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5312 - val_loss: 0.5617\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5284 - val_loss: 0.5628\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5250 - val_loss: 0.5463\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5182 - val_loss: 0.5482\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5225 - val_loss: 0.5571\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5172 - val_loss: 0.5541\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5231 - val_loss: 0.5601\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5225 - val_loss: 0.5598\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5298 - val_loss: 0.5596\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5248 - val_loss: 0.5508\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5119 - val_loss: 0.5466\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5129 - val_loss: 0.5501\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5195 - val_loss: 0.5522\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5264 - val_loss: 0.5423\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5180 - val_loss: 0.5467\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5170 - val_loss: 0.5517\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5179 - val_loss: 0.5441\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5135 - val_loss: 0.5478\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5130 - val_loss: 0.5771\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5195 - val_loss: 0.5594\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5154 - val_loss: 0.5554\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 963us/step - loss: 0.5172 - val_loss: 0.5663\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5203 - val_loss: 0.5387\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5108 - val_loss: 0.5472\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5217 - val_loss: 0.5507\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5122 - val_loss: 0.5485\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5157 - val_loss: 0.5406\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5230 - val_loss: 0.5463\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5121 - val_loss: 0.5407\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5105 - val_loss: 0.5402\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5128 - val_loss: 0.5361\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5233 - val_loss: 0.5367\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5088 - val_loss: 0.5419\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5135 - val_loss: 0.5556\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5172 - val_loss: 0.5457\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5129 - val_loss: 0.5510\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5184 - val_loss: 0.5435\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5234 - val_loss: 0.5436\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5163 - val_loss: 0.5539\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5098 - val_loss: 0.5455\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5179 - val_loss: 0.5719\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5217 - val_loss: 0.5375\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5145 - val_loss: 0.5398\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5120 - val_loss: 0.5402\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5104 - val_loss: 0.5388\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5171 - val_loss: 0.5516\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5169 - val_loss: 0.5372\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5108 - val_loss: 0.5502\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5093 - val_loss: 0.5457\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5155 - val_loss: 0.5355\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5173 - val_loss: 0.5568\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5266 - val_loss: 0.5446\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5129 - val_loss: 0.5350\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5107 - val_loss: 0.5544\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5251 - val_loss: 0.5540\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5134 - val_loss: 0.5381\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5094 - val_loss: 0.5411\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5044 - val_loss: 0.5475\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5109 - val_loss: 0.5389\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5159 - val_loss: 0.5402\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5223 - val_loss: 0.5416\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5096 - val_loss: 0.5361\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5092 - val_loss: 0.5476\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5069 - val_loss: 0.5420\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5053 - val_loss: 0.5467\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5115 - val_loss: 0.5393\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5194 - val_loss: 0.5455\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5126 - val_loss: 0.5426\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5148 - val_loss: 0.5465\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5125 - val_loss: 0.5408\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5112 - val_loss: 0.5353\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5051 - val_loss: 0.5401\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5143 - val_loss: 0.5381\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5099 - val_loss: 0.5401\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5038 - val_loss: 0.5401\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5090 - val_loss: 0.5501\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5089 - val_loss: 0.5340\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5032 - val_loss: 0.5364\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 763us/step - loss: 0.5008 - val_loss: 0.5383\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 755us/step - loss: 0.5049 - val_loss: 0.5360\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 732us/step - loss: 0.5070 - val_loss: 0.5501\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 756us/step - loss: 0.5020 - val_loss: 0.5786\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.5041 - val_loss: 0.5397\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 711us/step - loss: 0.5074 - val_loss: 0.5410\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 735us/step - loss: 0.5050 - val_loss: 0.5401\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 737us/step - loss: 0.5110 - val_loss: 0.5374\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 962us/step - loss: 0.5108 - val_loss: 0.5367\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.5170 - val_loss: 0.5571\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.5060 - val_loss: 0.5406\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.5130 - val_loss: 0.5376\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5044 - val_loss: 0.5429\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5113 - val_loss: 0.5515\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5101 - val_loss: 0.5363\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 718us/step - loss: 0.5139 - val_loss: 0.5377\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5051 - val_loss: 0.5347\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5040 - val_loss: 0.5372\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5122 - val_loss: 0.5632\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5109 - val_loss: 0.5391\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5023 - val_loss: 0.5414\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5107 - val_loss: 0.5416\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5059 - val_loss: 0.5390\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5074 - val_loss: 0.5415\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5111 - val_loss: 0.5391\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5006 - val_loss: 0.5390\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5099 - val_loss: 0.5541\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5076 - val_loss: 0.5419\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5070 - val_loss: 0.5429\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5111 - val_loss: 0.5504\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5096 - val_loss: 0.5318\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5120 - val_loss: 0.5396\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5119 - val_loss: 0.5364\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5067 - val_loss: 0.5349\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5070 - val_loss: 0.5382\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4994 - val_loss: 0.5299\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.4974 - val_loss: 0.5472\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4995 - val_loss: 0.5348\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5035 - val_loss: 0.5373\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5027 - val_loss: 0.5455\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5017 - val_loss: 0.5330\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5096 - val_loss: 0.5422\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5045 - val_loss: 0.5398\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4970 - val_loss: 0.5396\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4959 - val_loss: 0.5276\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.4962 - val_loss: 0.5401\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5097 - val_loss: 0.5671\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5120 - val_loss: 0.5434\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5056 - val_loss: 0.5384\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5025 - val_loss: 0.5408\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5003 - val_loss: 0.5336\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5084 - val_loss: 0.5427\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5048 - val_loss: 0.5286\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5048 - val_loss: 0.5320\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4947 - val_loss: 0.5272\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5026 - val_loss: 0.5367\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5001 - val_loss: 0.5382\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5034 - val_loss: 0.5471\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5002 - val_loss: 0.5320\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.4997 - val_loss: 0.5362\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5035 - val_loss: 0.5300\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4958 - val_loss: 0.5337\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5010 - val_loss: 0.5288\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5001 - val_loss: 0.5337\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.4999 - val_loss: 0.5258\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5020 - val_loss: 0.5297\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5066 - val_loss: 0.5409\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5029 - val_loss: 0.5338\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.5070 - val_loss: 0.5233\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.4965 - val_loss: 0.5292\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 731us/step - loss: 0.5027 - val_loss: 0.5357\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 772us/step - loss: 0.5015 - val_loss: 0.5398\n",
      "Epoch 390/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5009 - val_loss: 0.5485\n",
      "Epoch 391/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4979 - val_loss: 0.5444\n",
      "Epoch 392/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5052 - val_loss: 0.5395\n",
      "Epoch 393/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5017 - val_loss: 0.5383\n",
      "Epoch 394/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5206 - val_loss: 0.5479\n",
      "Epoch 395/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4945 - val_loss: 0.5300\n",
      "Epoch 396/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.4940 - val_loss: 0.5255\n",
      "Epoch 397/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5015 - val_loss: 0.5256\n",
      "Epoch 398/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.4971 - val_loss: 0.5324\n",
      "Epoch 399/3000\n",
      "33/33 [==============================] - 0s 756us/step - loss: 0.4936 - val_loss: 0.5396\n",
      "Epoch 400/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5039 - val_loss: 0.5322\n",
      "Epoch 401/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5032 - val_loss: 0.5312\n",
      "Epoch 402/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.4967 - val_loss: 0.5303\n",
      "Epoch 403/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.4978 - val_loss: 0.5319\n",
      "Epoch 404/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.4953 - val_loss: 0.5282\n",
      "Epoch 405/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4959 - val_loss: 0.5262\n",
      "Epoch 406/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5103 - val_loss: 0.5323\n",
      "Epoch 407/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4987 - val_loss: 0.5269\n",
      "Epoch 408/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.4954 - val_loss: 0.5370\n",
      "Epoch 409/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.4965 - val_loss: 0.5326\n",
      "Epoch 410/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4964 - val_loss: 0.5248\n",
      "Epoch 411/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4974 - val_loss: 0.5306\n",
      "Epoch 412/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4904 - val_loss: 0.5279\n",
      "Epoch 413/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4983 - val_loss: 0.5265\n",
      "Epoch 414/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.4967 - val_loss: 0.5285\n",
      "Epoch 415/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5000 - val_loss: 0.5247\n",
      "Epoch 416/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4887 - val_loss: 0.5253\n",
      "Epoch 417/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.4947 - val_loss: 0.5327\n",
      "Epoch 418/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.4888 - val_loss: 0.5332\n",
      "Epoch 419/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.4925 - val_loss: 0.5224\n",
      "Epoch 420/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.4953 - val_loss: 0.5257\n",
      "Epoch 421/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5037 - val_loss: 0.5260\n",
      "Epoch 422/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4948 - val_loss: 0.5247\n",
      "Epoch 423/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.4932 - val_loss: 0.5303\n",
      "Epoch 424/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.4973 - val_loss: 0.5326\n",
      "Epoch 425/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.4947 - val_loss: 0.5248\n",
      "Epoch 426/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4941 - val_loss: 0.5261\n",
      "Epoch 427/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5001 - val_loss: 0.5338\n",
      "Epoch 428/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4948 - val_loss: 0.5330\n",
      "Epoch 429/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4959 - val_loss: 0.5258\n",
      "Epoch 430/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.4956 - val_loss: 0.5296\n",
      "Epoch 431/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4941 - val_loss: 0.5272\n",
      "Epoch 432/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4979 - val_loss: 0.5316\n",
      "Epoch 433/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.4916 - val_loss: 0.5390\n",
      "Epoch 434/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.4960 - val_loss: 0.5311\n",
      "Epoch 435/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4958 - val_loss: 0.5233\n",
      "Epoch 436/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4908 - val_loss: 0.5270\n",
      "Epoch 437/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4884 - val_loss: 0.5251\n",
      "Epoch 438/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.4988 - val_loss: 0.5274\n",
      "Epoch 439/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4894 - val_loss: 0.5372\n",
      "Epoch 440/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.4977 - val_loss: 0.5228\n",
      "Epoch 441/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4940 - val_loss: 0.5235\n",
      "Epoch 442/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4912 - val_loss: 0.5198\n",
      "Epoch 443/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4904 - val_loss: 0.5320\n",
      "Epoch 444/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4887 - val_loss: 0.5179\n",
      "Epoch 445/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.4945 - val_loss: 0.5248\n",
      "Epoch 446/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4942 - val_loss: 0.5206\n",
      "Epoch 447/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.4865 - val_loss: 0.5190\n",
      "Epoch 448/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.4924 - val_loss: 0.5204\n",
      "Epoch 449/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.4957 - val_loss: 0.5315\n",
      "Epoch 450/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5006 - val_loss: 0.5208\n",
      "Epoch 451/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4943 - val_loss: 0.5231\n",
      "Epoch 452/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4983 - val_loss: 0.5244\n",
      "Epoch 453/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5004 - val_loss: 0.5201\n",
      "Epoch 454/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.4892 - val_loss: 0.5296\n",
      "Epoch 455/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.4880 - val_loss: 0.5235\n",
      "Epoch 456/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.4854 - val_loss: 0.5218\n",
      "Epoch 457/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4872 - val_loss: 0.5175\n",
      "Epoch 458/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4899 - val_loss: 0.5274\n",
      "Epoch 459/3000\n",
      "33/33 [==============================] - 0s 713us/step - loss: 0.4873 - val_loss: 0.5294\n",
      "Epoch 460/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.4825 - val_loss: 0.5357\n",
      "Epoch 461/3000\n",
      "33/33 [==============================] - 0s 703us/step - loss: 0.4932 - val_loss: 0.5350\n",
      "Epoch 462/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4916 - val_loss: 0.5330\n",
      "Epoch 463/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.4915 - val_loss: 0.5299\n",
      "Epoch 464/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.4942 - val_loss: 0.5247\n",
      "Epoch 465/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4872 - val_loss: 0.5174\n",
      "Epoch 466/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4874 - val_loss: 0.5348\n",
      "Epoch 467/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.4953 - val_loss: 0.5166\n",
      "Epoch 468/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4869 - val_loss: 0.5241\n",
      "Epoch 469/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4884 - val_loss: 0.5266\n",
      "Epoch 470/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.4890 - val_loss: 0.5170\n",
      "Epoch 471/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5019 - val_loss: 0.5235\n",
      "Epoch 472/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4844 - val_loss: 0.5166\n",
      "Epoch 473/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4955 - val_loss: 0.5268\n",
      "Epoch 474/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.4917 - val_loss: 0.5359\n",
      "Epoch 475/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.4893 - val_loss: 0.5260\n",
      "Epoch 476/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4931 - val_loss: 0.5237\n",
      "Epoch 477/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.4887 - val_loss: 0.5219\n",
      "Epoch 478/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4849 - val_loss: 0.5166\n",
      "Epoch 479/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.4856 - val_loss: 0.5194\n",
      "Epoch 480/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.4864 - val_loss: 0.5290\n",
      "Epoch 481/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.4915 - val_loss: 0.5308\n",
      "Epoch 482/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4952 - val_loss: 0.5187\n",
      "Epoch 483/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.4889 - val_loss: 0.5164\n",
      "Epoch 484/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.4826 - val_loss: 0.5214\n",
      "Epoch 485/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4888 - val_loss: 0.5193\n",
      "Epoch 486/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.4883 - val_loss: 0.5305\n",
      "Epoch 487/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.4921 - val_loss: 0.5244\n",
      "Epoch 488/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.4897 - val_loss: 0.5285\n",
      "Epoch 489/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4825 - val_loss: 0.5199\n",
      "Epoch 490/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.4819 - val_loss: 0.5324\n",
      "Epoch 491/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.4893 - val_loss: 0.5195\n",
      "Epoch 492/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4833 - val_loss: 0.5200\n",
      "Epoch 493/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.4874 - val_loss: 0.5182\n",
      "Epoch 494/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5005 - val_loss: 0.5252\n",
      "Epoch 495/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4873 - val_loss: 0.5320\n",
      "Epoch 496/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4861 - val_loss: 0.5169\n",
      "Epoch 497/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.4835 - val_loss: 0.5363\n",
      "Epoch 498/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.4943 - val_loss: 0.5168\n",
      "Epoch 499/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.4864 - val_loss: 0.5285\n",
      "Epoch 500/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.4867 - val_loss: 0.5276\n",
      "Epoch 501/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.4940 - val_loss: 0.5215\n",
      "Epoch 502/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4817 - val_loss: 0.5190\n",
      "Epoch 503/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4928 - val_loss: 0.5250\n",
      "Epoch 504/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.4855 - val_loss: 0.5361\n",
      "Epoch 505/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.4827 - val_loss: 0.5251\n",
      "Epoch 506/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4842 - val_loss: 0.5314\n",
      "Epoch 507/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4923 - val_loss: 0.5408\n",
      "Epoch 508/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.4908 - val_loss: 0.5231\n",
      "Epoch 509/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.4914 - val_loss: 0.5191\n",
      "Epoch 510/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.4925 - val_loss: 0.5334\n",
      "Epoch 511/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.4878 - val_loss: 0.5154\n",
      "Epoch 512/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.4866 - val_loss: 0.5190\n",
      "Epoch 513/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4840 - val_loss: 0.5191\n",
      "Epoch 514/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4820 - val_loss: 0.5182\n",
      "Epoch 515/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.4838 - val_loss: 0.5118\n",
      "Epoch 516/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.4868 - val_loss: 0.5144\n",
      "Epoch 517/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4940 - val_loss: 0.5172\n",
      "Epoch 518/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.4845 - val_loss: 0.5157\n",
      "Epoch 519/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.4800 - val_loss: 0.5205\n",
      "Epoch 520/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.4810 - val_loss: 0.5228\n",
      "Epoch 521/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.4783 - val_loss: 0.5245\n",
      "Epoch 522/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.4854 - val_loss: 0.5182\n",
      "Epoch 523/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4829 - val_loss: 0.5173\n",
      "Epoch 524/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.4888 - val_loss: 0.5299\n",
      "Epoch 525/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.4818 - val_loss: 0.5338\n",
      "Epoch 526/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.4797 - val_loss: 0.5203\n",
      "Epoch 527/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.4850 - val_loss: 0.5148\n",
      "Epoch 528/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.4825 - val_loss: 0.5157\n",
      "Epoch 529/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.4833 - val_loss: 0.5202\n",
      "Epoch 530/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.4877 - val_loss: 0.5165\n",
      "Epoch 531/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4840 - val_loss: 0.5158\n",
      "Epoch 532/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.4825 - val_loss: 0.5157\n",
      "Epoch 533/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4841 - val_loss: 0.5146\n",
      "Epoch 534/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.4793 - val_loss: 0.5219\n",
      "Epoch 535/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.4843 - val_loss: 0.5160\n",
      "Epoch 536/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.4820 - val_loss: 0.5311\n",
      "Epoch 537/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.4815 - val_loss: 0.5174\n",
      "Epoch 538/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.4819 - val_loss: 0.5239\n",
      "Epoch 539/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.4886 - val_loss: 0.5123\n",
      "Epoch 540/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.4818 - val_loss: 0.5172\n",
      "Epoch 541/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.4852 - val_loss: 0.5163\n",
      "Epoch 542/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.4791 - val_loss: 0.5188\n",
      "Epoch 543/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4794 - val_loss: 0.5215\n",
      "Epoch 544/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4822 - val_loss: 0.5254\n",
      "Epoch 545/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4861 - val_loss: 0.5234\n",
      "Epoch 546/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.4795 - val_loss: 0.5185\n",
      "Epoch 547/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.4786 - val_loss: 0.5159\n",
      "Epoch 548/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.4837 - val_loss: 0.5236\n",
      "Epoch 549/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.4889 - val_loss: 0.5248\n",
      "Epoch 550/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.4864 - val_loss: 0.5180\n",
      "Epoch 551/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.4938 - val_loss: 0.5201\n",
      "Epoch 552/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.4998 - val_loss: 0.5257\n",
      "Epoch 553/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.4845 - val_loss: 0.5171\n",
      "Epoch 554/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.4783 - val_loss: 0.5182\n",
      "Epoch 555/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.4958 - val_loss: 0.5411\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.1760 - val_loss: 3.3553\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 1.8742 - val_loss: 1.6712\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 1.3220 - val_loss: 1.3889\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 1.2009 - val_loss: 1.3916\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 717us/step - loss: 1.1313 - val_loss: 1.2737\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 1.0955 - val_loss: 1.2065\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 1.0488 - val_loss: 1.2396\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 1.0291 - val_loss: 1.1529\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 1.0135 - val_loss: 1.0198\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.9921 - val_loss: 1.1833\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.9719 - val_loss: 1.0600\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.9645 - val_loss: 1.2583\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.9484 - val_loss: 0.9536\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.9208 - val_loss: 1.0841\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.9290 - val_loss: 1.0803\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.9117 - val_loss: 0.8922\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.8933 - val_loss: 0.9826\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.8694 - val_loss: 0.9278\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.8506 - val_loss: 0.8967\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.8495 - val_loss: 1.0800\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.8394 - val_loss: 0.9540\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.8304 - val_loss: 1.0455\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.8169 - val_loss: 0.9485\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.7986 - val_loss: 0.8916\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.7903 - val_loss: 0.8323\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.7790 - val_loss: 0.8216\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.7740 - val_loss: 0.8579\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.7546 - val_loss: 0.9177\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.7611 - val_loss: 0.7802\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.7412 - val_loss: 0.8020\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.7406 - val_loss: 0.8397\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.7332 - val_loss: 0.7945\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.7166 - val_loss: 0.8609\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.7182 - val_loss: 0.8181\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.7175 - val_loss: 0.8513\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.7074 - val_loss: 0.7973\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.7015 - val_loss: 0.7874\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6856 - val_loss: 0.8052\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6894 - val_loss: 0.7669\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.6759 - val_loss: 0.7716\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6800 - val_loss: 0.7599\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6798 - val_loss: 0.7491\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6679 - val_loss: 0.7831\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.6783 - val_loss: 0.7631\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6685 - val_loss: 0.7921\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6600 - val_loss: 0.8394\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6555 - val_loss: 0.7485\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.6498 - val_loss: 0.7439\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6585 - val_loss: 0.7679\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.6567 - val_loss: 0.7728\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.6554 - val_loss: 0.7511\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6390 - val_loss: 0.8022\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6712 - val_loss: 0.7866\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.6394 - val_loss: 0.7174\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 728us/step - loss: 0.6414 - val_loss: 0.7954\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.6484 - val_loss: 0.7989\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 723us/step - loss: 0.6486 - val_loss: 0.7276\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 763us/step - loss: 0.6412 - val_loss: 0.7307\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.6314 - val_loss: 0.7127\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 729us/step - loss: 0.6259 - val_loss: 0.7513\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6284 - val_loss: 0.7367\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.6374 - val_loss: 0.7469\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 702us/step - loss: 0.6197 - val_loss: 0.7088\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 986us/step - loss: 0.6228 - val_loss: 0.7120\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.6191 - val_loss: 0.7268\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.6194 - val_loss: 0.7076\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.6320 - val_loss: 0.7379\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.6245 - val_loss: 0.7403\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 703us/step - loss: 0.6246 - val_loss: 0.6943\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 709us/step - loss: 0.6091 - val_loss: 0.7185\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 727us/step - loss: 0.6402 - val_loss: 0.6969\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6137 - val_loss: 0.7144\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6078 - val_loss: 0.7367\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.6079 - val_loss: 0.6865\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6080 - val_loss: 0.7510\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6148 - val_loss: 0.7347\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6148 - val_loss: 0.7500\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.6099 - val_loss: 0.6934\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6203 - val_loss: 0.7183\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5992 - val_loss: 0.6744\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.6045 - val_loss: 0.7062\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6087 - val_loss: 0.6699\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6054 - val_loss: 0.6960\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6033 - val_loss: 0.7365\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6134 - val_loss: 0.7374\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6186 - val_loss: 0.6848\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.6054 - val_loss: 0.6771\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5992 - val_loss: 0.6663\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6019 - val_loss: 0.7251\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6226 - val_loss: 0.6730\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.6177 - val_loss: 0.6713\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5938 - val_loss: 0.6744\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5888 - val_loss: 0.6869\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5943 - val_loss: 0.6612\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5973 - val_loss: 0.6652\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5893 - val_loss: 0.6612\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5917 - val_loss: 0.7112\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5960 - val_loss: 0.6685\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5939 - val_loss: 0.6665\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6780\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 746us/step - loss: 0.6005 - val_loss: 0.6694\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 744us/step - loss: 0.5931 - val_loss: 0.7463\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.5908 - val_loss: 0.6624\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5858 - val_loss: 0.6626\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.6010 - val_loss: 0.6831\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5859 - val_loss: 0.6320\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5823 - val_loss: 0.6513\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5848 - val_loss: 0.6336\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 736us/step - loss: 0.5872 - val_loss: 0.6712\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 731us/step - loss: 0.6002 - val_loss: 0.7302\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 737us/step - loss: 0.5917 - val_loss: 0.6504\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5895 - val_loss: 0.6801\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5956 - val_loss: 0.7212\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5919 - val_loss: 0.6568\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5850 - val_loss: 0.6506\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5872 - val_loss: 0.6812\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5812 - val_loss: 0.6500\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5870 - val_loss: 0.6526\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5976 - val_loss: 0.6566\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5843 - val_loss: 0.6893\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5912 - val_loss: 0.6379\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5868 - val_loss: 0.6622\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5802 - val_loss: 0.6633\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5741 - val_loss: 0.6411\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 796us/step - loss: 0.5838 - val_loss: 0.6331\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5829 - val_loss: 0.6372\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5778 - val_loss: 0.6652\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5787 - val_loss: 0.6851\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5893 - val_loss: 0.7056\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5828 - val_loss: 0.6527\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5829 - val_loss: 0.6595\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5892 - val_loss: 0.6806\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5705 - val_loss: 0.6482\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5678 - val_loss: 0.6352\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 738us/step - loss: 0.5805 - val_loss: 0.6677\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5712 - val_loss: 0.6181\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5721 - val_loss: 0.6480\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5900 - val_loss: 0.6172\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5893 - val_loss: 0.7132\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5829 - val_loss: 0.6572\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5792 - val_loss: 0.6210\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5706 - val_loss: 0.6416\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5701 - val_loss: 0.6739\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5828 - val_loss: 0.6457\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5645 - val_loss: 0.6371\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5691 - val_loss: 0.6898\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5698 - val_loss: 0.6250\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5634 - val_loss: 0.6840\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5804 - val_loss: 0.6785\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5692 - val_loss: 0.6090\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5638 - val_loss: 0.6506\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5809 - val_loss: 0.6542\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5776 - val_loss: 0.6374\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5729 - val_loss: 0.6144\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5774 - val_loss: 0.6996\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 718us/step - loss: 0.5726 - val_loss: 0.6232\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5716 - val_loss: 0.6627\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5749 - val_loss: 0.6498\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5648 - val_loss: 0.6848\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5712 - val_loss: 0.6771\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5730 - val_loss: 0.6617\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5680 - val_loss: 0.6195\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5649 - val_loss: 0.6296\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5638 - val_loss: 0.6395\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5642 - val_loss: 0.6332\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5603 - val_loss: 0.6756\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5580 - val_loss: 0.6390\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5605 - val_loss: 0.6361\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5793 - val_loss: 0.7211\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5679 - val_loss: 0.6530\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5779 - val_loss: 0.6759\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5718 - val_loss: 0.6987\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5587 - val_loss: 0.6737\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5666 - val_loss: 0.6141\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5659 - val_loss: 0.6231\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5641 - val_loss: 0.6488\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5679 - val_loss: 0.6321\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5643 - val_loss: 0.6506\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5615 - val_loss: 0.6303\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5646 - val_loss: 0.6230\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5742 - val_loss: 0.6108\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5590 - val_loss: 0.6506\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5584 - val_loss: 0.6269\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5686 - val_loss: 0.6634\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5665 - val_loss: 0.6250\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5606 - val_loss: 0.6925\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5590 - val_loss: 0.6242\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5526 - val_loss: 0.6157\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5562 - val_loss: 0.6376\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 969us/step - loss: 0.5621 - val_loss: 0.6237\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 6.8271 - val_loss: 3.6189\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 2.0915 - val_loss: 1.6176\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 1.3651 - val_loss: 1.2367\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 1.1709 - val_loss: 1.2376\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 1.0829 - val_loss: 1.1213\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 1.0186 - val_loss: 1.1633\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.9893 - val_loss: 1.0847\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.9653 - val_loss: 1.1685\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.9520 - val_loss: 1.0739\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.9146 - val_loss: 1.0287\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.9068 - val_loss: 1.0436\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.8935 - val_loss: 1.0417\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 718us/step - loss: 0.8938 - val_loss: 0.9825\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.8764 - val_loss: 0.9777\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.8496 - val_loss: 0.9770\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.8463 - val_loss: 0.9510\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.8491 - val_loss: 0.9337\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.8281 - val_loss: 0.9536\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.8139 - val_loss: 0.9380\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.8145 - val_loss: 0.8978\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.8172 - val_loss: 0.8753\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.7747 - val_loss: 0.8635\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.7749 - val_loss: 0.8864\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.7860 - val_loss: 0.8707\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.7603 - val_loss: 0.8548\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.7588 - val_loss: 0.8531\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.7536 - val_loss: 0.8649\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.7467 - val_loss: 0.8103\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.7652 - val_loss: 0.8121\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.7320 - val_loss: 0.8286\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.7301 - val_loss: 0.8069\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.7213 - val_loss: 0.7913\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7280 - val_loss: 0.7987\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.7025 - val_loss: 0.7674\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.7052 - val_loss: 0.8081\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.7013 - val_loss: 0.8026\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.6996 - val_loss: 0.7954\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6865 - val_loss: 0.7542\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.6833 - val_loss: 0.7372\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6801 - val_loss: 0.7394\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6689 - val_loss: 0.7468\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.6648 - val_loss: 0.7317\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6691 - val_loss: 0.8022\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.6855 - val_loss: 0.7790\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6705 - val_loss: 0.7303\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.6605 - val_loss: 0.7546\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6489 - val_loss: 0.7280\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6628 - val_loss: 0.7406\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6530 - val_loss: 0.7429\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.6586 - val_loss: 0.7396\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.6422 - val_loss: 0.7512\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.6493 - val_loss: 0.7604\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.6404 - val_loss: 0.7026\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6402 - val_loss: 0.6940\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6403 - val_loss: 0.7054\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6398 - val_loss: 0.7121\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6432 - val_loss: 0.7279\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6276 - val_loss: 0.6842\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6333 - val_loss: 0.6871\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6269 - val_loss: 0.6989\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.6268 - val_loss: 0.7169\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6357 - val_loss: 0.7082\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6294 - val_loss: 0.6934\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6285 - val_loss: 0.6728\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.6184 - val_loss: 0.6765\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6278 - val_loss: 0.6776\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6195 - val_loss: 0.6796\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.6161 - val_loss: 0.7025\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6102 - val_loss: 0.6842\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.6209 - val_loss: 0.6810\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.6121 - val_loss: 0.6703\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6080 - val_loss: 0.6554\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.6083 - val_loss: 0.6670\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5933 - val_loss: 0.6774\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6217 - val_loss: 0.6786\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.6124 - val_loss: 0.6783\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6162 - val_loss: 0.6716\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6234 - val_loss: 0.6965\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6131 - val_loss: 0.6719\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5914 - val_loss: 0.6781\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.6017 - val_loss: 0.6888\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.6012 - val_loss: 0.6663\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5904 - val_loss: 0.6538\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6235 - val_loss: 0.6820\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6145 - val_loss: 0.6622\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 866us/step - loss: 0.5994 - val_loss: 0.6670\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 789us/step - loss: 0.5923 - val_loss: 0.6585\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 708us/step - loss: 0.5926 - val_loss: 0.7033\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 714us/step - loss: 0.6000 - val_loss: 0.7059\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.6112 - val_loss: 0.7054\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6097 - val_loss: 0.6594\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.6129 - val_loss: 0.6710\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5949 - val_loss: 0.6927\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5977 - val_loss: 0.6512\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5824 - val_loss: 0.6490\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5902 - val_loss: 0.6585\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5892 - val_loss: 0.6546\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5973 - val_loss: 0.6731\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5819 - val_loss: 0.6670\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5942 - val_loss: 0.6935\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5740 - val_loss: 0.6598\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5924 - val_loss: 0.6509\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 725us/step - loss: 0.5946 - val_loss: 0.6488\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.5791 - val_loss: 0.6443\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5868 - val_loss: 0.7423\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5881 - val_loss: 0.6656\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5989 - val_loss: 0.6747\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5808 - val_loss: 0.6629\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5844 - val_loss: 0.6523\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5771 - val_loss: 0.6349\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5699 - val_loss: 0.6545\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5813 - val_loss: 0.6567\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5818 - val_loss: 0.6653\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5798 - val_loss: 0.6494\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 918us/step - loss: 0.5803 - val_loss: 0.6404\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5707 - val_loss: 0.6632\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 886us/step - loss: 0.5702 - val_loss: 0.6551\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5646 - val_loss: 0.6611\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5778 - val_loss: 0.6540\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5775 - val_loss: 0.6470\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5730 - val_loss: 0.6468\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5760 - val_loss: 0.6452\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5725 - val_loss: 0.6296\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5667 - val_loss: 0.6383\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5698 - val_loss: 0.6492\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5750 - val_loss: 0.6391\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5703 - val_loss: 0.6436\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5648 - val_loss: 0.6644\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5611 - val_loss: 0.6276\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5634 - val_loss: 0.6542\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5678 - val_loss: 0.6510\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5625 - val_loss: 0.6163\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5678 - val_loss: 0.6306\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5648 - val_loss: 0.6624\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5660 - val_loss: 0.6523\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.5729 - val_loss: 0.6454\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5721 - val_loss: 0.6786\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5765 - val_loss: 0.6313\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5540 - val_loss: 0.6389\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5637 - val_loss: 0.6499\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5762 - val_loss: 0.6243\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5641 - val_loss: 0.6279\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5703 - val_loss: 0.6351\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5806 - val_loss: 0.6708\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5661 - val_loss: 0.6457\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5600 - val_loss: 0.6178\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5513 - val_loss: 0.6341\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5602 - val_loss: 0.6203\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 729us/step - loss: 0.5597 - val_loss: 0.6188\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 721us/step - loss: 0.5614 - val_loss: 0.6567\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 703us/step - loss: 0.5707 - val_loss: 0.6469\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 735us/step - loss: 0.5705 - val_loss: 0.6179\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 794us/step - loss: 0.5727 - val_loss: 0.6232\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 770us/step - loss: 0.5633 - val_loss: 0.6252\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 723us/step - loss: 0.5651 - val_loss: 0.7363\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 753us/step - loss: 0.5770 - val_loss: 0.6373\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 739us/step - loss: 0.5629 - val_loss: 0.6277\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5733 - val_loss: 0.6560\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 882us/step - loss: 0.5640 - val_loss: 0.6150\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 786us/step - loss: 0.5540 - val_loss: 0.6236\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 731us/step - loss: 0.5650 - val_loss: 0.6400\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.5560 - val_loss: 0.6116\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.5534 - val_loss: 0.6391\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 741us/step - loss: 0.5525 - val_loss: 0.6390\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5659 - val_loss: 0.6423\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 707us/step - loss: 0.5502 - val_loss: 0.6024\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5459 - val_loss: 0.6346\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5590 - val_loss: 0.6534\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5648 - val_loss: 0.6411\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5766 - val_loss: 0.6156\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5549 - val_loss: 0.6485\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5446 - val_loss: 0.6249\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5496 - val_loss: 0.6381\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5514 - val_loss: 0.6095\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5565 - val_loss: 0.6573\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5544 - val_loss: 0.6177\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5584 - val_loss: 0.6083\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5460 - val_loss: 0.6233\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5525 - val_loss: 0.6429\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5649 - val_loss: 0.6214\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5637 - val_loss: 0.6483\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5601 - val_loss: 0.6797\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5651 - val_loss: 0.6102\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5493 - val_loss: 0.6198\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5447 - val_loss: 0.6095\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5472 - val_loss: 0.6064\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5385 - val_loss: 0.6078\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5457 - val_loss: 0.6244\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5455 - val_loss: 0.6066\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5523 - val_loss: 0.6267\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5585 - val_loss: 0.6453\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5511 - val_loss: 0.6089\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5395 - val_loss: 0.6083\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5414 - val_loss: 0.6310\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5416 - val_loss: 0.6402\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5417 - val_loss: 0.6198\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5376 - val_loss: 0.6252\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5447 - val_loss: 0.6174\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5506 - val_loss: 0.6337\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5419 - val_loss: 0.6083\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5353 - val_loss: 0.6188\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5467 - val_loss: 0.6232\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5530 - val_loss: 0.6546\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5446 - val_loss: 0.6011\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5442 - val_loss: 0.6184\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5413 - val_loss: 0.6041\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5559 - val_loss: 0.6193\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5395 - val_loss: 0.6223\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5395 - val_loss: 0.6030\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5353 - val_loss: 0.6134\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5336 - val_loss: 0.6307\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5526 - val_loss: 0.6487\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5339 - val_loss: 0.6274\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5392 - val_loss: 0.6028\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 732us/step - loss: 0.5510 - val_loss: 0.6189\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5379 - val_loss: 0.6331\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5414 - val_loss: 0.6439\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5429 - val_loss: 0.6001\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5400 - val_loss: 0.6197\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5411 - val_loss: 0.6086\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5413 - val_loss: 0.6265\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5365 - val_loss: 0.6562\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5453 - val_loss: 0.6438\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 789us/step - loss: 0.5407 - val_loss: 0.6247\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5369 - val_loss: 0.6106\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5391 - val_loss: 0.5927\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5419 - val_loss: 0.6302\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5449 - val_loss: 0.6157\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5439 - val_loss: 0.6507\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5381 - val_loss: 0.5945\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5314 - val_loss: 0.6215\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5357 - val_loss: 0.6472\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5390 - val_loss: 0.6083\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5317 - val_loss: 0.6170\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5493 - val_loss: 0.6185\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5381 - val_loss: 0.6188\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5314 - val_loss: 0.6171\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5424 - val_loss: 0.6159\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5387 - val_loss: 0.6185\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5433 - val_loss: 0.6076\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5516 - val_loss: 0.5958\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5395 - val_loss: 0.6336\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5301 - val_loss: 0.6061\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5230 - val_loss: 0.6108\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5368 - val_loss: 0.6167\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.5392 - val_loss: 0.6047\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5351 - val_loss: 0.6083\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5346 - val_loss: 0.6224\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5318 - val_loss: 0.6209\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5254 - val_loss: 0.6000\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5423 - val_loss: 0.6452\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5407 - val_loss: 0.6131\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5279 - val_loss: 0.5966\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5363 - val_loss: 0.5990\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5228 - val_loss: 0.6149\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5396 - val_loss: 0.6278\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5455 - val_loss: 0.6003\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5380 - val_loss: 0.6016\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5324 - val_loss: 0.6008\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5253 - val_loss: 0.6014\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5469 - val_loss: 0.6336\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5450 - val_loss: 0.5955\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5260 - val_loss: 0.5961\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5432 - val_loss: 0.6495\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5481 - val_loss: 0.6006\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5404 - val_loss: 0.6152\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0719 - val_loss: 2.5419\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 2.1074 - val_loss: 1.4690\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 1.4011 - val_loss: 1.0487\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 1.1906 - val_loss: 0.9592\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 1.0875 - val_loss: 0.9237\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 1.0261 - val_loss: 0.8563\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.9919 - val_loss: 0.8632\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.9950 - val_loss: 0.8421\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.9470 - val_loss: 0.8716\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.9397 - val_loss: 0.8122\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.9028 - val_loss: 0.7982\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.8835 - val_loss: 0.7759\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.8667 - val_loss: 0.8306\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.8496 - val_loss: 0.8218\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.8521 - val_loss: 0.7985\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.8450 - val_loss: 0.8054\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.8235 - val_loss: 0.7572\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.8124 - val_loss: 0.8118\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.7950 - val_loss: 0.7844\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.7829 - val_loss: 0.7994\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.7793 - val_loss: 0.7309\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 724us/step - loss: 0.7901 - val_loss: 0.7048\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.7534 - val_loss: 0.7553\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.7380 - val_loss: 0.6948\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.7308 - val_loss: 0.7088\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.7204 - val_loss: 0.7096\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.7169 - val_loss: 0.6646\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.7139 - val_loss: 0.7287\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.7067 - val_loss: 0.6928\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.6997 - val_loss: 0.6684\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6988 - val_loss: 0.7020\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6800 - val_loss: 0.6858\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6787 - val_loss: 0.6993\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6751 - val_loss: 0.6741\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.6752 - val_loss: 0.6688\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6836 - val_loss: 0.7275\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6719 - val_loss: 0.6936\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6732 - val_loss: 0.6414\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.6708 - val_loss: 0.6616\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.6669 - val_loss: 0.6429\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.6607 - val_loss: 0.6910\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.6704 - val_loss: 0.6462\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6476 - val_loss: 0.6307\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6534 - val_loss: 0.6111\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6475 - val_loss: 0.6451\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.6459 - val_loss: 0.6290\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6370 - val_loss: 0.6401\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6321 - val_loss: 0.6031\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6282 - val_loss: 0.6109\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.6341 - val_loss: 0.5983\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.6394 - val_loss: 0.6180\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6340 - val_loss: 0.6180\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.6211 - val_loss: 0.5980\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6220 - val_loss: 0.6177\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.6309 - val_loss: 0.6094\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6279 - val_loss: 0.6160\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6191 - val_loss: 0.6006\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6142 - val_loss: 0.6027\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6284 - val_loss: 0.6310\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.6189 - val_loss: 0.6214\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6157 - val_loss: 0.5916\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6202 - val_loss: 0.6173\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6253 - val_loss: 0.6144\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6264 - val_loss: 0.5789\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.6076 - val_loss: 0.6131\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.6079 - val_loss: 0.5993\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6117 - val_loss: 0.6114\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6036 - val_loss: 0.5834\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.6041 - val_loss: 0.5973\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5997 - val_loss: 0.5936\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6012 - val_loss: 0.5859\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 707us/step - loss: 0.6030 - val_loss: 0.6385\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5992 - val_loss: 0.5727\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6046 - val_loss: 0.5745\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5925 - val_loss: 0.5983\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5958 - val_loss: 0.5976\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5982 - val_loss: 0.5831\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5973 - val_loss: 0.5832\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5881 - val_loss: 0.5974\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5855 - val_loss: 0.5828\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5947 - val_loss: 0.5796\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.6072 - val_loss: 0.5971\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6019 - val_loss: 0.5994\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5909 - val_loss: 0.5794\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5935 - val_loss: 0.5744\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5893 - val_loss: 0.5651\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5946 - val_loss: 0.5823\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5933 - val_loss: 0.5820\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5869 - val_loss: 0.6031\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5845 - val_loss: 0.5750\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5879 - val_loss: 0.5783\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5888 - val_loss: 0.6006\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5828 - val_loss: 0.5820\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5850 - val_loss: 0.5826\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5824 - val_loss: 0.5823\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5888 - val_loss: 0.5708\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5815 - val_loss: 0.5756\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5801 - val_loss: 0.6061\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.5967 - val_loss: 0.6221\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5865 - val_loss: 0.5709\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5955 - val_loss: 0.5793\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5830 - val_loss: 0.5861\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5769 - val_loss: 0.5737\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5763 - val_loss: 0.5615\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5809 - val_loss: 0.5555\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5713 - val_loss: 0.5738\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5704 - val_loss: 0.5699\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5781 - val_loss: 0.5760\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5736 - val_loss: 0.5731\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5743 - val_loss: 0.5569\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5766 - val_loss: 0.5766\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5785 - val_loss: 0.5469\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5719 - val_loss: 0.5962\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5683 - val_loss: 0.5682\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5858 - val_loss: 0.5944\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5747 - val_loss: 0.5751\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5803 - val_loss: 0.5661\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5741 - val_loss: 0.5709\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5639 - val_loss: 0.5503\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5770 - val_loss: 0.5649\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5720 - val_loss: 0.5639\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5702 - val_loss: 0.6141\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5709 - val_loss: 0.5573\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 769us/step - loss: 0.5648 - val_loss: 0.5383\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5603 - val_loss: 0.5622\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5819 - val_loss: 0.5955\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5789 - val_loss: 0.5595\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5666 - val_loss: 0.6299\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5742 - val_loss: 0.5623\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5598 - val_loss: 0.6065\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5735 - val_loss: 0.5446\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5609 - val_loss: 0.5720\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5667 - val_loss: 0.5521\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5606 - val_loss: 0.5475\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5732 - val_loss: 0.5724\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5579 - val_loss: 0.5495\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5557 - val_loss: 0.5679\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5637 - val_loss: 0.5450\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5678 - val_loss: 0.5525\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5629 - val_loss: 0.5591\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5769 - val_loss: 0.5808\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5585 - val_loss: 0.5564\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5623 - val_loss: 0.5412\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5690 - val_loss: 0.5399\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5630 - val_loss: 0.5720\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5564 - val_loss: 0.5536\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5549 - val_loss: 0.5772\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5672 - val_loss: 0.5375\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5548 - val_loss: 0.5340\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5593 - val_loss: 0.5330\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5592 - val_loss: 0.5410\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5525 - val_loss: 0.5430\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 743us/step - loss: 0.5657 - val_loss: 0.5387\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5587 - val_loss: 0.5804\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 777us/step - loss: 0.5560 - val_loss: 0.5296\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 727us/step - loss: 0.5531 - val_loss: 0.5465\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 712us/step - loss: 0.5548 - val_loss: 0.5476\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 737us/step - loss: 0.5567 - val_loss: 0.5402\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 741us/step - loss: 0.5491 - val_loss: 0.5426\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 740us/step - loss: 0.5516 - val_loss: 0.5609\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 785us/step - loss: 0.5534 - val_loss: 0.5376\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 860us/step - loss: 0.5503 - val_loss: 0.5495\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 756us/step - loss: 0.5569 - val_loss: 0.5419\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5484 - val_loss: 0.5436\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 737us/step - loss: 0.5469 - val_loss: 0.5566\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5497 - val_loss: 0.5534\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5620 - val_loss: 0.5529\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.5565 - val_loss: 0.5621\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5630 - val_loss: 0.5652\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5586 - val_loss: 0.5457\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5544 - val_loss: 0.5494\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5440 - val_loss: 0.5360\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5584 - val_loss: 0.5549\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5505 - val_loss: 0.5343\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5468 - val_loss: 0.5629\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5562 - val_loss: 0.5438\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5495 - val_loss: 0.5385\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5506 - val_loss: 0.5357\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5467 - val_loss: 0.5304\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5553 - val_loss: 0.5627\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5501 - val_loss: 0.5387\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5517 - val_loss: 0.5479\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5508 - val_loss: 0.5255\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5407 - val_loss: 0.5381\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5429 - val_loss: 0.5187\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5509 - val_loss: 0.5542\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5540 - val_loss: 0.5261\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5447 - val_loss: 0.5799\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5507 - val_loss: 0.5542\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5587 - val_loss: 0.5389\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5584 - val_loss: 0.5487\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5508 - val_loss: 0.5519\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5465 - val_loss: 0.5273\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5403 - val_loss: 0.5324\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5493 - val_loss: 0.5526\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5539 - val_loss: 0.5410\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5548 - val_loss: 0.5356\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5434 - val_loss: 0.5263\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5506 - val_loss: 0.5455\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5458 - val_loss: 0.5350\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5449 - val_loss: 0.5447\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5510 - val_loss: 0.5615\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5519 - val_loss: 0.5427\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5434 - val_loss: 0.5520\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5483 - val_loss: 0.5378\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5425 - val_loss: 0.5429\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5568 - val_loss: 0.5689\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5438 - val_loss: 0.5474\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5540 - val_loss: 0.5850\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5541 - val_loss: 0.5456\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5400 - val_loss: 0.5523\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5545 - val_loss: 0.5742\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5490 - val_loss: 0.5199\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5407 - val_loss: 0.5370\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5353 - val_loss: 0.5289\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5472 - val_loss: 0.5440\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 770us/step - loss: 0.5419 - val_loss: 0.5662\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5391 - val_loss: 0.5219\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5372 - val_loss: 0.5451\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5459 - val_loss: 0.5284\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5455 - val_loss: 0.5442\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5399 - val_loss: 0.5473\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5483 - val_loss: 0.5366\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5371 - val_loss: 0.5275\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5410 - val_loss: 0.5432\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.0461 - val_loss: 2.5255\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 717us/step - loss: 1.9089 - val_loss: 1.2696\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 1.3507 - val_loss: 1.0078\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 1.1630 - val_loss: 0.9809\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 1.1143 - val_loss: 1.0444\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 1.0600 - val_loss: 0.9291\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 1.0712 - val_loss: 1.0325\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 1.0117 - val_loss: 0.9373\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 1.0047 - val_loss: 0.8881\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.9698 - val_loss: 0.9423\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.9469 - val_loss: 0.8844\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.9348 - val_loss: 0.8947\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.9252 - val_loss: 0.8762\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.9182 - val_loss: 0.8644\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.9021 - val_loss: 0.9167\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.9395 - val_loss: 0.8294\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.8953 - val_loss: 0.7810\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.8690 - val_loss: 0.8551\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.8324 - val_loss: 0.8031\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.8287 - val_loss: 0.7403\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.8443 - val_loss: 0.8106\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.8003 - val_loss: 0.7963\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.8073 - val_loss: 0.6977\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.7930 - val_loss: 0.7509\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.7902 - val_loss: 0.7720\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.7690 - val_loss: 0.7252\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.7534 - val_loss: 0.7654\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.7504 - val_loss: 0.7484\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.7526 - val_loss: 0.7199\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.7396 - val_loss: 0.7380\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.7252 - val_loss: 0.6724\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.7290 - val_loss: 0.6975\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.7079 - val_loss: 0.6786\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.7122 - val_loss: 0.6470\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.7031 - val_loss: 0.6564\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.7040 - val_loss: 0.7127\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6907 - val_loss: 0.6895\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.6943 - val_loss: 0.7014\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.7036 - val_loss: 0.7403\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6826 - val_loss: 0.7015\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6934 - val_loss: 0.6275\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.6924 - val_loss: 0.6901\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6835 - val_loss: 0.7170\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6682 - val_loss: 0.6864\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.6646 - val_loss: 0.6866\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.6632 - val_loss: 0.6288\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.6620 - val_loss: 0.6427\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.6635 - val_loss: 0.7176\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.6607 - val_loss: 0.6925\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6499 - val_loss: 0.6416\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6568 - val_loss: 0.6177\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.6404 - val_loss: 0.6264\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6388 - val_loss: 0.6618\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.6430 - val_loss: 0.6626\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.6565 - val_loss: 0.6722\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.6641 - val_loss: 0.6587\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6322 - val_loss: 0.7058\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6628 - val_loss: 0.6131\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6366 - val_loss: 0.6039\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.6388 - val_loss: 0.6247\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6335 - val_loss: 0.6112\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6352 - val_loss: 0.6441\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.6293 - val_loss: 0.6079\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.6339 - val_loss: 0.6305\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.6455 - val_loss: 0.5969\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6387 - val_loss: 0.6288\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6219 - val_loss: 0.6261\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.6485 - val_loss: 0.6201\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.6346 - val_loss: 0.5963\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.6196 - val_loss: 0.5990\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6240 - val_loss: 0.6223\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6304 - val_loss: 0.5851\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.6268 - val_loss: 0.5940\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.6146 - val_loss: 0.6068\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.6052 - val_loss: 0.6029\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6292 - val_loss: 0.5901\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6318 - val_loss: 0.6177\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6276 - val_loss: 0.6675\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.6326 - val_loss: 0.5879\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.6159 - val_loss: 0.6616\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.6375 - val_loss: 0.7210\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6269 - val_loss: 0.5699\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.6194 - val_loss: 0.6486\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 798us/step - loss: 0.6047 - val_loss: 0.6267\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 799us/step - loss: 0.5984 - val_loss: 0.5841\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 748us/step - loss: 0.6118 - val_loss: 0.6056\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 741us/step - loss: 0.6021 - val_loss: 0.5661\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 723us/step - loss: 0.6016 - val_loss: 0.5829\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 748us/step - loss: 0.6258 - val_loss: 0.5915\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 704us/step - loss: 0.6005 - val_loss: 0.5866\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 816us/step - loss: 0.6064 - val_loss: 0.6327\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 931us/step - loss: 0.6058 - val_loss: 0.5590\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 706us/step - loss: 0.6039 - val_loss: 0.6112\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 766us/step - loss: 0.5964 - val_loss: 0.6279\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 755us/step - loss: 0.6026 - val_loss: 0.6308\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 720us/step - loss: 0.6104 - val_loss: 0.6663\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 715us/step - loss: 0.6038 - val_loss: 0.5840\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 707us/step - loss: 0.5907 - val_loss: 0.5908\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5896 - val_loss: 0.6058\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5990 - val_loss: 0.5602\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6057 - val_loss: 0.5835\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6170 - val_loss: 0.6211\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.6098 - val_loss: 0.5835\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5918 - val_loss: 0.5948\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 883us/step - loss: 0.6064 - val_loss: 0.5696\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 702us/step - loss: 0.6056 - val_loss: 0.6171\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5947 - val_loss: 0.5818\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 745us/step - loss: 0.6010 - val_loss: 0.5951\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.6119 - val_loss: 0.5749\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.6110 - val_loss: 0.5696\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5959 - val_loss: 0.5970\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5966 - val_loss: 0.6509\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 0.5896 - val_loss: 0.6258\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.6066 - val_loss: 0.6113\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5918 - val_loss: 0.5860\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5907 - val_loss: 0.5354\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6023 - val_loss: 0.6265\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5895 - val_loss: 0.5857\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5938 - val_loss: 0.6573\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5934 - val_loss: 0.5745\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.5859 - val_loss: 0.5927\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5827 - val_loss: 0.5753\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5805 - val_loss: 0.5703\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5796 - val_loss: 0.5812\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5769 - val_loss: 0.6253\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5914 - val_loss: 0.6258\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5927 - val_loss: 0.6575\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5816 - val_loss: 0.5743\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5801 - val_loss: 0.6157\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5834 - val_loss: 0.5334\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5823 - val_loss: 0.5878\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5727 - val_loss: 0.5637\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5841 - val_loss: 0.5348\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5761 - val_loss: 0.5446\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5883 - val_loss: 0.6519\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5772 - val_loss: 0.5570\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5791 - val_loss: 0.5697\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5744 - val_loss: 0.5673\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5794 - val_loss: 0.5704\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5697 - val_loss: 0.5909\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5805 - val_loss: 0.5595\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5723 - val_loss: 0.5622\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5813 - val_loss: 0.5727\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5806 - val_loss: 0.5602\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5894 - val_loss: 0.5672\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5851 - val_loss: 0.5651\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5782 - val_loss: 0.5596\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 770us/step - loss: 0.5751 - val_loss: 0.5835\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5720 - val_loss: 0.6169\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5828 - val_loss: 0.5856\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5684 - val_loss: 0.5940\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5712 - val_loss: 0.5667\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5680 - val_loss: 0.5663\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5862 - val_loss: 0.5369\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5726 - val_loss: 0.6152\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5694 - val_loss: 0.5642\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 784us/step - loss: 0.5721 - val_loss: 0.5700\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5804 - val_loss: 0.5720\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5649 - val_loss: 0.5552\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5677 - val_loss: 0.6188\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5786 - val_loss: 0.6047\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5706 - val_loss: 0.5639\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5768 - val_loss: 0.6366\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5818 - val_loss: 0.5787\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5674 - val_loss: 0.6279\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5735 - val_loss: 0.6331\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5794 - val_loss: 0.5843\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5670 - val_loss: 0.6473\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5870 - val_loss: 0.5750\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5657 - val_loss: 0.5790\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 8.3302 - val_loss: 4.5401\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 696us/step - loss: 2.0368 - val_loss: 1.6584\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 1.3147 - val_loss: 1.3517\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 1.1276 - val_loss: 1.2006\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 1.0412 - val_loss: 1.1315\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.9989 - val_loss: 1.1001\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.9714 - val_loss: 1.0478\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.9449 - val_loss: 1.0151\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.9170 - val_loss: 1.0079\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.9295 - val_loss: 1.0237\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.9130 - val_loss: 0.9716\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.8825 - val_loss: 1.0143\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.8978 - val_loss: 0.9599\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.8779 - val_loss: 0.9926\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.8643 - val_loss: 1.0060\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.8545 - val_loss: 0.9721\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.8780 - val_loss: 0.9516\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.8413 - val_loss: 0.9743\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.8296 - val_loss: 0.9088\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.8185 - val_loss: 0.9720\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.8171 - val_loss: 0.9377\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.7936 - val_loss: 0.9212\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.7942 - val_loss: 0.9162\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.7757 - val_loss: 0.8935\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.7748 - val_loss: 0.8597\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.7818 - val_loss: 0.9144\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.7715 - val_loss: 0.8943\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 699us/step - loss: 0.7667 - val_loss: 0.8376\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.7556 - val_loss: 0.8561\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.7524 - val_loss: 0.8353\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.7511 - val_loss: 0.8477\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 692us/step - loss: 0.7426 - val_loss: 0.8115\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.7147 - val_loss: 0.7898\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.7349 - val_loss: 0.8079\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.7324 - val_loss: 0.8326\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.7138 - val_loss: 0.7768\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6988 - val_loss: 0.7749\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.7114 - val_loss: 0.7784\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6981 - val_loss: 0.7528\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.6957 - val_loss: 0.7484\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.6866 - val_loss: 0.7587\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6790 - val_loss: 0.7468\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 790us/step - loss: 0.6702 - val_loss: 0.7603\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 770us/step - loss: 0.6698 - val_loss: 0.7334\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6717 - val_loss: 0.7807\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.6746 - val_loss: 0.7424\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6709 - val_loss: 0.7415\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.6650 - val_loss: 0.7201\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6570 - val_loss: 0.7273\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.6749 - val_loss: 0.7565\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 718us/step - loss: 0.6767 - val_loss: 0.7400\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 718us/step - loss: 0.6610 - val_loss: 0.7057\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.6523 - val_loss: 0.7146\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 713us/step - loss: 0.6526 - val_loss: 0.7015\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 733us/step - loss: 0.6599 - val_loss: 0.7007\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 720us/step - loss: 0.6660 - val_loss: 0.7373\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.6464 - val_loss: 0.6919\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 722us/step - loss: 0.6449 - val_loss: 0.6988\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 780us/step - loss: 0.6521 - val_loss: 0.7020\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6489 - val_loss: 0.7756\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6614 - val_loss: 0.7715\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 886us/step - loss: 0.6534 - val_loss: 0.7027\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.6360 - val_loss: 0.6757\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.6498 - val_loss: 0.6825\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 730us/step - loss: 0.6460 - val_loss: 0.7034\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 731us/step - loss: 0.6365 - val_loss: 0.7016\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 772us/step - loss: 0.6313 - val_loss: 0.6808\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.6397 - val_loss: 0.7136\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.6426 - val_loss: 0.7385\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6378 - val_loss: 0.7050\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6359 - val_loss: 0.6820\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.6261 - val_loss: 0.6665\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6334 - val_loss: 0.6735\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.6942\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6293 - val_loss: 0.6627\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 999us/step - loss: 0.6200 - val_loss: 0.7135\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6155 - val_loss: 0.6686\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 791us/step - loss: 0.6173 - val_loss: 0.7024\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6308 - val_loss: 0.6757\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 717us/step - loss: 0.6219 - val_loss: 0.7120\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.6308 - val_loss: 0.6585\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.6147 - val_loss: 0.6549\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.6210 - val_loss: 0.6764\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.6250 - val_loss: 0.6771\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 744us/step - loss: 0.6322 - val_loss: 0.6545\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 759us/step - loss: 0.6306 - val_loss: 0.6566\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 728us/step - loss: 0.6265 - val_loss: 0.6650\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.6242 - val_loss: 0.6884\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6345 - val_loss: 0.6950\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.6201 - val_loss: 0.6542\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.6182 - val_loss: 0.6890\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.6165 - val_loss: 0.6512\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6134 - val_loss: 0.6644\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.6088 - val_loss: 0.6526\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 700us/step - loss: 0.6069 - val_loss: 0.6702\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 708us/step - loss: 0.6200 - val_loss: 0.6366\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.6104 - val_loss: 0.6632\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.6131 - val_loss: 0.6654\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.6063 - val_loss: 0.6608\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6132 - val_loss: 0.6414\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6096 - val_loss: 0.6475\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.6125 - val_loss: 0.6558\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.6011 - val_loss: 0.6678\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6023 - val_loss: 0.6883\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.6007 - val_loss: 0.6226\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 0.6041 - val_loss: 0.6363\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5965 - val_loss: 0.6405\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.5976 - val_loss: 0.6354\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.6005 - val_loss: 0.6293\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 905us/step - loss: 0.5946 - val_loss: 0.6588\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 713us/step - loss: 0.5943 - val_loss: 0.6530\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6089 - val_loss: 0.6587\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 707us/step - loss: 0.6024 - val_loss: 0.6654\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 740us/step - loss: 0.5981 - val_loss: 0.6463\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5966 - val_loss: 0.6165\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 736us/step - loss: 0.6061 - val_loss: 0.6389\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5992 - val_loss: 0.6401\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 688us/step - loss: 0.5853 - val_loss: 0.6408\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5946 - val_loss: 0.6413\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.6093 - val_loss: 0.6449\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.6013 - val_loss: 0.6475\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5919 - val_loss: 0.6283\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.6154 - val_loss: 0.6253\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.5959 - val_loss: 0.6478\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5964 - val_loss: 0.6251\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 689us/step - loss: 0.5933 - val_loss: 0.6367\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5853 - val_loss: 0.6151\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 716us/step - loss: 0.5827 - val_loss: 0.6294\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.6017 - val_loss: 0.6135\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5840 - val_loss: 0.6215\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 711us/step - loss: 0.5859 - val_loss: 0.6180\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5770 - val_loss: 0.6210\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5945 - val_loss: 0.6382\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5972 - val_loss: 0.6220\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5834 - val_loss: 0.5954\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5878 - val_loss: 0.6390\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5794 - val_loss: 0.6259\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5967 - val_loss: 0.6117\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.5797 - val_loss: 0.6326\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5878 - val_loss: 0.6664\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5822 - val_loss: 0.6603\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5877 - val_loss: 0.6271\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5811 - val_loss: 0.6096\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5829 - val_loss: 0.6115\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5768 - val_loss: 0.5874\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5819 - val_loss: 0.6109\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5908 - val_loss: 0.6491\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5859 - val_loss: 0.6075\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5784 - val_loss: 0.6064\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5769 - val_loss: 0.6311\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5788 - val_loss: 0.6181\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5790 - val_loss: 0.6009\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5893 - val_loss: 0.6185\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5795 - val_loss: 0.6279\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5726 - val_loss: 0.6080\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5697 - val_loss: 0.6006\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5909 - val_loss: 0.6299\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5740 - val_loss: 0.6092\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 686us/step - loss: 0.5676 - val_loss: 0.6112\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5722 - val_loss: 0.6248\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5817 - val_loss: 0.6251\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5783 - val_loss: 0.6119\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5790 - val_loss: 0.6075\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5725 - val_loss: 0.6004\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5646 - val_loss: 0.5989\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5696 - val_loss: 0.6438\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5607 - val_loss: 0.6315\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5821 - val_loss: 0.6004\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5699 - val_loss: 0.6044\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5675 - val_loss: 0.6124\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5775 - val_loss: 0.6006\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5745 - val_loss: 0.5908\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5596 - val_loss: 0.6194\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5746 - val_loss: 0.6183\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5800 - val_loss: 0.6240\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5675 - val_loss: 0.6074\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5619 - val_loss: 0.6150\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5741 - val_loss: 0.6021\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5789 - val_loss: 0.6102\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5749 - val_loss: 0.5924\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5673 - val_loss: 0.6040\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5715 - val_loss: 0.5907\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 653us/step - loss: 0.5653 - val_loss: 0.5855\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5616 - val_loss: 0.6031\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5846 - val_loss: 0.6161\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5638 - val_loss: 0.5931\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5602 - val_loss: 0.5891\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 719us/step - loss: 0.5581 - val_loss: 0.5947\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 739us/step - loss: 0.5619 - val_loss: 0.5828\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5673 - val_loss: 0.6061\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 744us/step - loss: 0.5662 - val_loss: 0.6167\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 684us/step - loss: 0.5669 - val_loss: 0.6163\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 731us/step - loss: 0.5680 - val_loss: 0.6681\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 764us/step - loss: 0.5670 - val_loss: 0.6149\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5731 - val_loss: 0.5871\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 726us/step - loss: 0.5656 - val_loss: 0.6324\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 924us/step - loss: 0.5695 - val_loss: 0.6156\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5561 - val_loss: 0.5839\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 737us/step - loss: 0.5654 - val_loss: 0.6002\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5596 - val_loss: 0.6139\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 796us/step - loss: 0.5588 - val_loss: 0.6046\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.5625 - val_loss: 0.6070\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 744us/step - loss: 0.5700 - val_loss: 0.5911\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 723us/step - loss: 0.5554 - val_loss: 0.6011\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5665 - val_loss: 0.6199\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5588 - val_loss: 0.6258\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 698us/step - loss: 0.5496 - val_loss: 0.5952\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5667 - val_loss: 0.6033\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5687 - val_loss: 0.5960\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5590 - val_loss: 0.6536\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5615 - val_loss: 0.6086\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5580 - val_loss: 0.5955\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5492 - val_loss: 0.5942\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5561 - val_loss: 0.5921\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5590 - val_loss: 0.5976\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 681us/step - loss: 0.5528 - val_loss: 0.5868\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5532 - val_loss: 0.6152\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5615 - val_loss: 0.5876\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5464 - val_loss: 0.5843\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5484 - val_loss: 0.5805\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 668us/step - loss: 0.5465 - val_loss: 0.5929\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5665 - val_loss: 0.6134\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5493 - val_loss: 0.5913\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5518 - val_loss: 0.5968\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5554 - val_loss: 0.5804\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5509 - val_loss: 0.5793\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5528 - val_loss: 0.5762\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5650 - val_loss: 0.5967\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5587 - val_loss: 0.6200\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5534 - val_loss: 0.5841\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 687us/step - loss: 0.5537 - val_loss: 0.5953\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5532 - val_loss: 0.5933\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 693us/step - loss: 0.5558 - val_loss: 0.5865\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5443 - val_loss: 0.5836\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5491 - val_loss: 0.6042\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5508 - val_loss: 0.5936\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 669us/step - loss: 0.5458 - val_loss: 0.6040\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5521 - val_loss: 0.5859\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.5489 - val_loss: 0.5936\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 697us/step - loss: 0.5489 - val_loss: 0.5887\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5433 - val_loss: 0.5812\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5532 - val_loss: 0.5975\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 678us/step - loss: 0.5536 - val_loss: 0.6596\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5546 - val_loss: 0.6363\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 0.5593 - val_loss: 0.5842\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5488 - val_loss: 0.5826\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5428 - val_loss: 0.5876\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5380 - val_loss: 0.5917\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 0.5457 - val_loss: 0.5926\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5513 - val_loss: 0.5813\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5451 - val_loss: 0.5931\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 767us/step - loss: 0.5472 - val_loss: 0.5889\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5472 - val_loss: 0.5967\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 679us/step - loss: 0.5506 - val_loss: 0.5933\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5463 - val_loss: 0.5775\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 685us/step - loss: 0.5482 - val_loss: 0.5669\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5395 - val_loss: 0.5898\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.5471 - val_loss: 0.5933\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5443 - val_loss: 0.5888\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5643 - val_loss: 0.5939\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.5594 - val_loss: 0.5988\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5442 - val_loss: 0.5876\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5458 - val_loss: 0.5887\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5484 - val_loss: 0.6619\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5628 - val_loss: 0.5939\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5458 - val_loss: 0.5880\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5452 - val_loss: 0.5899\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5454 - val_loss: 0.5771\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5449 - val_loss: 0.5855\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.5367 - val_loss: 0.5630\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5431 - val_loss: 0.5678\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5367 - val_loss: 0.6087\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5364 - val_loss: 0.5947\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5452 - val_loss: 0.5879\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 0.5395 - val_loss: 0.5712\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5458 - val_loss: 0.5825\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.5356 - val_loss: 0.5922\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5506 - val_loss: 0.6039\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 691us/step - loss: 0.5510 - val_loss: 0.5781\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5455 - val_loss: 0.5892\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.5364 - val_loss: 0.5662\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 701us/step - loss: 0.5405 - val_loss: 0.5945\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5388 - val_loss: 0.5845\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 695us/step - loss: 0.5372 - val_loss: 0.5784\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5493 - val_loss: 0.5972\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5429 - val_loss: 0.5849\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5443 - val_loss: 0.5930\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 672us/step - loss: 0.5314 - val_loss: 0.5730\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.5431 - val_loss: 0.5650\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5346 - val_loss: 0.5940\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5423 - val_loss: 0.5583\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5409 - val_loss: 0.6289\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5397 - val_loss: 0.5835\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5398 - val_loss: 0.5794\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 671us/step - loss: 0.5415 - val_loss: 0.5705\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5399 - val_loss: 0.5633\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 690us/step - loss: 0.5349 - val_loss: 0.5784\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5355 - val_loss: 0.5831\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5595 - val_loss: 0.5748\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 677us/step - loss: 0.5404 - val_loss: 0.5611\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5418 - val_loss: 0.5664\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5359 - val_loss: 0.5981\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5398 - val_loss: 0.6110\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5330 - val_loss: 0.5557\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5330 - val_loss: 0.5862\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5315 - val_loss: 0.5728\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5369 - val_loss: 0.5540\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5370 - val_loss: 0.5744\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5309 - val_loss: 0.5764\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5320 - val_loss: 0.5611\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5300 - val_loss: 0.5897\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5365 - val_loss: 0.5657\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5488 - val_loss: 0.5776\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5413 - val_loss: 0.5666\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5425 - val_loss: 0.6110\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5539 - val_loss: 0.5861\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5310 - val_loss: 0.5674\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5317 - val_loss: 0.5558\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5332 - val_loss: 0.6122\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5390 - val_loss: 0.5751\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5308 - val_loss: 0.5878\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 558us/step - loss: 0.5356 - val_loss: 0.5637\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5345 - val_loss: 0.5621\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5355 - val_loss: 0.5683\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5321 - val_loss: 0.5665\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 566us/step - loss: 0.5423 - val_loss: 0.5815\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5386 - val_loss: 0.5574\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5379 - val_loss: 0.5758\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5294 - val_loss: 0.5682\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5404 - val_loss: 0.5601\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5386 - val_loss: 0.5667\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5294 - val_loss: 0.5699\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5328 - val_loss: 0.5683\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5334 - val_loss: 0.5754\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5288 - val_loss: 0.5484\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5344 - val_loss: 0.5824\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5328 - val_loss: 0.6018\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5334 - val_loss: 0.5603\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5361 - val_loss: 0.5625\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 561us/step - loss: 0.5334 - val_loss: 0.5745\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5321 - val_loss: 0.5659\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5372 - val_loss: 0.5519\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5349 - val_loss: 0.5900\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5357 - val_loss: 0.5716\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5340 - val_loss: 0.5868\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5305 - val_loss: 0.5621\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5290 - val_loss: 0.5925\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5351 - val_loss: 0.6012\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5290 - val_loss: 0.5750\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5306 - val_loss: 0.5581\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5271 - val_loss: 0.5853\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5318 - val_loss: 0.5480\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5280 - val_loss: 0.5802\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5255 - val_loss: 0.5547\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5313 - val_loss: 0.5618\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5391 - val_loss: 0.6037\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5351 - val_loss: 0.5933\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5374 - val_loss: 0.5655\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5200 - val_loss: 0.5766\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5308 - val_loss: 0.5753\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 871us/step - loss: 0.5282 - val_loss: 0.5615\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5258 - val_loss: 0.5645\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5306 - val_loss: 0.5627\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5283 - val_loss: 0.5727\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5251 - val_loss: 0.5564\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5204 - val_loss: 0.5533\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5250 - val_loss: 0.5976\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5419 - val_loss: 0.5654\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5215 - val_loss: 0.5562\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5209 - val_loss: 0.5751\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5308 - val_loss: 0.5459\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5213 - val_loss: 0.5755\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5311 - val_loss: 0.5673\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5279 - val_loss: 0.5745\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5330 - val_loss: 0.5717\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5354 - val_loss: 0.5564\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5292 - val_loss: 0.5677\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5258 - val_loss: 0.5713\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5251 - val_loss: 0.5677\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5272 - val_loss: 0.5576\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5212 - val_loss: 0.6002\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5346 - val_loss: 0.5792\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5372 - val_loss: 0.5775\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5342 - val_loss: 0.5507\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5359 - val_loss: 0.5646\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5275 - val_loss: 0.5726\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5211 - val_loss: 0.5665\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5221 - val_loss: 0.5460\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5242 - val_loss: 0.5825\n",
      "Epoch 390/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5200 - val_loss: 0.5579\n",
      "Epoch 391/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5268 - val_loss: 0.5623\n",
      "Epoch 392/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5388 - val_loss: 0.5568\n",
      "Epoch 393/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5292 - val_loss: 0.5599\n",
      "Epoch 394/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5207 - val_loss: 0.5523\n",
      "Epoch 395/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5381 - val_loss: 0.5582\n",
      "Epoch 396/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5264 - val_loss: 0.5524\n",
      "Epoch 397/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5211 - val_loss: 0.6070\n",
      "Epoch 398/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5256 - val_loss: 0.5538\n",
      "Epoch 399/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5221 - val_loss: 0.5672\n",
      "Epoch 400/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5198 - val_loss: 0.5545\n",
      "Epoch 401/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5377 - val_loss: 0.5831\n",
      "Epoch 402/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5327 - val_loss: 0.5656\n",
      "Epoch 403/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5226 - val_loss: 0.5653\n",
      "Epoch 404/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5234 - val_loss: 0.5537\n",
      "Epoch 405/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5216 - val_loss: 0.5810\n",
      "Epoch 406/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5284 - val_loss: 0.5491\n",
      "Epoch 407/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5362 - val_loss: 0.5938\n",
      "Epoch 408/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5340 - val_loss: 0.5539\n",
      "Epoch 409/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5157 - val_loss: 0.5770\n",
      "Epoch 410/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5244 - val_loss: 0.5654\n",
      "Epoch 411/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5226 - val_loss: 0.5709\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.8754 - val_loss: 2.9609\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 1.7089 - val_loss: 1.1555\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 1.2687 - val_loss: 1.0847\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.1683 - val_loss: 1.0198\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.1211 - val_loss: 1.0167\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 1.1028 - val_loss: 1.0490\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 1.0668 - val_loss: 0.9584\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 1.0273 - val_loss: 0.9433\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9834 - val_loss: 0.9209\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.9612 - val_loss: 0.9232\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.9707 - val_loss: 0.9195\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.9466 - val_loss: 0.8863\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.9241 - val_loss: 0.8652\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.9115 - val_loss: 0.8783\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.9143 - val_loss: 0.8535\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.9093 - val_loss: 0.8169\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.8901 - val_loss: 0.8368\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.8687 - val_loss: 0.8102\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.8618 - val_loss: 0.8047\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.8663 - val_loss: 0.8403\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.8440 - val_loss: 0.8099\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.8308 - val_loss: 0.8049\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.8334 - val_loss: 0.8361\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.8478 - val_loss: 0.8648\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.8357 - val_loss: 0.8424\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.8563 - val_loss: 0.8373\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8360 - val_loss: 0.7744\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.7906 - val_loss: 0.7425\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8015 - val_loss: 0.7548\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7672 - val_loss: 0.8055\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.7762 - val_loss: 0.7642\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.7619 - val_loss: 0.7517\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7616 - val_loss: 0.7224\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7542 - val_loss: 0.7223\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.7640 - val_loss: 0.7811\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.7458 - val_loss: 0.7266\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.7548 - val_loss: 0.7102\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7559 - val_loss: 0.7341\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.7322 - val_loss: 0.7206\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7412 - val_loss: 0.6858\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7206 - val_loss: 0.7101\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7140 - val_loss: 0.6934\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7164 - val_loss: 0.6866\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7153 - val_loss: 0.7332\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.7082 - val_loss: 0.7296\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7249 - val_loss: 0.7137\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7051 - val_loss: 0.6791\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.7062 - val_loss: 0.6836\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7006 - val_loss: 0.7339\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6821 - val_loss: 0.6661\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6869 - val_loss: 0.7144\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6774 - val_loss: 0.6643\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6761 - val_loss: 0.6639\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6827 - val_loss: 0.6838\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6770 - val_loss: 0.6775\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6896 - val_loss: 0.6865\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6748 - val_loss: 0.6901\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6608 - val_loss: 0.6637\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6802 - val_loss: 0.6459\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.6863 - val_loss: 0.6593\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6787 - val_loss: 0.6570\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6656 - val_loss: 0.6987\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6651 - val_loss: 0.6226\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6594 - val_loss: 0.7392\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6631 - val_loss: 0.6225\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6583 - val_loss: 0.6361\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6714 - val_loss: 0.6345\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6723 - val_loss: 0.7458\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6531 - val_loss: 0.6175\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6449 - val_loss: 0.6307\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6426 - val_loss: 0.6483\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.6445 - val_loss: 0.6925\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6470 - val_loss: 0.6309\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6425 - val_loss: 0.6458\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6638 - val_loss: 0.6732\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6605 - val_loss: 0.6164\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6290 - val_loss: 0.6959\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6373 - val_loss: 0.6121\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6435 - val_loss: 0.6432\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6377 - val_loss: 0.6392\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6434 - val_loss: 0.6315\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6396 - val_loss: 0.6789\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.6279 - val_loss: 0.6241\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6289 - val_loss: 0.6351\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6344 - val_loss: 0.6319\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6325 - val_loss: 0.6358\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6235 - val_loss: 0.6364\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6316 - val_loss: 0.6326\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6413 - val_loss: 0.6286\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.6263 - val_loss: 0.6063\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6309 - val_loss: 0.6335\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6286 - val_loss: 0.6331\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6214 - val_loss: 0.6108\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6203 - val_loss: 0.6410\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6197 - val_loss: 0.6371\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6178 - val_loss: 0.6193\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6230 - val_loss: 0.6622\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6138 - val_loss: 0.6509\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6315 - val_loss: 0.6206\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.6216 - val_loss: 0.6478\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.6287 - val_loss: 0.6466\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6276 - val_loss: 0.6029\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6221 - val_loss: 0.6213\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6257 - val_loss: 0.6338\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6100 - val_loss: 0.5809\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 564us/step - loss: 0.6118 - val_loss: 0.5924\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6078 - val_loss: 0.6278\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6275 - val_loss: 0.6417\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6126 - val_loss: 0.5978\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.6079 - val_loss: 0.5807\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6240 - val_loss: 0.6318\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6069 - val_loss: 0.6523\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6074 - val_loss: 0.6081\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6140 - val_loss: 0.5853\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6083 - val_loss: 0.6186\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6066 - val_loss: 0.6096\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6129 - val_loss: 0.6453\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 683us/step - loss: 0.6067 - val_loss: 0.5900\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6010 - val_loss: 0.5827\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6064 - val_loss: 0.5789\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6234 - val_loss: 0.6023\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6078 - val_loss: 0.5947\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5988 - val_loss: 0.6191\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6127 - val_loss: 0.5888\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6021 - val_loss: 0.6077\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5976 - val_loss: 0.5881\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6157 - val_loss: 0.6152\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6120 - val_loss: 0.6009\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6046 - val_loss: 0.6029\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6002 - val_loss: 0.6260\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6033 - val_loss: 0.6017\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5934 - val_loss: 0.5971\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5975 - val_loss: 0.6115\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6134 - val_loss: 0.5799\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5924 - val_loss: 0.5898\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6031 - val_loss: 0.6107\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6082 - val_loss: 0.6309\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6043 - val_loss: 0.6001\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6032 - val_loss: 0.5752\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5917 - val_loss: 0.6278\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5921 - val_loss: 0.5908\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5868 - val_loss: 0.6358\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5893 - val_loss: 0.5725\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5921 - val_loss: 0.6183\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6063 - val_loss: 0.5736\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5799 - val_loss: 0.6217\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5912 - val_loss: 0.6257\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5947 - val_loss: 0.6006\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.6027 - val_loss: 0.5771\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5915 - val_loss: 0.5723\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5887 - val_loss: 0.5601\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5803 - val_loss: 0.5780\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5851 - val_loss: 0.5973\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5938 - val_loss: 0.5966\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5966 - val_loss: 0.6486\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5824 - val_loss: 0.5854\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5826 - val_loss: 0.5649\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5949 - val_loss: 0.5698\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6141 - val_loss: 0.5802\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5840 - val_loss: 0.5901\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5767 - val_loss: 0.5767\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5796 - val_loss: 0.6041\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5982 - val_loss: 0.5794\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5805 - val_loss: 0.5706\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5904 - val_loss: 0.5991\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5863 - val_loss: 0.5731\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5798 - val_loss: 0.5711\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5685 - val_loss: 0.5841\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5812 - val_loss: 0.5665\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5735 - val_loss: 0.5747\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5748 - val_loss: 0.5605\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5817 - val_loss: 0.5791\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5779 - val_loss: 0.5734\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5826 - val_loss: 0.5590\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5996 - val_loss: 0.5953\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 566us/step - loss: 0.5884 - val_loss: 0.5853\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5796 - val_loss: 0.5802\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5745 - val_loss: 0.5491\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5731 - val_loss: 0.5761\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5804 - val_loss: 0.6003\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5672 - val_loss: 0.5628\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5828 - val_loss: 0.5479\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5816 - val_loss: 0.5975\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5759 - val_loss: 0.5849\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5942 - val_loss: 0.5532\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5756 - val_loss: 0.5583\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5785 - val_loss: 0.5728\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5728 - val_loss: 0.5771\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5726 - val_loss: 0.5733\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5755 - val_loss: 0.5910\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5774 - val_loss: 0.5838\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5726 - val_loss: 0.5545\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5751 - val_loss: 0.5603\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5713 - val_loss: 0.5506\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5756 - val_loss: 0.5703\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 566us/step - loss: 0.5744 - val_loss: 0.5690\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 566us/step - loss: 0.5713 - val_loss: 0.5535\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5859 - val_loss: 0.5997\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5786 - val_loss: 0.5716\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5794 - val_loss: 0.5656\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5639 - val_loss: 0.5588\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5651 - val_loss: 0.6053\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5829 - val_loss: 0.5546\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5759 - val_loss: 0.5765\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5655 - val_loss: 0.5833\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5670 - val_loss: 0.6023\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5704 - val_loss: 0.5766\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5648 - val_loss: 0.5508\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5628 - val_loss: 0.5530\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5606 - val_loss: 0.5848\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5664 - val_loss: 0.5625\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5904 - val_loss: 0.5839\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5665 - val_loss: 0.5782\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5763 - val_loss: 0.5693\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5717 - val_loss: 0.5498\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5731 - val_loss: 0.5672\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5667 - val_loss: 0.6142\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.5729 - val_loss: 0.5564\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5654 - val_loss: 0.5760\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5585 - val_loss: 0.5768\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5632 - val_loss: 0.5616\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5737 - val_loss: 0.5673\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.0208 - val_loss: 2.1924\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 1.8459 - val_loss: 1.4643\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 1.3162 - val_loss: 1.1623\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 1.1671 - val_loss: 1.2398\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.0968 - val_loss: 1.1187\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 1.0391 - val_loss: 1.1120\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 1.0121 - val_loss: 1.0392\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.9761 - val_loss: 1.0812\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9831 - val_loss: 1.0051\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.9494 - val_loss: 0.9859\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.9524 - val_loss: 0.9345\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.9244 - val_loss: 0.9472\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.9028 - val_loss: 0.9365\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8839 - val_loss: 1.0283\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.8930 - val_loss: 0.9294\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.8669 - val_loss: 0.8471\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.8554 - val_loss: 0.9361\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.8574 - val_loss: 0.8583\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.8245 - val_loss: 0.8328\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8251 - val_loss: 0.8372\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.8107 - val_loss: 0.8870\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.7956 - val_loss: 0.7728\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7702 - val_loss: 0.7689\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.7738 - val_loss: 0.7540\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.7585 - val_loss: 0.7899\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.7509 - val_loss: 0.7205\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.7409 - val_loss: 0.7630\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7272 - val_loss: 0.7124\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 705us/step - loss: 0.7220 - val_loss: 0.7311\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.7132 - val_loss: 0.7752\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.7015 - val_loss: 0.7230\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6986 - val_loss: 0.7009\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6792 - val_loss: 0.6993\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 759us/step - loss: 0.6891 - val_loss: 0.7014\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.6686 - val_loss: 0.6815\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.6671 - val_loss: 0.6583\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6562 - val_loss: 0.7042\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6515 - val_loss: 0.6602\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6536 - val_loss: 0.6864\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6422 - val_loss: 0.6571\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6359 - val_loss: 0.6364\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6528 - val_loss: 0.6579\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6221 - val_loss: 0.6488\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6224 - val_loss: 0.6887\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6225 - val_loss: 0.6498\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6143 - val_loss: 0.6354\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6146 - val_loss: 0.6487\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6219 - val_loss: 0.6630\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6094 - val_loss: 0.6429\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6129 - val_loss: 0.6738\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6002 - val_loss: 0.6382\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6132 - val_loss: 0.6483\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6022 - val_loss: 0.6558\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6070 - val_loss: 0.6550\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5957 - val_loss: 0.6170\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6381 - val_loss: 0.6599\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5947 - val_loss: 0.6628\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6062 - val_loss: 0.6313\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5973 - val_loss: 0.6418\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5938 - val_loss: 0.6256\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6068 - val_loss: 0.7466\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6108 - val_loss: 0.6259\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5874 - val_loss: 0.6034\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5796 - val_loss: 0.6336\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5910 - val_loss: 0.6351\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5902 - val_loss: 0.6051\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5802 - val_loss: 0.6271\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5727 - val_loss: 0.6228\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5839 - val_loss: 0.6098\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5794 - val_loss: 0.6468\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5954 - val_loss: 0.6399\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5980 - val_loss: 0.6596\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5851 - val_loss: 0.6089\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5724 - val_loss: 0.5856\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5851 - val_loss: 0.6017\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5814 - val_loss: 0.6127\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5732 - val_loss: 0.5880\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5642 - val_loss: 0.6212\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5697 - val_loss: 0.6069\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5658 - val_loss: 0.6010\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5689 - val_loss: 0.6009\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5702 - val_loss: 0.5869\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5822 - val_loss: 0.6018\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5691 - val_loss: 0.5939\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5686 - val_loss: 0.6005\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5764 - val_loss: 0.6009\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5763 - val_loss: 0.6077\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5669 - val_loss: 0.5969\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5669 - val_loss: 0.6132\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5726 - val_loss: 0.6080\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5637 - val_loss: 0.6549\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5803 - val_loss: 0.6260\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5602 - val_loss: 0.5822\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5631 - val_loss: 0.6166\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5800 - val_loss: 0.5901\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5563 - val_loss: 0.5799\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5585 - val_loss: 0.5901\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5743 - val_loss: 0.6104\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5647 - val_loss: 0.6078\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5650 - val_loss: 0.6007\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5670 - val_loss: 0.6006\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5758 - val_loss: 0.5866\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5588 - val_loss: 0.6118\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5547 - val_loss: 0.6010\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5673 - val_loss: 0.5863\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5556 - val_loss: 0.5885\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5592 - val_loss: 0.5773\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5513 - val_loss: 0.5768\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5508 - val_loss: 0.6197\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5542 - val_loss: 0.5953\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5569 - val_loss: 0.5856\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5445 - val_loss: 0.5948\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5585 - val_loss: 0.5774\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5539 - val_loss: 0.5862\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5584 - val_loss: 0.5607\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5490 - val_loss: 0.5824\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5655 - val_loss: 0.5792\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5508 - val_loss: 0.6187\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5466 - val_loss: 0.5801\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5521 - val_loss: 0.5535\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5447 - val_loss: 0.5689\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5559 - val_loss: 0.5834\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5471 - val_loss: 0.5634\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.5446 - val_loss: 0.5760\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5544 - val_loss: 0.5721\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5471 - val_loss: 0.5887\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5590 - val_loss: 0.6050\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5509 - val_loss: 0.6161\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5570 - val_loss: 0.5767\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5477 - val_loss: 0.5513\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5444 - val_loss: 0.5829\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5475 - val_loss: 0.5791\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5540 - val_loss: 0.5703\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5489 - val_loss: 0.5597\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5415 - val_loss: 0.5887\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5502 - val_loss: 0.5942\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5474 - val_loss: 0.5560\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5408 - val_loss: 0.5852\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5461 - val_loss: 0.5909\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5587 - val_loss: 0.5640\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5401 - val_loss: 0.5541\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5327 - val_loss: 0.5738\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5520 - val_loss: 0.5819\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5406 - val_loss: 0.5779\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5458 - val_loss: 0.5644\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5410 - val_loss: 0.5604\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5389 - val_loss: 0.5450\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5296 - val_loss: 0.5712\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5414 - val_loss: 0.5695\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5405 - val_loss: 0.5880\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5498 - val_loss: 0.5658\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5385 - val_loss: 0.5466\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5465 - val_loss: 0.5924\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5446 - val_loss: 0.5915\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5465 - val_loss: 0.5762\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5334 - val_loss: 0.5823\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5348 - val_loss: 0.5633\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5332 - val_loss: 0.5647\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5332 - val_loss: 0.5841\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5477 - val_loss: 0.5943\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5481 - val_loss: 0.6015\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5294 - val_loss: 0.5690\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5319 - val_loss: 0.5524\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5390 - val_loss: 0.5720\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5396 - val_loss: 0.5959\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5418 - val_loss: 0.5728\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5325 - val_loss: 0.5732\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5311 - val_loss: 0.5446\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5366 - val_loss: 0.5848\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5398 - val_loss: 0.5593\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5374 - val_loss: 0.5642\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5465 - val_loss: 0.5891\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5291 - val_loss: 0.5824\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5275 - val_loss: 0.5506\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5439 - val_loss: 0.5618\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5368 - val_loss: 0.5788\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5434 - val_loss: 0.5711\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5317 - val_loss: 0.5563\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5298 - val_loss: 0.5654\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5346 - val_loss: 0.5631\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5261 - val_loss: 0.5686\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5328 - val_loss: 0.5660\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5362 - val_loss: 0.6178\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5511 - val_loss: 0.5532\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5210 - val_loss: 0.5605\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5231 - val_loss: 0.5539\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5306 - val_loss: 0.5674\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5214 - val_loss: 0.5785\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5304 - val_loss: 0.5490\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5213 - val_loss: 0.5383\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5317 - val_loss: 0.5525\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5435 - val_loss: 0.5819\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5256 - val_loss: 0.5535\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5338 - val_loss: 0.5523\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5302 - val_loss: 0.5428\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5247 - val_loss: 0.5568\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5302 - val_loss: 0.5729\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5213 - val_loss: 0.5573\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5310 - val_loss: 0.5653\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5254 - val_loss: 0.5550\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5287 - val_loss: 0.5540\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5201 - val_loss: 0.5534\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5315 - val_loss: 0.5737\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5306 - val_loss: 0.5542\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5271 - val_loss: 0.5643\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5204 - val_loss: 0.5556\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5226 - val_loss: 0.5475\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5236 - val_loss: 0.5658\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5205 - val_loss: 0.5712\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5249 - val_loss: 0.5726\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5269 - val_loss: 0.5598\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5437 - val_loss: 0.5488\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5227 - val_loss: 0.5430\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5179 - val_loss: 0.5558\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5145 - val_loss: 0.5388\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5192 - val_loss: 0.5608\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5245 - val_loss: 0.5542\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5218 - val_loss: 0.5474\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5180 - val_loss: 0.5534\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5190 - val_loss: 0.5836\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5353 - val_loss: 0.5573\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5223 - val_loss: 0.5510\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5260 - val_loss: 0.5736\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5227 - val_loss: 0.5502\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5276 - val_loss: 0.5305\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5210 - val_loss: 0.5495\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5298 - val_loss: 0.5742\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5253 - val_loss: 0.5649\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5159 - val_loss: 0.5601\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5226 - val_loss: 0.5348\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5191 - val_loss: 0.5544\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5263 - val_loss: 0.5356\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5186 - val_loss: 0.5927\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5291 - val_loss: 0.5360\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5149 - val_loss: 0.5525\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5164 - val_loss: 0.5375\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5208 - val_loss: 0.5514\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5203 - val_loss: 0.5784\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5162 - val_loss: 0.5501\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5157 - val_loss: 0.5555\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5241 - val_loss: 0.5463\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5162 - val_loss: 0.5454\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5146 - val_loss: 0.5697\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5229 - val_loss: 0.5536\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5273 - val_loss: 0.5768\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5272 - val_loss: 0.5598\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5147 - val_loss: 0.5471\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5241 - val_loss: 0.5536\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5215 - val_loss: 0.5856\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5248 - val_loss: 0.5615\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5218 - val_loss: 0.5498\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5189 - val_loss: 0.5331\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5151 - val_loss: 0.5356\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5150 - val_loss: 0.5557\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5143 - val_loss: 0.5443\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5193 - val_loss: 0.5689\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5196 - val_loss: 0.5406\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5069 - val_loss: 0.5358\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5119 - val_loss: 0.5280\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5086 - val_loss: 0.5449\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5157 - val_loss: 0.5366\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5162 - val_loss: 0.5404\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5099 - val_loss: 0.5344\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5135 - val_loss: 0.5299\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5078 - val_loss: 0.5666\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5206 - val_loss: 0.5469\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5154 - val_loss: 0.5538\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5126 - val_loss: 0.5454\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5120 - val_loss: 0.5467\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5199 - val_loss: 0.5382\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5166 - val_loss: 0.5419\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.5137 - val_loss: 0.5381\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5149 - val_loss: 0.5481\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5345 - val_loss: 0.5711\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5107 - val_loss: 0.5383\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5140 - val_loss: 0.5393\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5071 - val_loss: 0.5415\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5120 - val_loss: 0.5367\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5168 - val_loss: 0.5513\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5142 - val_loss: 0.5636\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5096 - val_loss: 0.5310\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5169 - val_loss: 0.5516\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5173 - val_loss: 0.5225\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5180 - val_loss: 0.5512\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5259 - val_loss: 0.5588\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5111 - val_loss: 0.5361\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5104 - val_loss: 0.5627\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5189 - val_loss: 0.5391\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5084 - val_loss: 0.5500\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5069 - val_loss: 0.5278\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.5097 - val_loss: 0.5447\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5149 - val_loss: 0.5397\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5093 - val_loss: 0.5334\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5072 - val_loss: 0.5307\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5047 - val_loss: 0.5270\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5041 - val_loss: 0.5602\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5153 - val_loss: 0.5477\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5135 - val_loss: 0.5327\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5130 - val_loss: 0.5500\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5136 - val_loss: 0.5330\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5113 - val_loss: 0.5301\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5130 - val_loss: 0.5511\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5084 - val_loss: 0.5407\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5050 - val_loss: 0.5318\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5120 - val_loss: 0.5531\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5041 - val_loss: 0.5513\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5166 - val_loss: 0.5412\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5197 - val_loss: 0.5230\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5148 - val_loss: 0.5476\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5131 - val_loss: 0.5351\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5085 - val_loss: 0.5303\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5112 - val_loss: 0.5243\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5029 - val_loss: 0.5469\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.5086 - val_loss: 0.5715\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5155 - val_loss: 0.5358\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5067 - val_loss: 0.5435\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5086 - val_loss: 0.5303\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5079 - val_loss: 0.5536\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5092 - val_loss: 0.5471\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5092 - val_loss: 0.5371\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5196 - val_loss: 0.5446\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5055 - val_loss: 0.5586\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5122 - val_loss: 0.5448\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.0058 - val_loss: 2.5387\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 1.6887 - val_loss: 1.2475\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 1.2623 - val_loss: 1.0244\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 1.0932 - val_loss: 0.9135\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 1.0315 - val_loss: 0.8663\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.9960 - val_loss: 0.9156\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.9800 - val_loss: 0.7762\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.9698 - val_loss: 0.9301\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.9546 - val_loss: 0.7903\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9457 - val_loss: 0.8014\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.9072 - val_loss: 0.7645\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8916 - val_loss: 0.6699\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8914 - val_loss: 0.7749\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8828 - val_loss: 0.6966\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.8597 - val_loss: 0.7366\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.8413 - val_loss: 0.6972\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.8398 - val_loss: 0.6503\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.8235 - val_loss: 0.6676\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.8250 - val_loss: 0.7521\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.8237 - val_loss: 0.6496\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.7914 - val_loss: 0.6740\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7774 - val_loss: 0.6633\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7691 - val_loss: 0.6162\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.7590 - val_loss: 0.6072\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.7374 - val_loss: 0.6210\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7307 - val_loss: 0.6425\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.7286 - val_loss: 0.5939\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7264 - val_loss: 0.6284\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.7136 - val_loss: 0.6132\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7064 - val_loss: 0.6233\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.7034 - val_loss: 0.5767\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6939 - val_loss: 0.5914\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6929 - val_loss: 0.6312\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7069 - val_loss: 0.6035\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6652 - val_loss: 0.5942\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6683 - val_loss: 0.5882\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6659 - val_loss: 0.5946\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6680 - val_loss: 0.5552\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6528 - val_loss: 0.5735\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6549 - val_loss: 0.5580\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6458 - val_loss: 0.5782\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6391 - val_loss: 0.5560\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6432 - val_loss: 0.5579\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6474 - val_loss: 0.5675\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6287 - val_loss: 0.5767\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6275 - val_loss: 0.5984\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6251 - val_loss: 0.5500\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6301 - val_loss: 0.5700\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6427 - val_loss: 0.5662\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6258 - val_loss: 0.5524\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6157 - val_loss: 0.5515\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6263 - val_loss: 0.5427\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6279 - val_loss: 0.5604\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6108 - val_loss: 0.5645\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6143 - val_loss: 0.5412\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6119 - val_loss: 0.5345\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.6079 - val_loss: 0.5400\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6113 - val_loss: 0.5295\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5988 - val_loss: 0.5467\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6124 - val_loss: 0.5221\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 874us/step - loss: 0.6032 - val_loss: 0.5233\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.6251 - val_loss: 0.5676\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6082 - val_loss: 0.5248\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5973 - val_loss: 0.5404\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6041 - val_loss: 0.5076\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6038 - val_loss: 0.5193\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5910 - val_loss: 0.5302\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5960 - val_loss: 0.5213\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5941 - val_loss: 0.5074\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5898 - val_loss: 0.5079\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5855 - val_loss: 0.4981\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5799 - val_loss: 0.5412\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5797 - val_loss: 0.5229\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6062 - val_loss: 0.5293\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5993 - val_loss: 0.5276\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5903 - val_loss: 0.5218\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5841 - val_loss: 0.5244\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5864 - val_loss: 0.5435\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5891 - val_loss: 0.5750\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5772 - val_loss: 0.4907\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5870 - val_loss: 0.5238\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5946 - val_loss: 0.5521\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 566us/step - loss: 0.5891 - val_loss: 0.5183\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5960 - val_loss: 0.5238\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5781 - val_loss: 0.5139\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5878 - val_loss: 0.4939\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5788 - val_loss: 0.5003\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5758 - val_loss: 0.5150\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5950 - val_loss: 0.5089\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5775 - val_loss: 0.5107\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5763 - val_loss: 0.5347\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5840 - val_loss: 0.5031\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5776 - val_loss: 0.4988\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5702 - val_loss: 0.4982\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5730 - val_loss: 0.5115\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5806 - val_loss: 0.5226\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5754 - val_loss: 0.4949\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5688 - val_loss: 0.5056\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5704 - val_loss: 0.4999\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5736 - val_loss: 0.5019\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5823 - val_loss: 0.5202\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5840 - val_loss: 0.4890\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5631 - val_loss: 0.4928\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5631 - val_loss: 0.4795\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5693 - val_loss: 0.4950\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5796 - val_loss: 0.5120\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5644 - val_loss: 0.5494\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5767 - val_loss: 0.5332\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5681 - val_loss: 0.5284\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5715 - val_loss: 0.5185\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5688 - val_loss: 0.4911\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5599 - val_loss: 0.4804\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5700 - val_loss: 0.5022\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5531 - val_loss: 0.4836\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5519 - val_loss: 0.4665\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5589 - val_loss: 0.5395\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5686 - val_loss: 0.4800\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5595 - val_loss: 0.4879\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5496 - val_loss: 0.5134\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5654 - val_loss: 0.5163\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5634 - val_loss: 0.4811\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5658 - val_loss: 0.5124\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5604 - val_loss: 0.5221\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5691 - val_loss: 0.4754\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5437 - val_loss: 0.4810\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5516 - val_loss: 0.4706\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5466 - val_loss: 0.4823\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5610 - val_loss: 0.5111\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5514 - val_loss: 0.5226\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5564 - val_loss: 0.5070\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5662 - val_loss: 0.4921\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5588 - val_loss: 0.4859\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5421 - val_loss: 0.5129\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 773us/step - loss: 0.5580 - val_loss: 0.4943\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 911us/step - loss: 0.5511 - val_loss: 0.4920\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5549 - val_loss: 0.4884\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5477 - val_loss: 0.4804\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5493 - val_loss: 0.5055\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5435 - val_loss: 0.4836\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5571 - val_loss: 0.4881\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5602 - val_loss: 0.4889\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5528 - val_loss: 0.4664\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5420 - val_loss: 0.4769\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5501 - val_loss: 0.5044\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5485 - val_loss: 0.5077\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5434 - val_loss: 0.4733\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5540 - val_loss: 0.4863\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5549 - val_loss: 0.4921\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5393 - val_loss: 0.4696\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5393 - val_loss: 0.4956\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5479 - val_loss: 0.5001\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5449 - val_loss: 0.4936\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5458 - val_loss: 0.4613\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5339 - val_loss: 0.4921\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5365 - val_loss: 0.4617\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5295 - val_loss: 0.5130\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5380 - val_loss: 0.4760\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5498 - val_loss: 0.4718\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 564us/step - loss: 0.5435 - val_loss: 0.4690\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5462 - val_loss: 0.4694\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5317 - val_loss: 0.4835\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5381 - val_loss: 0.5232\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5385 - val_loss: 0.4735\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5449 - val_loss: 0.4617\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5377 - val_loss: 0.4718\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5324 - val_loss: 0.4915\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5408 - val_loss: 0.4607\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5352 - val_loss: 0.4590\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5492 - val_loss: 0.4888\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5393 - val_loss: 0.4602\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5436 - val_loss: 0.4571\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5351 - val_loss: 0.4624\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5363 - val_loss: 0.4685\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5392 - val_loss: 0.4773\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5512 - val_loss: 0.4582\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5357 - val_loss: 0.4683\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5348 - val_loss: 0.4739\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5331 - val_loss: 0.4638\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5326 - val_loss: 0.4663\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5376 - val_loss: 0.4745\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5327 - val_loss: 0.4797\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5278 - val_loss: 0.4735\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5354 - val_loss: 0.4799\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5332 - val_loss: 0.4591\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5268 - val_loss: 0.4726\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5349 - val_loss: 0.4673\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5385 - val_loss: 0.4562\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5265 - val_loss: 0.4794\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5293 - val_loss: 0.4542\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5322 - val_loss: 0.4556\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5228 - val_loss: 0.4655\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5268 - val_loss: 0.5065\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5271 - val_loss: 0.5029\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5395 - val_loss: 0.5035\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5275 - val_loss: 0.4703\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5215 - val_loss: 0.4855\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5259 - val_loss: 0.4683\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5366 - val_loss: 0.4547\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5199 - val_loss: 0.4537\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5295 - val_loss: 0.4530\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5261 - val_loss: 0.4589\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5267 - val_loss: 0.5114\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5496 - val_loss: 0.4894\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5310 - val_loss: 0.4827\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5314 - val_loss: 0.4822\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5187 - val_loss: 0.4591\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5290 - val_loss: 0.4582\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5299 - val_loss: 0.4694\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5273 - val_loss: 0.4713\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5280 - val_loss: 0.4521\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5188 - val_loss: 0.4605\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5214 - val_loss: 0.4604\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5250 - val_loss: 0.4835\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5228 - val_loss: 0.4815\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5191 - val_loss: 0.4597\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5209 - val_loss: 0.4780\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5237 - val_loss: 0.4604\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5180 - val_loss: 0.4969\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5273 - val_loss: 0.4529\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5273 - val_loss: 0.4558\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5296 - val_loss: 0.4738\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5283 - val_loss: 0.4602\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5269 - val_loss: 0.4571\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5163 - val_loss: 0.4664\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5307 - val_loss: 0.4434\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5254 - val_loss: 0.4482\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5232 - val_loss: 0.4873\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5323 - val_loss: 0.4792\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5288 - val_loss: 0.4647\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5222 - val_loss: 0.4911\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5412 - val_loss: 0.4618\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5238 - val_loss: 0.4786\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5332 - val_loss: 0.4511\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5228 - val_loss: 0.4650\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5155 - val_loss: 0.4426\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5158 - val_loss: 0.4658\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5183 - val_loss: 0.4392\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5146 - val_loss: 0.4642\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5142 - val_loss: 0.4423\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5195 - val_loss: 0.4549\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5204 - val_loss: 0.4720\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5171 - val_loss: 0.4617\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5153 - val_loss: 0.4402\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5071 - val_loss: 0.4470\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5119 - val_loss: 0.4521\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5111 - val_loss: 0.4368\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5136 - val_loss: 0.4556\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5112 - val_loss: 0.4427\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5125 - val_loss: 0.4842\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5242 - val_loss: 0.4704\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5177 - val_loss: 0.4457\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5143 - val_loss: 0.4300\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5100 - val_loss: 0.4547\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5269 - val_loss: 0.4742\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5156 - val_loss: 0.4478\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5153 - val_loss: 0.4517\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5169 - val_loss: 0.4656\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5213 - val_loss: 0.4406\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5059 - val_loss: 0.4335\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5126 - val_loss: 0.4442\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5259 - val_loss: 0.4617\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5150 - val_loss: 0.4456\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5153 - val_loss: 0.4626\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5128 - val_loss: 0.4742\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5055 - val_loss: 0.4421\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5051 - val_loss: 0.4507\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5185 - val_loss: 0.4608\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5152 - val_loss: 0.4396\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5251 - val_loss: 0.4993\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5193 - val_loss: 0.4389\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5188 - val_loss: 0.4398\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5099 - val_loss: 0.4356\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5281 - val_loss: 0.4361\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5113 - val_loss: 0.4340\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5050 - val_loss: 0.4340\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5047 - val_loss: 0.4324\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5027 - val_loss: 0.4369\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5078 - val_loss: 0.4448\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5110 - val_loss: 0.4578\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5101 - val_loss: 0.4426\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5062 - val_loss: 0.4696\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5114 - val_loss: 0.4425\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5116 - val_loss: 0.4538\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5104 - val_loss: 0.4574\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5139 - val_loss: 0.4719\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5054 - val_loss: 0.4317\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5140 - val_loss: 0.4300\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5023 - val_loss: 0.4398\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5037 - val_loss: 0.4385\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5127 - val_loss: 0.4350\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5082 - val_loss: 0.4301\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5019 - val_loss: 0.4214\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5032 - val_loss: 0.4684\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5144 - val_loss: 0.4467\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5058 - val_loss: 0.4414\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.4985 - val_loss: 0.4564\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5153 - val_loss: 0.4679\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5177 - val_loss: 0.4551\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5066 - val_loss: 0.4440\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5023 - val_loss: 0.4488\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5047 - val_loss: 0.4484\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5140 - val_loss: 0.4507\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5029 - val_loss: 0.4440\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5019 - val_loss: 0.4417\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5057 - val_loss: 0.4287\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5055 - val_loss: 0.4807\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5130 - val_loss: 0.4488\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5102 - val_loss: 0.4425\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5000 - val_loss: 0.4294\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.4994 - val_loss: 0.4423\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5008 - val_loss: 0.4684\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5039 - val_loss: 0.4310\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5046 - val_loss: 0.4395\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.4980 - val_loss: 0.4472\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5066 - val_loss: 0.4375\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5071 - val_loss: 0.4576\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5035 - val_loss: 0.4525\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.4992 - val_loss: 0.4418\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.4940 - val_loss: 0.4369\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5068 - val_loss: 0.4666\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5082 - val_loss: 0.4209\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5023 - val_loss: 0.4456\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.4970 - val_loss: 0.4252\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5082 - val_loss: 0.4565\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5039 - val_loss: 0.4436\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5109 - val_loss: 0.4362\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5107 - val_loss: 0.4776\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5114 - val_loss: 0.4593\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5079 - val_loss: 0.4385\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5077 - val_loss: 0.4349\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.4921 - val_loss: 0.4487\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5006 - val_loss: 0.4476\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5035 - val_loss: 0.4251\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5015 - val_loss: 0.4363\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5057 - val_loss: 0.4434\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5028 - val_loss: 0.4259\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.4948 - val_loss: 0.4283\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.4991 - val_loss: 0.4357\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.4994 - val_loss: 0.4330\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5014 - val_loss: 0.4389\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5114 - val_loss: 0.4441\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5070 - val_loss: 0.4418\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.4950 - val_loss: 0.4340\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5047 - val_loss: 0.4649\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5100 - val_loss: 0.4338\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.4986 - val_loss: 0.4588\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5044 - val_loss: 0.4435\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5011 - val_loss: 0.4259\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.4971 - val_loss: 0.4274\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.4987 - val_loss: 0.4484\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.4938 - val_loss: 0.4300\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.4946 - val_loss: 0.4379\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5014 - val_loss: 0.4320\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.4964 - val_loss: 0.4150\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.4918 - val_loss: 0.4347\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5009 - val_loss: 0.4353\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.4896 - val_loss: 0.4206\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.4931 - val_loss: 0.4244\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 0.5048 - val_loss: 0.4453\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5046 - val_loss: 0.4399\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5033 - val_loss: 0.4198\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.4984 - val_loss: 0.4321\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.4971 - val_loss: 0.4460\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.4925 - val_loss: 0.4393\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.4901 - val_loss: 0.4252\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.4955 - val_loss: 0.4399\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.4916 - val_loss: 0.4347\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5030 - val_loss: 0.4465\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5031 - val_loss: 0.4188\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.4903 - val_loss: 0.4229\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.4904 - val_loss: 0.4311\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.4950 - val_loss: 0.4647\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.4977 - val_loss: 0.4525\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.4985 - val_loss: 0.4222\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.4873 - val_loss: 0.4294\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.4922 - val_loss: 0.4333\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.4910 - val_loss: 0.4352\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.4958 - val_loss: 0.4236\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.4917 - val_loss: 0.4266\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.4885 - val_loss: 0.4211\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.4894 - val_loss: 0.4386\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.4878 - val_loss: 0.4241\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.4927 - val_loss: 0.4450\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.4967 - val_loss: 0.4483\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5051 - val_loss: 0.4473\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.4928 - val_loss: 0.4338\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.4951 - val_loss: 0.4283\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.4947 - val_loss: 0.4266\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.4846 - val_loss: 0.4298\n",
      "Epoch 390/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.4891 - val_loss: 0.4591\n",
      "Epoch 391/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.4902 - val_loss: 0.4163\n",
      "Epoch 392/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.4865 - val_loss: 0.4275\n",
      "Epoch 393/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.4886 - val_loss: 0.4580\n",
      "Epoch 394/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.4900 - val_loss: 0.4403\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 4.6912 - val_loss: 2.0347\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 1.6940 - val_loss: 1.3652\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 1.3638 - val_loss: 1.1749\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 1.2662 - val_loss: 1.1349\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 1.1892 - val_loss: 1.1337\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.1384 - val_loss: 1.1161\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.0927 - val_loss: 1.0177\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 1.0716 - val_loss: 1.0645\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.0504 - val_loss: 0.9987\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 1.0195 - val_loss: 1.0211\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 1.0039 - val_loss: 0.9163\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.9756 - val_loss: 1.0093\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.9645 - val_loss: 0.9821\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9473 - val_loss: 0.9199\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.9114 - val_loss: 0.9161\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.8899 - val_loss: 0.8802\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8771 - val_loss: 0.8725\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.8574 - val_loss: 0.8864\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.8304 - val_loss: 0.9438\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.8230 - val_loss: 0.8122\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.8076 - val_loss: 0.8458\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7966 - val_loss: 0.8677\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7812 - val_loss: 0.8122\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7680 - val_loss: 0.8234\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.7439 - val_loss: 0.8761\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.7385 - val_loss: 0.7712\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7274 - val_loss: 0.7859\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7198 - val_loss: 0.7653\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.7041 - val_loss: 0.7576\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6873 - val_loss: 0.7411\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 796us/step - loss: 0.6887 - val_loss: 0.7313\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.6814 - val_loss: 0.7762\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6718 - val_loss: 0.7627\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6763 - val_loss: 0.7255\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6617 - val_loss: 0.7025\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6542 - val_loss: 0.7413\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6634 - val_loss: 0.7172\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6593 - val_loss: 0.7110\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6491 - val_loss: 0.7359\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6422 - val_loss: 0.7164\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6443 - val_loss: 0.7223\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6367 - val_loss: 0.6768\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.6377 - val_loss: 0.6968\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6324 - val_loss: 0.6806\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6340 - val_loss: 0.6675\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6330 - val_loss: 0.6868\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6342 - val_loss: 0.6945\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6300 - val_loss: 0.6794\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6269 - val_loss: 0.6869\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6357 - val_loss: 0.6718\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6486 - val_loss: 0.6913\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6303 - val_loss: 0.6972\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6371 - val_loss: 0.7247\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6125 - val_loss: 0.6469\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6310 - val_loss: 0.7213\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6183 - val_loss: 0.6876\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.6150 - val_loss: 0.6583\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6213 - val_loss: 0.6767\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6180 - val_loss: 0.6840\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6174 - val_loss: 0.6950\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6210 - val_loss: 0.6706\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6098 - val_loss: 0.6635\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6005 - val_loss: 0.6618\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6023 - val_loss: 0.6519\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5937 - val_loss: 0.6561\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5980 - val_loss: 0.6828\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5964 - val_loss: 0.6546\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5981 - val_loss: 0.6436\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5989 - val_loss: 0.6776\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5989 - val_loss: 0.6375\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5882 - val_loss: 0.6592\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6007 - val_loss: 0.6407\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5916 - val_loss: 0.6772\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6079 - val_loss: 0.6556\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6102 - val_loss: 0.6330\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6098 - val_loss: 0.6619\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5944 - val_loss: 0.6621\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5855 - val_loss: 0.6611\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5997 - val_loss: 0.6525\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5976 - val_loss: 0.6404\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5869 - val_loss: 0.6353\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5927 - val_loss: 0.6479\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5877 - val_loss: 0.6394\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5891 - val_loss: 0.6543\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5898 - val_loss: 0.6683\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5811 - val_loss: 0.6549\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5836 - val_loss: 0.6662\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5852 - val_loss: 0.6373\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5804 - val_loss: 0.6510\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5723 - val_loss: 0.6486\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5809 - val_loss: 0.6364\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5755 - val_loss: 0.6217\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5898 - val_loss: 0.6251\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5718 - val_loss: 0.6378\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5809 - val_loss: 0.6729\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5770 - val_loss: 0.6410\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5734 - val_loss: 0.6284\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5819 - val_loss: 0.6476\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5685 - val_loss: 0.6318\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5720 - val_loss: 0.6367\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5738 - val_loss: 0.6291\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5677 - val_loss: 0.6138\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5710 - val_loss: 0.6889\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5695 - val_loss: 0.6399\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5685 - val_loss: 0.6203\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5790 - val_loss: 0.6355\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5641 - val_loss: 0.6499\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5716 - val_loss: 0.6433\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5668 - val_loss: 0.6312\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5630 - val_loss: 0.6125\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5611 - val_loss: 0.6252\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5604 - val_loss: 0.6265\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5708 - val_loss: 0.6293\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5682 - val_loss: 0.6080\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5668 - val_loss: 0.6297\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5685 - val_loss: 0.6476\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5669 - val_loss: 0.6563\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5663 - val_loss: 0.6273\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5593 - val_loss: 0.6392\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5539 - val_loss: 0.6143\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5675 - val_loss: 0.6190\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5643 - val_loss: 0.6373\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5599 - val_loss: 0.6028\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5706 - val_loss: 0.6182\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5579 - val_loss: 0.6274\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5608 - val_loss: 0.6870\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5568 - val_loss: 0.6018\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5603 - val_loss: 0.6370\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5646 - val_loss: 0.6019\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5542 - val_loss: 0.6150\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5544 - val_loss: 0.6387\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5531 - val_loss: 0.6051\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5573 - val_loss: 0.6654\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5611 - val_loss: 0.6130\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5504 - val_loss: 0.6197\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5550 - val_loss: 0.5977\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5537 - val_loss: 0.6059\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5683 - val_loss: 0.6073\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5606 - val_loss: 0.6107\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5462 - val_loss: 0.6127\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5564 - val_loss: 0.6076\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5512 - val_loss: 0.6161\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5475 - val_loss: 0.6024\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5488 - val_loss: 0.6230\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5531 - val_loss: 0.5932\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5483 - val_loss: 0.6438\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5545 - val_loss: 0.6124\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5548 - val_loss: 0.6052\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5515 - val_loss: 0.6232\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5526 - val_loss: 0.6178\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5520 - val_loss: 0.5841\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5483 - val_loss: 0.6168\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5452 - val_loss: 0.5927\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5573 - val_loss: 0.5836\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5441 - val_loss: 0.6152\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5445 - val_loss: 0.5971\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5477 - val_loss: 0.6242\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5463 - val_loss: 0.6197\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5437 - val_loss: 0.5882\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5464 - val_loss: 0.6006\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5474 - val_loss: 0.5907\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5406 - val_loss: 0.5960\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5455 - val_loss: 0.6116\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5489 - val_loss: 0.6085\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5388 - val_loss: 0.5864\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5456 - val_loss: 0.6502\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5508 - val_loss: 0.6087\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5519 - val_loss: 0.6458\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5559 - val_loss: 0.6221\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5546 - val_loss: 0.5820\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5399 - val_loss: 0.5799\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5442 - val_loss: 0.5839\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5451 - val_loss: 0.5826\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5402 - val_loss: 0.5834\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5417 - val_loss: 0.6037\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5495 - val_loss: 0.6138\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5441 - val_loss: 0.5982\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5404 - val_loss: 0.5932\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5430 - val_loss: 0.5978\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5349 - val_loss: 0.5846\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5508 - val_loss: 0.5984\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5363 - val_loss: 0.5945\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5411 - val_loss: 0.6099\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5382 - val_loss: 0.5743\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5333 - val_loss: 0.6130\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5385 - val_loss: 0.5954\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5451 - val_loss: 0.5965\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5384 - val_loss: 0.5761\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5353 - val_loss: 0.5994\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5394 - val_loss: 0.5736\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5347 - val_loss: 0.5971\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5324 - val_loss: 0.5903\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5371 - val_loss: 0.6022\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5288 - val_loss: 0.5851\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5406 - val_loss: 0.5886\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5386 - val_loss: 0.5863\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5400 - val_loss: 0.6062\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5344 - val_loss: 0.5817\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5405 - val_loss: 0.5805\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5298 - val_loss: 0.5853\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5271 - val_loss: 0.5611\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5351 - val_loss: 0.5932\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5336 - val_loss: 0.5844\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5356 - val_loss: 0.5839\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5332 - val_loss: 0.5812\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5401 - val_loss: 0.5698\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5400 - val_loss: 0.5849\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5379 - val_loss: 0.5939\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 911us/step - loss: 0.5346 - val_loss: 0.5709\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5346 - val_loss: 0.5792\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5290 - val_loss: 0.5631\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5338 - val_loss: 0.5752\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5296 - val_loss: 0.5600\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5367 - val_loss: 0.5829\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5394 - val_loss: 0.5989\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5374 - val_loss: 0.5756\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5373 - val_loss: 0.5848\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5307 - val_loss: 0.5628\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5312 - val_loss: 0.5760\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5273 - val_loss: 0.5563\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5253 - val_loss: 0.5930\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5354 - val_loss: 0.5594\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5300 - val_loss: 0.5669\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5357 - val_loss: 0.5903\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5356 - val_loss: 0.6129\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5368 - val_loss: 0.5744\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5322 - val_loss: 0.5809\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5274 - val_loss: 0.5638\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5370 - val_loss: 0.6067\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5316 - val_loss: 0.5796\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5333 - val_loss: 0.5604\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5327 - val_loss: 0.5981\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5315 - val_loss: 0.5718\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5238 - val_loss: 0.5801\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5249 - val_loss: 0.5673\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5286 - val_loss: 0.5638\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5233 - val_loss: 0.5702\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5257 - val_loss: 0.5597\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5244 - val_loss: 0.5790\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5242 - val_loss: 0.5817\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5334 - val_loss: 0.5728\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5233 - val_loss: 0.5726\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5230 - val_loss: 0.5920\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5249 - val_loss: 0.5523\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5290 - val_loss: 0.5591\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5279 - val_loss: 0.5596\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5261 - val_loss: 0.6310\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5235 - val_loss: 0.6139\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5320 - val_loss: 0.6006\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5234 - val_loss: 0.5736\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5238 - val_loss: 0.5758\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5205 - val_loss: 0.5780\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5194 - val_loss: 0.5649\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5171 - val_loss: 0.5550\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5183 - val_loss: 0.5791\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5249 - val_loss: 0.5671\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5303 - val_loss: 0.5708\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5225 - val_loss: 0.5352\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5152 - val_loss: 0.5491\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5211 - val_loss: 0.5710\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5204 - val_loss: 0.5786\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5185 - val_loss: 0.5819\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5210 - val_loss: 0.5692\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5193 - val_loss: 0.6092\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5289 - val_loss: 0.5626\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5199 - val_loss: 0.5655\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5208 - val_loss: 0.5611\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5242 - val_loss: 0.5510\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5242 - val_loss: 0.5701\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5254 - val_loss: 0.5812\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5187 - val_loss: 0.5540\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5186 - val_loss: 0.5783\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5222 - val_loss: 0.5546\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5170 - val_loss: 0.5629\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5207 - val_loss: 0.5936\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5156 - val_loss: 0.5718\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5154 - val_loss: 0.5724\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5191 - val_loss: 0.5684\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5123 - val_loss: 0.5763\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5144 - val_loss: 0.5766\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5261 - val_loss: 0.5717\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5263 - val_loss: 0.5774\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5259 - val_loss: 0.5505\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5175 - val_loss: 0.5773\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5178 - val_loss: 0.5693\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5220 - val_loss: 0.5743\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5079 - val_loss: 0.5620\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5190 - val_loss: 0.5724\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5140 - val_loss: 0.5803\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5183 - val_loss: 0.5470\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5191 - val_loss: 0.5525\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5189 - val_loss: 0.5722\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5201 - val_loss: 0.5567\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5193 - val_loss: 0.5835\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5222 - val_loss: 0.5911\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5134 - val_loss: 0.5683\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5123 - val_loss: 0.5474\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.5186 - val_loss: 0.5680\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0212 - val_loss: 3.6728\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 2.3330 - val_loss: 1.7011\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 1.5700 - val_loss: 1.3187\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 1.3432 - val_loss: 1.2517\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.2263 - val_loss: 1.1226\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 1.1462 - val_loss: 1.0787\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 1.0835 - val_loss: 1.0226\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.0529 - val_loss: 0.9959\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 1.0271 - val_loss: 0.8978\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9852 - val_loss: 0.9153\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.9815 - val_loss: 0.9045\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.9530 - val_loss: 0.9254\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.9273 - val_loss: 0.8575\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.8993 - val_loss: 0.8264\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.8791 - val_loss: 0.7909\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.8559 - val_loss: 0.7360\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.8471 - val_loss: 0.8220\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.8306 - val_loss: 0.7291\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7977 - val_loss: 0.7564\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7953 - val_loss: 0.7044\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7744 - val_loss: 0.6868\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7685 - val_loss: 0.7080\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.7609 - val_loss: 0.7061\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7328 - val_loss: 0.6746\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.7187 - val_loss: 0.6453\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7203 - val_loss: 0.7224\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7270 - val_loss: 0.6808\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.7011 - val_loss: 0.6543\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.7075 - val_loss: 0.6844\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6948 - val_loss: 0.7149\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.6824 - val_loss: 0.6581\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6820 - val_loss: 0.6579\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6775 - val_loss: 0.6793\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6777 - val_loss: 0.6523\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6792 - val_loss: 0.6456\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.6885 - val_loss: 0.6212\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6591 - val_loss: 0.6807\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6634 - val_loss: 0.6633\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6529 - val_loss: 0.6298\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6699 - val_loss: 0.6939\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6628 - val_loss: 0.6190\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6502 - val_loss: 0.6428\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6585 - val_loss: 0.6332\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6438 - val_loss: 0.6067\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6488 - val_loss: 0.6358\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6405 - val_loss: 0.5907\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6376 - val_loss: 0.6080\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6448 - val_loss: 0.5930\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6424 - val_loss: 0.6440\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.6398 - val_loss: 0.5948\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6425 - val_loss: 0.6089\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6524 - val_loss: 0.6096\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6437 - val_loss: 0.5955\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6375 - val_loss: 0.6154\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6304 - val_loss: 0.6185\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6296 - val_loss: 0.6115\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6350 - val_loss: 0.6056\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6220 - val_loss: 0.6105\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6278 - val_loss: 0.6281\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6270 - val_loss: 0.5937\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6199 - val_loss: 0.6179\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6336 - val_loss: 0.5965\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6283 - val_loss: 0.5686\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6152 - val_loss: 0.6107\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6246 - val_loss: 0.5800\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6101 - val_loss: 0.5852\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6320 - val_loss: 0.5755\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6165 - val_loss: 0.5743\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6198 - val_loss: 0.5984\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6172 - val_loss: 0.5570\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6144 - val_loss: 0.5730\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6140 - val_loss: 0.6013\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6321 - val_loss: 0.5927\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6175 - val_loss: 0.5949\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6091 - val_loss: 0.5959\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6124 - val_loss: 0.5650\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6181 - val_loss: 0.5849\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6114 - val_loss: 0.5912\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6144 - val_loss: 0.5979\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6010 - val_loss: 0.5676\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6134 - val_loss: 0.6206\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6145 - val_loss: 0.5650\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6086 - val_loss: 0.6219\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6281 - val_loss: 0.6154\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6069 - val_loss: 0.5991\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5977 - val_loss: 0.5906\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6071 - val_loss: 0.5640\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.6030 - val_loss: 0.5701\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5984 - val_loss: 0.5583\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5994 - val_loss: 0.5487\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5965 - val_loss: 0.5634\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6018 - val_loss: 0.5620\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5978 - val_loss: 0.5965\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6023 - val_loss: 0.5994\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6089 - val_loss: 0.5519\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6004 - val_loss: 0.5488\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5929 - val_loss: 0.5441\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5980 - val_loss: 0.5917\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6115 - val_loss: 0.5912\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5977 - val_loss: 0.5546\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6067 - val_loss: 0.5545\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5941 - val_loss: 0.5532\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5858 - val_loss: 0.5355\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5934 - val_loss: 0.5627\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6049 - val_loss: 0.6212\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6123 - val_loss: 0.5567\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5932 - val_loss: 0.5494\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5812 - val_loss: 0.5714\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5858 - val_loss: 0.5840\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6010 - val_loss: 0.5523\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5932 - val_loss: 0.5566\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5938 - val_loss: 0.5451\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5880 - val_loss: 0.5370\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5890 - val_loss: 0.5693\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5870 - val_loss: 0.5416\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5836 - val_loss: 0.5703\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5925 - val_loss: 0.5768\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5936 - val_loss: 0.5694\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5944 - val_loss: 0.5682\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5882 - val_loss: 0.5412\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5833 - val_loss: 0.5522\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5867 - val_loss: 0.5417\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5892 - val_loss: 0.5700\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5873 - val_loss: 0.5349\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5766 - val_loss: 0.5526\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5878 - val_loss: 0.5524\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6117 - val_loss: 0.5408\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5978 - val_loss: 0.5485\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5990 - val_loss: 0.5949\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5908 - val_loss: 0.5396\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5781 - val_loss: 0.5413\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5713 - val_loss: 0.5531\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5762 - val_loss: 0.5605\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5745 - val_loss: 0.5600\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5820 - val_loss: 0.5326\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5732 - val_loss: 0.5470\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5828 - val_loss: 0.5346\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5974 - val_loss: 0.5724\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5786 - val_loss: 0.5304\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5827 - val_loss: 0.5433\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5768 - val_loss: 0.5456\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5750 - val_loss: 0.5329\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5765 - val_loss: 0.5657\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5838 - val_loss: 0.5376\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5769 - val_loss: 0.5580\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5852 - val_loss: 0.5810\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 565us/step - loss: 0.5762 - val_loss: 0.5407\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5721 - val_loss: 0.5337\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5715 - val_loss: 0.5355\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5876 - val_loss: 0.5646\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5703 - val_loss: 0.5363\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5650 - val_loss: 0.5458\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5725 - val_loss: 0.5285\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5720 - val_loss: 0.5762\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5837 - val_loss: 0.5495\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5702 - val_loss: 0.5305\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5698 - val_loss: 0.5330\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5731 - val_loss: 0.5269\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5726 - val_loss: 0.5621\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5656 - val_loss: 0.5774\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5857 - val_loss: 0.5221\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5669 - val_loss: 0.5348\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5654 - val_loss: 0.5248\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5749 - val_loss: 0.5463\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5744 - val_loss: 0.5295\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5678 - val_loss: 0.5202\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5661 - val_loss: 0.5268\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5717 - val_loss: 0.5161\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5720 - val_loss: 0.5427\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5775 - val_loss: 0.5672\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5735 - val_loss: 0.5576\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5774 - val_loss: 0.5429\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5668 - val_loss: 0.5187\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5752 - val_loss: 0.5320\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 566us/step - loss: 0.5634 - val_loss: 0.5329\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5699 - val_loss: 0.5274\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5676 - val_loss: 0.5632\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5614 - val_loss: 0.5480\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5663 - val_loss: 0.5296\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5691 - val_loss: 0.5537\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5813 - val_loss: 0.5296\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5616 - val_loss: 0.5288\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5631 - val_loss: 0.5292\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5668 - val_loss: 0.5396\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5633 - val_loss: 0.5164\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5759 - val_loss: 0.5395\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5571 - val_loss: 0.5266\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5627 - val_loss: 0.5276\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5831 - val_loss: 0.5536\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5621 - val_loss: 0.5237\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5567 - val_loss: 0.5097\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5683 - val_loss: 0.5231\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5790 - val_loss: 0.5170\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5606 - val_loss: 0.5269\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5537 - val_loss: 0.5409\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5556 - val_loss: 0.5388\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5778 - val_loss: 0.5306\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5602 - val_loss: 0.5426\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5701 - val_loss: 0.5500\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5620 - val_loss: 0.5467\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5616 - val_loss: 0.5325\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5555 - val_loss: 0.5335\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5550 - val_loss: 0.5085\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5618 - val_loss: 0.5140\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5552 - val_loss: 0.5096\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5561 - val_loss: 0.5261\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5588 - val_loss: 0.5297\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5514 - val_loss: 0.5131\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5647 - val_loss: 0.5348\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5627 - val_loss: 0.5140\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5469 - val_loss: 0.5443\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5591 - val_loss: 0.5677\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5782 - val_loss: 0.5302\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5521 - val_loss: 0.5313\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5553 - val_loss: 0.5189\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5620 - val_loss: 0.5440\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5553 - val_loss: 0.5271\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5497 - val_loss: 0.5183\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5530 - val_loss: 0.5261\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5534 - val_loss: 0.5014\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5484 - val_loss: 0.5163\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5565 - val_loss: 0.5250\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5586 - val_loss: 0.5328\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5567 - val_loss: 0.5265\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5550 - val_loss: 0.5220\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5551 - val_loss: 0.5053\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5484 - val_loss: 0.5113\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5508 - val_loss: 0.5309\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5494 - val_loss: 0.5359\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5533 - val_loss: 0.5144\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5574 - val_loss: 0.5720\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5546 - val_loss: 0.5135\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5519 - val_loss: 0.5083\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5504 - val_loss: 0.5260\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5486 - val_loss: 0.5047\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5529 - val_loss: 0.5299\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5553 - val_loss: 0.5319\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5642 - val_loss: 0.5114\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5538 - val_loss: 0.5258\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5485 - val_loss: 0.5115\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5598 - val_loss: 0.5101\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5624 - val_loss: 0.5319\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5549 - val_loss: 0.5039\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5451 - val_loss: 0.5291\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5530 - val_loss: 0.5006\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5518 - val_loss: 0.5384\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5553 - val_loss: 0.5385\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5588 - val_loss: 0.5112\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5483 - val_loss: 0.5335\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5494 - val_loss: 0.5117\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5535 - val_loss: 0.5210\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5494 - val_loss: 0.5255\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5519 - val_loss: 0.5362\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5607 - val_loss: 0.5246\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5629 - val_loss: 0.5118\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5507 - val_loss: 0.5144\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5430 - val_loss: 0.5058\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5605 - val_loss: 0.5339\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5618 - val_loss: 0.5233\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5576 - val_loss: 0.5170\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5576 - val_loss: 0.5211\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5601 - val_loss: 0.5347\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5436 - val_loss: 0.5142\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5546 - val_loss: 0.5059\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5402 - val_loss: 0.5260\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5427 - val_loss: 0.4996\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5484 - val_loss: 0.5105\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5434 - val_loss: 0.5198\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5495 - val_loss: 0.5082\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5470 - val_loss: 0.5016\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5485 - val_loss: 0.5097\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5564 - val_loss: 0.5106\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5516 - val_loss: 0.5245\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5439 - val_loss: 0.4986\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5517 - val_loss: 0.4946\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5401 - val_loss: 0.5214\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5501 - val_loss: 0.5174\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5451 - val_loss: 0.5192\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5384 - val_loss: 0.5037\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5370 - val_loss: 0.5206\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5539 - val_loss: 0.5214\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5368 - val_loss: 0.5055\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5491 - val_loss: 0.4918\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5509 - val_loss: 0.5016\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5403 - val_loss: 0.5068\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5412 - val_loss: 0.5200\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5403 - val_loss: 0.5170\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5414 - val_loss: 0.5000\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5374 - val_loss: 0.4919\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5464 - val_loss: 0.4988\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.5393 - val_loss: 0.5019\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5370 - val_loss: 0.4952\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5460 - val_loss: 0.5242\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5506 - val_loss: 0.4974\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5403 - val_loss: 0.4980\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5405 - val_loss: 0.5070\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5407 - val_loss: 0.5041\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5437 - val_loss: 0.4949\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5430 - val_loss: 0.5023\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5365 - val_loss: 0.5009\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5446 - val_loss: 0.5363\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5361 - val_loss: 0.4927\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5425 - val_loss: 0.5126\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5420 - val_loss: 0.4977\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5420 - val_loss: 0.5123\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5472 - val_loss: 0.5159\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5451 - val_loss: 0.4925\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5378 - val_loss: 0.5028\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5383 - val_loss: 0.5187\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5466 - val_loss: 0.4983\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5342 - val_loss: 0.5128\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5375 - val_loss: 0.4919\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5388 - val_loss: 0.4963\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5463 - val_loss: 0.4905\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5378 - val_loss: 0.5097\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5493 - val_loss: 0.5051\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5417 - val_loss: 0.5254\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5391 - val_loss: 0.4935\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5351 - val_loss: 0.5002\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5387 - val_loss: 0.5071\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5340 - val_loss: 0.4972\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5417 - val_loss: 0.4932\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5434 - val_loss: 0.5260\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5457 - val_loss: 0.4886\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5064\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5359 - val_loss: 0.5076\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5491 - val_loss: 0.5394\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5423 - val_loss: 0.4985\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5386 - val_loss: 0.4954\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5327 - val_loss: 0.4997\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5347 - val_loss: 0.4861\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5413 - val_loss: 0.4932\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5368 - val_loss: 0.4929\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5380 - val_loss: 0.4901\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5495 - val_loss: 0.4969\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5373 - val_loss: 0.4980\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5299 - val_loss: 0.5173\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5417 - val_loss: 0.4950\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 710us/step - loss: 0.5282 - val_loss: 0.4940\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5331 - val_loss: 0.5208\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 694us/step - loss: 0.5428 - val_loss: 0.5071\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.5413 - val_loss: 0.5056\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 750us/step - loss: 0.5400 - val_loss: 0.4840\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5311 - val_loss: 0.4978\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5312 - val_loss: 0.4941\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5426 - val_loss: 0.4974\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.5355 - val_loss: 0.4884\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5355 - val_loss: 0.5128\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5299 - val_loss: 0.4856\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 658us/step - loss: 0.5346 - val_loss: 0.4924\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5312 - val_loss: 0.4955\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5351 - val_loss: 0.4999\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5302 - val_loss: 0.4950\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5373 - val_loss: 0.5016\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5347 - val_loss: 0.4979\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5350 - val_loss: 0.5012\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5323 - val_loss: 0.4973\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5418 - val_loss: 0.4943\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5275 - val_loss: 0.4994\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5331 - val_loss: 0.4854\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5384 - val_loss: 0.5011\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5408 - val_loss: 0.4974\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5280 - val_loss: 0.4844\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5287 - val_loss: 0.4823\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5389 - val_loss: 0.4928\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5405 - val_loss: 0.5004\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5338 - val_loss: 0.4909\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5334 - val_loss: 0.5082\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 565us/step - loss: 0.5371 - val_loss: 0.5075\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5334 - val_loss: 0.4873\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5277 - val_loss: 0.4916\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5301 - val_loss: 0.5016\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5330 - val_loss: 0.4911\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5352 - val_loss: 0.4999\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5270 - val_loss: 0.4818\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5309 - val_loss: 0.5093\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5344 - val_loss: 0.4894\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5235 - val_loss: 0.4876\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5337 - val_loss: 0.5085\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5305 - val_loss: 0.4848\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5309 - val_loss: 0.5112\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5329 - val_loss: 0.4908\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5237 - val_loss: 0.4859\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5233 - val_loss: 0.4944\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5314 - val_loss: 0.4968\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5298 - val_loss: 0.4907\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5316 - val_loss: 0.5043\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5296 - val_loss: 0.4834\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5287 - val_loss: 0.5112\n",
      "Epoch 390/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5302 - val_loss: 0.4942\n",
      "Epoch 391/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5294 - val_loss: 0.4919\n",
      "Epoch 392/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5363 - val_loss: 0.5073\n",
      "Epoch 393/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5396 - val_loss: 0.5125\n",
      "Epoch 394/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5273 - val_loss: 0.4962\n",
      "Epoch 395/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5439 - val_loss: 0.5002\n",
      "Epoch 396/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5360 - val_loss: 0.4846\n",
      "Epoch 397/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5268 - val_loss: 0.4973\n",
      "Epoch 398/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5253 - val_loss: 0.4816\n",
      "Epoch 399/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5257 - val_loss: 0.4953\n",
      "Epoch 400/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5231 - val_loss: 0.5094\n",
      "Epoch 401/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5286 - val_loss: 0.4914\n",
      "Epoch 402/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5306 - val_loss: 0.5029\n",
      "Epoch 403/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5320 - val_loss: 0.4947\n",
      "Epoch 404/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5327 - val_loss: 0.4831\n",
      "Epoch 405/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5274 - val_loss: 0.4838\n",
      "Epoch 406/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5306 - val_loss: 0.4969\n",
      "Epoch 407/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5309 - val_loss: 0.4973\n",
      "Epoch 408/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5260 - val_loss: 0.4893\n",
      "Epoch 409/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5259 - val_loss: 0.4891\n",
      "Epoch 410/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5295 - val_loss: 0.5109\n",
      "Epoch 411/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5315 - val_loss: 0.4874\n",
      "Epoch 412/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5296 - val_loss: 0.4906\n",
      "Epoch 413/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5312 - val_loss: 0.4854\n",
      "Epoch 414/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5210 - val_loss: 0.5072\n",
      "Epoch 415/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5321 - val_loss: 0.5017\n",
      "Epoch 416/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5260 - val_loss: 0.4979\n",
      "Epoch 417/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5244 - val_loss: 0.4909\n",
      "Epoch 418/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5297 - val_loss: 0.5019\n",
      "Epoch 419/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5305 - val_loss: 0.4952\n",
      "Epoch 420/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5248 - val_loss: 0.4896\n",
      "Epoch 421/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5284 - val_loss: 0.4950\n",
      "Epoch 422/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5245 - val_loss: 0.5037\n",
      "Epoch 423/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5260 - val_loss: 0.4894\n",
      "Epoch 424/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5207 - val_loss: 0.4764\n",
      "Epoch 425/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5180 - val_loss: 0.4836\n",
      "Epoch 426/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5315 - val_loss: 0.4953\n",
      "Epoch 427/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5304 - val_loss: 0.4819\n",
      "Epoch 428/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5318 - val_loss: 0.4872\n",
      "Epoch 429/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5241 - val_loss: 0.5037\n",
      "Epoch 430/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5334 - val_loss: 0.4919\n",
      "Epoch 431/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5239 - val_loss: 0.4803\n",
      "Epoch 432/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5284 - val_loss: 0.4922\n",
      "Epoch 433/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5247 - val_loss: 0.4915\n",
      "Epoch 434/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5317 - val_loss: 0.5022\n",
      "Epoch 435/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5268 - val_loss: 0.4885\n",
      "Epoch 436/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5233 - val_loss: 0.4916\n",
      "Epoch 437/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5354 - val_loss: 0.4824\n",
      "Epoch 438/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5255 - val_loss: 0.4786\n",
      "Epoch 439/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5284 - val_loss: 0.4989\n",
      "Epoch 440/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5288 - val_loss: 0.4825\n",
      "Epoch 441/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5296 - val_loss: 0.4868\n",
      "Epoch 442/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5237 - val_loss: 0.4801\n",
      "Epoch 443/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5213 - val_loss: 0.4959\n",
      "Epoch 444/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5379 - val_loss: 0.4971\n",
      "Epoch 445/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5239 - val_loss: 0.4939\n",
      "Epoch 446/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5220 - val_loss: 0.4938\n",
      "Epoch 447/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5287 - val_loss: 0.4913\n",
      "Epoch 448/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5392 - val_loss: 0.4757\n",
      "Epoch 449/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5265 - val_loss: 0.4895\n",
      "Epoch 450/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5314 - val_loss: 0.5068\n",
      "Epoch 451/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5230 - val_loss: 0.4868\n",
      "Epoch 452/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5344 - val_loss: 0.5070\n",
      "Epoch 453/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5280 - val_loss: 0.5143\n",
      "Epoch 454/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5256 - val_loss: 0.4908\n",
      "Epoch 455/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5257 - val_loss: 0.4874\n",
      "Epoch 456/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5270 - val_loss: 0.4807\n",
      "Epoch 457/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5196 - val_loss: 0.4778\n",
      "Epoch 458/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5197 - val_loss: 0.4724\n",
      "Epoch 459/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5180 - val_loss: 0.4801\n",
      "Epoch 460/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5219 - val_loss: 0.4772\n",
      "Epoch 461/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5282 - val_loss: 0.4923\n",
      "Epoch 462/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5352 - val_loss: 0.5329\n",
      "Epoch 463/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5301 - val_loss: 0.4865\n",
      "Epoch 464/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5226 - val_loss: 0.4975\n",
      "Epoch 465/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5193 - val_loss: 0.4873\n",
      "Epoch 466/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5233 - val_loss: 0.4814\n",
      "Epoch 467/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5204 - val_loss: 0.4816\n",
      "Epoch 468/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5196 - val_loss: 0.4853\n",
      "Epoch 469/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5210 - val_loss: 0.4830\n",
      "Epoch 470/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5181 - val_loss: 0.4775\n",
      "Epoch 471/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5183 - val_loss: 0.4740\n",
      "Epoch 472/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5204 - val_loss: 0.4917\n",
      "Epoch 473/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5195 - val_loss: 0.4754\n",
      "Epoch 474/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5169 - val_loss: 0.4729\n",
      "Epoch 475/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5193 - val_loss: 0.4859\n",
      "Epoch 476/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5215 - val_loss: 0.4953\n",
      "Epoch 477/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5222 - val_loss: 0.4750\n",
      "Epoch 478/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5165 - val_loss: 0.4786\n",
      "Epoch 479/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5261 - val_loss: 0.4838\n",
      "Epoch 480/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5371 - val_loss: 0.5243\n",
      "Epoch 481/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5298 - val_loss: 0.4798\n",
      "Epoch 482/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5202 - val_loss: 0.4778\n",
      "Epoch 483/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5235 - val_loss: 0.4948\n",
      "Epoch 484/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5205 - val_loss: 0.4759\n",
      "Epoch 485/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5240 - val_loss: 0.4790\n",
      "Epoch 486/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5184 - val_loss: 0.4821\n",
      "Epoch 487/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5209 - val_loss: 0.5216\n",
      "Epoch 488/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5238 - val_loss: 0.4768\n",
      "Epoch 489/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5203 - val_loss: 0.4903\n",
      "Epoch 490/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5231 - val_loss: 0.4743\n",
      "Epoch 491/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5224 - val_loss: 0.4740\n",
      "Epoch 492/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5166 - val_loss: 0.4988\n",
      "Epoch 493/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5203 - val_loss: 0.4860\n",
      "Epoch 494/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5237 - val_loss: 0.4816\n",
      "Epoch 495/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5199 - val_loss: 0.4828\n",
      "Epoch 496/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5215 - val_loss: 0.4810\n",
      "Epoch 497/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5173 - val_loss: 0.4778\n",
      "Epoch 498/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5175 - val_loss: 0.4843\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 6.8992 - val_loss: 2.8324\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 1.9529 - val_loss: 1.5051\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 1.3232 - val_loss: 1.2216\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.1434 - val_loss: 1.1861\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 1.0811 - val_loss: 1.0978\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 1.0291 - val_loss: 0.9426\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 1.0078 - val_loss: 0.9584\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.9914 - val_loss: 0.9061\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.9657 - val_loss: 0.9754\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.9574 - val_loss: 0.9363\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.9349 - val_loss: 0.9038\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.9436 - val_loss: 0.9317\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.9327 - val_loss: 0.9001\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.9212 - val_loss: 0.8475\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.8899 - val_loss: 0.8692\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.9193 - val_loss: 0.8775\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.8931 - val_loss: 0.9290\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.8703 - val_loss: 0.8955\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.8628 - val_loss: 0.8566\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.8366 - val_loss: 0.8127\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.8222 - val_loss: 0.8541\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.8360 - val_loss: 0.8456\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.8129 - val_loss: 0.8078\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.8111 - val_loss: 0.8651\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.7963 - val_loss: 0.8375\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7978 - val_loss: 0.8579\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7688 - val_loss: 0.7785\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7653 - val_loss: 0.8192\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7445 - val_loss: 0.7747\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7291 - val_loss: 0.7393\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7252 - val_loss: 0.7952\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 656us/step - loss: 0.7260 - val_loss: 0.7486\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.7268 - val_loss: 0.7727\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.7302 - val_loss: 0.7360\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7180 - val_loss: 0.8020\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7043 - val_loss: 0.7876\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6973 - val_loss: 0.8014\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6992 - val_loss: 0.7272\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6947 - val_loss: 0.7527\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6859 - val_loss: 0.7092\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6785 - val_loss: 0.7059\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6824 - val_loss: 0.6920\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6607 - val_loss: 0.6774\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6608 - val_loss: 0.6742\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6696 - val_loss: 0.7823\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6555 - val_loss: 0.7251\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6500 - val_loss: 0.7519\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6629 - val_loss: 0.7220\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6477 - val_loss: 0.6820\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6459 - val_loss: 0.6694\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6507 - val_loss: 0.7608\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6556 - val_loss: 0.7250\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6371 - val_loss: 0.7026\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6710 - val_loss: 0.8040\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6399 - val_loss: 0.7048\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6323 - val_loss: 0.6719\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6356 - val_loss: 0.7023\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6278 - val_loss: 0.6903\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6289 - val_loss: 0.6410\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6349 - val_loss: 0.7316\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6354 - val_loss: 0.6639\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6225 - val_loss: 0.6928\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6150 - val_loss: 0.6691\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6189 - val_loss: 0.6407\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6245 - val_loss: 0.6336\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6338 - val_loss: 0.7270\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6180 - val_loss: 0.6822\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6076 - val_loss: 0.6620\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6157 - val_loss: 0.6923\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6111 - val_loss: 0.6746\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6132 - val_loss: 0.7586\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6167 - val_loss: 0.6841\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6155 - val_loss: 0.7051\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6069 - val_loss: 0.6857\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6148 - val_loss: 0.6394\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6005 - val_loss: 0.6584\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6058 - val_loss: 0.6990\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6054 - val_loss: 0.7486\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6089 - val_loss: 0.7116\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6102 - val_loss: 0.8154\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6130 - val_loss: 0.6495\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6076 - val_loss: 0.6859\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5945 - val_loss: 0.6320\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6025 - val_loss: 0.7320\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6036 - val_loss: 0.7153\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6045 - val_loss: 0.6261\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5931 - val_loss: 0.6683\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6026 - val_loss: 0.6648\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6018 - val_loss: 0.6796\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6072 - val_loss: 0.7465\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5901 - val_loss: 0.6275\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5982 - val_loss: 0.6617\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5975 - val_loss: 0.6910\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6015 - val_loss: 0.6318\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5893 - val_loss: 0.6790\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5936 - val_loss: 0.7300\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5964 - val_loss: 0.6684\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5906 - val_loss: 0.7600\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6042 - val_loss: 0.6618\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6007 - val_loss: 0.6081\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5927 - val_loss: 0.6704\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5898 - val_loss: 0.6498\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5960 - val_loss: 0.6756\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6142 - val_loss: 0.6228\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6039 - val_loss: 0.7108\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5858 - val_loss: 0.6685\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5829 - val_loss: 0.7475\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5999 - val_loss: 0.6291\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5820 - val_loss: 0.6971\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5873 - val_loss: 0.6187\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5841 - val_loss: 0.6178\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5775 - val_loss: 0.6745\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5814 - val_loss: 0.6289\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5973 - val_loss: 0.6877\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5884 - val_loss: 0.6998\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5787 - val_loss: 0.6169\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5755 - val_loss: 0.6597\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5841 - val_loss: 0.6191\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5808 - val_loss: 0.6656\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5830 - val_loss: 0.7524\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5826 - val_loss: 0.6338\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5848 - val_loss: 0.7065\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5967 - val_loss: 0.6810\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5789 - val_loss: 0.7006\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5811 - val_loss: 0.6497\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5781 - val_loss: 0.6592\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5797 - val_loss: 0.6337\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5772 - val_loss: 0.6150\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5827 - val_loss: 0.6310\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5903 - val_loss: 0.7728\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5840 - val_loss: 0.7388\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5822 - val_loss: 0.6172\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5818 - val_loss: 0.6103\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5806 - val_loss: 0.6684\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5864 - val_loss: 0.6641\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5778 - val_loss: 0.6301\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5821 - val_loss: 0.6241\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5784 - val_loss: 0.6244\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5768 - val_loss: 0.6430\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5657 - val_loss: 0.6705\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.9312 - val_loss: 2.7875\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 2.0485 - val_loss: 1.6784\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 1.4361 - val_loss: 1.4219\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.2161 - val_loss: 1.2650\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 1.1410 - val_loss: 1.1308\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 1.1071 - val_loss: 1.1900\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 1.0900 - val_loss: 1.0627\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 1.0422 - val_loss: 1.0668\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.0389 - val_loss: 0.9955\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 1.0194 - val_loss: 0.9775\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.9963 - val_loss: 1.0933\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.9905 - val_loss: 0.9644\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.9665 - val_loss: 0.9472\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.9435 - val_loss: 0.9446\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.9271 - val_loss: 0.9370\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.9325 - val_loss: 0.8887\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9227 - val_loss: 0.8793\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.9136 - val_loss: 0.8734\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.9071 - val_loss: 0.8747\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.8682 - val_loss: 0.8560\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.8735 - val_loss: 0.8665\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.8729 - val_loss: 0.8493\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.8544 - val_loss: 0.8414\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.8352 - val_loss: 0.8343\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8358 - val_loss: 0.7987\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8170 - val_loss: 0.8007\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.8127 - val_loss: 0.7759\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.8049 - val_loss: 0.8057\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8206 - val_loss: 0.7744\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7873 - val_loss: 0.7922\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7867 - val_loss: 0.7663\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.7740 - val_loss: 0.8206\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.7614 - val_loss: 0.7459\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.7543 - val_loss: 0.7527\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7647 - val_loss: 0.7307\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.7650 - val_loss: 0.7307\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7411 - val_loss: 0.7502\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.7427 - val_loss: 0.7686\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7358 - val_loss: 0.7379\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7158 - val_loss: 0.7476\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7269 - val_loss: 0.7082\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7133 - val_loss: 0.7196\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.7250 - val_loss: 0.7468\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7113 - val_loss: 0.6880\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7119 - val_loss: 0.7377\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6915 - val_loss: 0.7279\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6846 - val_loss: 0.7199\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6800 - val_loss: 0.6920\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6871 - val_loss: 0.6717\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6987 - val_loss: 0.7222\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6933 - val_loss: 0.6962\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6777 - val_loss: 0.7030\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6748 - val_loss: 0.6816\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6701 - val_loss: 0.6939\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6617 - val_loss: 0.6813\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6607 - val_loss: 0.7126\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6816 - val_loss: 0.6654\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6583 - val_loss: 0.6925\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6700 - val_loss: 0.7213\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6899 - val_loss: 0.6836\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6843 - val_loss: 0.6705\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6593 - val_loss: 0.6641\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6684 - val_loss: 0.6696\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6589 - val_loss: 0.6447\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6635 - val_loss: 0.7149\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6578 - val_loss: 0.6516\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6395 - val_loss: 0.6993\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6487 - val_loss: 0.6559\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6384 - val_loss: 0.6532\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6379 - val_loss: 0.6545\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6406 - val_loss: 0.6512\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6413 - val_loss: 0.6526\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6461 - val_loss: 0.6619\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6311 - val_loss: 0.6451\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6385 - val_loss: 0.6414\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6358 - val_loss: 0.6452\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6442 - val_loss: 0.6314\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6437 - val_loss: 0.6176\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6294 - val_loss: 0.6555\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6274 - val_loss: 0.6689\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6199 - val_loss: 0.6320\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6235 - val_loss: 0.6583\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6312 - val_loss: 0.6261\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6291 - val_loss: 0.6508\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6340 - val_loss: 0.6307\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6410 - val_loss: 0.6393\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6380 - val_loss: 0.6380\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6199 - val_loss: 0.6437\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6368 - val_loss: 0.6385\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6233 - val_loss: 0.6148\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6104 - val_loss: 0.6273\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6305 - val_loss: 0.6354\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6282 - val_loss: 0.6402\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6175 - val_loss: 0.6682\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6089 - val_loss: 0.6138\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6141 - val_loss: 0.6307\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6192 - val_loss: 0.6272\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6126 - val_loss: 0.6254\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6104 - val_loss: 0.6363\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6149 - val_loss: 0.6404\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6093 - val_loss: 0.6148\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6073 - val_loss: 0.5946\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6082 - val_loss: 0.6119\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6035 - val_loss: 0.6473\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6058 - val_loss: 0.6351\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6115 - val_loss: 0.5962\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.6068 - val_loss: 0.6318\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6266 - val_loss: 0.6149\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6054 - val_loss: 0.6356\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6188 - val_loss: 0.6201\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6088 - val_loss: 0.6083\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6086 - val_loss: 0.6480\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6074 - val_loss: 0.6197\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5983 - val_loss: 0.6143\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6048 - val_loss: 0.6238\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6145 - val_loss: 0.6039\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6099 - val_loss: 0.6096\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6055 - val_loss: 0.6718\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6034 - val_loss: 0.5946\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6000 - val_loss: 0.6105\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6186 - val_loss: 0.6258\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6104 - val_loss: 0.6249\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5973 - val_loss: 0.6063\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6064 - val_loss: 0.6084\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6006 - val_loss: 0.6153\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5991 - val_loss: 0.6025\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5945 - val_loss: 0.6190\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6135 - val_loss: 0.6316\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5893 - val_loss: 0.6094\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6177 - val_loss: 0.6314\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6175 - val_loss: 0.6336\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6060 - val_loss: 0.6091\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5917 - val_loss: 0.5934\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5910 - val_loss: 0.6096\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6015 - val_loss: 0.6207\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 942us/step - loss: 0.5897 - val_loss: 0.6018\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5869 - val_loss: 0.6222\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5996 - val_loss: 0.6538\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5935 - val_loss: 0.6113\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5955 - val_loss: 0.6075\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5987 - val_loss: 0.6206\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5980 - val_loss: 0.6166\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6013 - val_loss: 0.6335\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5971 - val_loss: 0.6123\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5924 - val_loss: 0.6145\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5936 - val_loss: 0.6152\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5964 - val_loss: 0.5865\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5806 - val_loss: 0.6043\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5901 - val_loss: 0.6746\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6025 - val_loss: 0.6208\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5913 - val_loss: 0.6169\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5862 - val_loss: 0.6043\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5942 - val_loss: 0.6774\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5991 - val_loss: 0.6322\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5822 - val_loss: 0.5927\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5953 - val_loss: 0.5843\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5907 - val_loss: 0.6012\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6011 - val_loss: 0.5865\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5878 - val_loss: 0.6003\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5982 - val_loss: 0.6025\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5877 - val_loss: 0.5841\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5740 - val_loss: 0.5914\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5870 - val_loss: 0.5901\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5818 - val_loss: 0.5780\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5774 - val_loss: 0.6049\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5845 - val_loss: 0.5845\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5821 - val_loss: 0.6041\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5743 - val_loss: 0.5840\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5767 - val_loss: 0.5809\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5824 - val_loss: 0.5839\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5733 - val_loss: 0.6119\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5906 - val_loss: 0.5852\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5748 - val_loss: 0.5930\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5886 - val_loss: 0.6182\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5956 - val_loss: 0.5823\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5785 - val_loss: 0.6171\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5840 - val_loss: 0.6112\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5762 - val_loss: 0.5735\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5740 - val_loss: 0.5894\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5873 - val_loss: 0.6127\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5760 - val_loss: 0.6256\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6018 - val_loss: 0.5971\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5771 - val_loss: 0.5989\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5716 - val_loss: 0.6017\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5795 - val_loss: 0.6285\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5827 - val_loss: 0.5743\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5692 - val_loss: 0.6077\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5743 - val_loss: 0.5898\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5848 - val_loss: 0.5908\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5807 - val_loss: 0.6097\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5703 - val_loss: 0.5955\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5829 - val_loss: 0.6051\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5814 - val_loss: 0.6059\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5844 - val_loss: 0.5931\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5703 - val_loss: 0.6042\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5800 - val_loss: 0.5965\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5620 - val_loss: 0.6206\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5798 - val_loss: 0.5853\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5702 - val_loss: 0.5642\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5702 - val_loss: 0.5805\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5809 - val_loss: 0.5647\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5716 - val_loss: 0.6011\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5672 - val_loss: 0.5669\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5763 - val_loss: 0.5813\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5623 - val_loss: 0.5879\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5721 - val_loss: 0.5737\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5738 - val_loss: 0.5733\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5743 - val_loss: 0.5702\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5824 - val_loss: 0.5989\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5816 - val_loss: 0.5812\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5677 - val_loss: 0.5914\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5714 - val_loss: 0.5736\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5639 - val_loss: 0.5688\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5667 - val_loss: 0.5792\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5710 - val_loss: 0.5736\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5617 - val_loss: 0.6009\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5656 - val_loss: 0.5742\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5719 - val_loss: 0.5982\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5743 - val_loss: 0.5854\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5661 - val_loss: 0.6041\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5616 - val_loss: 0.5776\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5732 - val_loss: 0.5760\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5711 - val_loss: 0.5925\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5633 - val_loss: 0.5619\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5663 - val_loss: 0.5820\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5752 - val_loss: 0.5751\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5690 - val_loss: 0.5664\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5666 - val_loss: 0.5772\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5680 - val_loss: 0.5669\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5609 - val_loss: 0.5688\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5741 - val_loss: 0.6004\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5608 - val_loss: 0.5822\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5732 - val_loss: 0.5693\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5627 - val_loss: 0.5813\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5630 - val_loss: 0.5648\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5603 - val_loss: 0.5690\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5652 - val_loss: 0.5825\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5694 - val_loss: 0.5818\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5710 - val_loss: 0.5775\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5597 - val_loss: 0.5825\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5610 - val_loss: 0.5693\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5632 - val_loss: 0.5844\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.5664 - val_loss: 0.5673\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5638 - val_loss: 0.6115\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5677 - val_loss: 0.5682\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5634 - val_loss: 0.5842\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5777 - val_loss: 0.5834\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5685 - val_loss: 0.5649\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5593 - val_loss: 0.6003\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5763 - val_loss: 0.5715\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5617 - val_loss: 0.5887\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5597 - val_loss: 0.5903\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5599 - val_loss: 0.5765\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5664 - val_loss: 0.6116\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5618 - val_loss: 0.5620\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5544 - val_loss: 0.5769\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5563 - val_loss: 0.6171\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5701 - val_loss: 0.5593\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5633 - val_loss: 0.5634\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5515 - val_loss: 0.5681\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5620 - val_loss: 0.5630\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5573 - val_loss: 0.5712\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5610 - val_loss: 0.5613\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.5590 - val_loss: 0.5925\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5596 - val_loss: 0.5867\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5547 - val_loss: 0.5715\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5588 - val_loss: 0.5731\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5634 - val_loss: 0.5642\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5531 - val_loss: 0.5560\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5593 - val_loss: 0.5979\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5608 - val_loss: 0.5606\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5534 - val_loss: 0.5600\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5771 - val_loss: 0.5703\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5560 - val_loss: 0.5698\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5518 - val_loss: 0.5694\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5614 - val_loss: 0.5858\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5603 - val_loss: 0.5585\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5556 - val_loss: 0.5588\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 561us/step - loss: 0.5536 - val_loss: 0.5834\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5576 - val_loss: 0.5671\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5506 - val_loss: 0.5558\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5530 - val_loss: 0.5656\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5489 - val_loss: 0.5621\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5528 - val_loss: 0.5783\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5636 - val_loss: 0.5646\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5599 - val_loss: 0.5696\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5515 - val_loss: 0.5678\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5537 - val_loss: 0.5773\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5580 - val_loss: 0.5706\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5587 - val_loss: 0.6216\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5631 - val_loss: 0.5582\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5580 - val_loss: 0.5699\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5454 - val_loss: 0.5629\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5554 - val_loss: 0.5501\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5495 - val_loss: 0.5680\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5640 - val_loss: 0.5703\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5665 - val_loss: 0.5814\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5572 - val_loss: 0.5584\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5535 - val_loss: 0.5711\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5508 - val_loss: 0.5901\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5532 - val_loss: 0.5744\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5547 - val_loss: 0.5572\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5547 - val_loss: 0.5657\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5537 - val_loss: 0.5683\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5529 - val_loss: 0.5701\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5426 - val_loss: 0.5696\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5463 - val_loss: 0.5517\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5438 - val_loss: 0.5569\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5448 - val_loss: 0.5592\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5551 - val_loss: 0.5569\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5557 - val_loss: 0.5641\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5450 - val_loss: 0.5532\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5469 - val_loss: 0.5719\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5450 - val_loss: 0.5770\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5492 - val_loss: 0.5646\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5527 - val_loss: 0.5647\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 565us/step - loss: 0.5466 - val_loss: 0.5658\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5448 - val_loss: 0.5538\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5443 - val_loss: 0.6004\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5667 - val_loss: 0.5699\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5504 - val_loss: 0.5682\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5516 - val_loss: 0.5536\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5449 - val_loss: 0.5628\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5502 - val_loss: 0.5687\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5555 - val_loss: 0.5600\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5413 - val_loss: 0.5547\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5403 - val_loss: 0.5805\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5497 - val_loss: 0.5601\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5465 - val_loss: 0.5658\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5434 - val_loss: 0.5579\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5445 - val_loss: 0.5627\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5447 - val_loss: 0.5744\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.5546 - val_loss: 0.5713\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5532 - val_loss: 0.5656\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.5938 - val_loss: 3.1691\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 675us/step - loss: 1.8508 - val_loss: 1.7901\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 1.2393 - val_loss: 1.4622\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 1.1083 - val_loss: 1.2913\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.0450 - val_loss: 1.2600\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 1.0205 - val_loss: 1.2359\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.9647 - val_loss: 1.2015\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9568 - val_loss: 1.1337\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.9334 - val_loss: 1.1365\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.9242 - val_loss: 1.1223\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.9098 - val_loss: 1.1523\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.9156 - val_loss: 1.1396\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.9008 - val_loss: 1.0883\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8733 - val_loss: 1.0887\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.8751 - val_loss: 1.0484\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8645 - val_loss: 1.0881\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8614 - val_loss: 1.0665\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.8714 - val_loss: 1.0710\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.8678 - val_loss: 1.0930\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.8320 - val_loss: 1.0209\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.8371 - val_loss: 1.0279\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8217 - val_loss: 0.9851\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8106 - val_loss: 0.9883\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7983 - val_loss: 1.0009\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.7984 - val_loss: 0.9883\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7984 - val_loss: 0.9902\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.8064 - val_loss: 0.9402\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7853 - val_loss: 0.9624\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.7697 - val_loss: 0.9651\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.8110 - val_loss: 0.9377\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.7635 - val_loss: 0.9270\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7465 - val_loss: 0.9013\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7517 - val_loss: 0.9414\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 0.7483 - val_loss: 0.9356\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7579 - val_loss: 0.9077\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.7348 - val_loss: 0.8982\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7366 - val_loss: 0.9024\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.7215 - val_loss: 0.8496\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.7189 - val_loss: 0.8748\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.7077 - val_loss: 0.8385\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.7089 - val_loss: 0.8624\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.7033 - val_loss: 0.8240\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6970 - val_loss: 0.8471\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.7001 - val_loss: 0.8351\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.7084 - val_loss: 0.8070\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6854 - val_loss: 0.8217\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6857 - val_loss: 0.8429\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6783 - val_loss: 0.8265\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6799 - val_loss: 0.7975\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6717 - val_loss: 0.8158\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.6801 - val_loss: 0.7996\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.6684 - val_loss: 0.7949\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6712 - val_loss: 0.8251\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6720 - val_loss: 0.8024\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6699 - val_loss: 0.8405\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6621 - val_loss: 0.8106\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6736 - val_loss: 0.8304\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6678 - val_loss: 0.8006\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6641 - val_loss: 0.7757\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6686 - val_loss: 0.7904\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 890us/step - loss: 0.6531 - val_loss: 0.7530\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 649us/step - loss: 0.6468 - val_loss: 0.7624\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6418 - val_loss: 0.7191\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6484 - val_loss: 0.7185\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6292 - val_loss: 0.8237\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6447 - val_loss: 0.7826\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6247 - val_loss: 0.7464\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6274 - val_loss: 0.7601\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6277 - val_loss: 0.7522\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6248 - val_loss: 0.7324\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6208 - val_loss: 0.7313\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6243 - val_loss: 0.7355\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6126 - val_loss: 0.7202\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6225 - val_loss: 0.7141\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6193 - val_loss: 0.7305\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6271 - val_loss: 0.7459\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6214 - val_loss: 0.7382\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6101 - val_loss: 0.7254\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6078 - val_loss: 0.7274\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6181 - val_loss: 0.6932\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6094 - val_loss: 0.7530\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6125 - val_loss: 0.7289\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6195 - val_loss: 0.7455\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6022 - val_loss: 0.7141\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6091 - val_loss: 0.7059\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6063 - val_loss: 0.6938\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6183 - val_loss: 0.7096\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5950 - val_loss: 0.7499\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5965 - val_loss: 0.7230\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5964 - val_loss: 0.6923\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6045 - val_loss: 0.6795\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5996 - val_loss: 0.7352\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5994 - val_loss: 0.7320\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6001 - val_loss: 0.6821\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5962 - val_loss: 0.7012\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6043 - val_loss: 0.7127\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6047 - val_loss: 0.7110\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5923 - val_loss: 0.6763\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5901 - val_loss: 0.7161\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5922 - val_loss: 0.6822\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5926 - val_loss: 0.6902\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5955 - val_loss: 0.6701\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6043 - val_loss: 0.6717\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5957 - val_loss: 0.6739\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5805 - val_loss: 0.7638\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5988 - val_loss: 0.6929\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5908 - val_loss: 0.6948\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5813 - val_loss: 0.6835\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5853 - val_loss: 0.6706\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5762 - val_loss: 0.7278\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5852 - val_loss: 0.6817\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5759 - val_loss: 0.6560\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5987 - val_loss: 0.7053\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5852 - val_loss: 0.6910\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5740 - val_loss: 0.7206\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5793 - val_loss: 0.6460\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5769 - val_loss: 0.6626\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5739 - val_loss: 0.6769\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5795 - val_loss: 0.6598\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5734 - val_loss: 0.7311\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5868 - val_loss: 0.6632\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5737 - val_loss: 0.6631\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5913 - val_loss: 0.6459\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5760 - val_loss: 0.6871\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5829 - val_loss: 0.6884\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5711 - val_loss: 0.6945\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5840 - val_loss: 0.6738\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5796 - val_loss: 0.6891\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5816 - val_loss: 0.6865\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5776 - val_loss: 0.6840\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5805 - val_loss: 0.6992\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5673 - val_loss: 0.6881\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 655us/step - loss: 0.5703 - val_loss: 0.6675\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5743 - val_loss: 0.6642\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5823 - val_loss: 0.6471\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5761 - val_loss: 0.6637\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5619 - val_loss: 0.7338\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5746 - val_loss: 0.7431\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5738 - val_loss: 0.6643\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5698 - val_loss: 0.6715\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5688 - val_loss: 0.6989\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5667 - val_loss: 0.6294\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5597 - val_loss: 0.6425\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5653 - val_loss: 0.6591\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5594 - val_loss: 0.6595\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5668 - val_loss: 0.7426\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5599 - val_loss: 0.6600\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5619 - val_loss: 0.6850\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5675 - val_loss: 0.6888\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5678 - val_loss: 0.6648\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5718 - val_loss: 0.6954\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5649 - val_loss: 0.6426\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5675 - val_loss: 0.6835\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5611 - val_loss: 0.6392\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5529 - val_loss: 0.6846\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5742 - val_loss: 0.6877\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5533 - val_loss: 0.6423\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5697 - val_loss: 0.6455\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5778 - val_loss: 0.6770\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5560 - val_loss: 0.6648\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5568 - val_loss: 0.6475\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5600 - val_loss: 0.6626\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5533 - val_loss: 0.7262\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5634 - val_loss: 0.7140\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5622 - val_loss: 0.6847\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5604 - val_loss: 0.6317\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5540 - val_loss: 0.6696\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5503 - val_loss: 0.6968\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5558 - val_loss: 0.6828\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5488 - val_loss: 0.6368\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5544 - val_loss: 0.6843\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5569 - val_loss: 0.6723\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5554 - val_loss: 0.6287\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5429 - val_loss: 0.7171\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5503 - val_loss: 0.6644\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5554 - val_loss: 0.6771\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5471 - val_loss: 0.6284\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5522 - val_loss: 0.6451\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5522 - val_loss: 0.6302\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5394 - val_loss: 0.6455\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5556 - val_loss: 0.7257\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5485 - val_loss: 0.6644\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5458 - val_loss: 0.6719\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5540 - val_loss: 0.7317\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5496 - val_loss: 0.6731\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5519 - val_loss: 0.6510\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5445 - val_loss: 0.6564\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5647 - val_loss: 0.6636\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5554 - val_loss: 0.6890\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5589 - val_loss: 0.6480\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5440 - val_loss: 0.6931\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5495 - val_loss: 0.6808\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5488 - val_loss: 0.6372\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5502 - val_loss: 0.6428\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5430 - val_loss: 0.6341\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5456 - val_loss: 0.6678\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5545 - val_loss: 0.7002\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5414 - val_loss: 0.6506\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5485 - val_loss: 0.6396\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5428 - val_loss: 0.6401\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5473 - val_loss: 0.6850\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5435 - val_loss: 0.6915\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5505 - val_loss: 0.7040\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5454 - val_loss: 0.7178\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5407 - val_loss: 0.6469\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5446 - val_loss: 0.6353\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5572 - val_loss: 0.6413\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5407 - val_loss: 0.6329\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5482 - val_loss: 0.6806\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5515 - val_loss: 0.6462\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5483 - val_loss: 0.6190\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5364 - val_loss: 0.6359\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5605 - val_loss: 0.6262\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5393 - val_loss: 0.6792\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5392 - val_loss: 0.6706\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5395 - val_loss: 0.6323\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5517 - val_loss: 0.7070\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5385 - val_loss: 0.6405\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5415 - val_loss: 0.6553\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5377 - val_loss: 0.6796\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5349 - val_loss: 0.6463\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5362 - val_loss: 0.6528\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5394 - val_loss: 0.6426\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5369 - val_loss: 0.6229\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5417 - val_loss: 0.6423\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5385 - val_loss: 0.6272\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5331 - val_loss: 0.6247\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5418 - val_loss: 0.6710\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5392 - val_loss: 0.6192\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5529 - val_loss: 0.6707\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5422 - val_loss: 0.6399\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5353 - val_loss: 0.6599\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5321 - val_loss: 0.6343\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5458 - val_loss: 0.6351\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5422 - val_loss: 0.6497\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5340 - val_loss: 0.6109\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5392 - val_loss: 0.6564\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5296 - val_loss: 0.6743\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5460 - val_loss: 0.6158\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5360 - val_loss: 0.6947\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5359 - val_loss: 0.6591\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5403 - val_loss: 0.6736\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5333 - val_loss: 0.6134\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5563 - val_loss: 0.6607\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5369 - val_loss: 0.6510\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 563us/step - loss: 0.5303 - val_loss: 0.6651\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5470 - val_loss: 0.7834\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5467 - val_loss: 0.6224\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5369 - val_loss: 0.6546\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5309 - val_loss: 0.6615\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5326 - val_loss: 0.6530\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5274 - val_loss: 0.7439\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5416 - val_loss: 0.7109\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5269 - val_loss: 0.6655\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5409 - val_loss: 0.6480\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5302 - val_loss: 0.6675\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5431 - val_loss: 0.6469\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5382 - val_loss: 0.6737\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5411 - val_loss: 0.6424\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5269 - val_loss: 0.6567\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5363 - val_loss: 0.6502\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 660us/step - loss: 0.5352 - val_loss: 0.6373\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5300 - val_loss: 0.6640\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5271 - val_loss: 0.6549\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5296 - val_loss: 0.6479\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5346 - val_loss: 0.6310\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5262 - val_loss: 0.6367\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5348 - val_loss: 0.6206\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5311 - val_loss: 0.6240\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5262 - val_loss: 0.6328\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5247 - val_loss: 0.6680\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5271 - val_loss: 0.6706\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5311 - val_loss: 0.6323\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5328 - val_loss: 0.6415\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5243 - val_loss: 0.6392\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5322 - val_loss: 0.6621\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.6935 - val_loss: 2.0090\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 641us/step - loss: 1.5532 - val_loss: 1.2359\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 1.2317 - val_loss: 1.1557\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 1.1415 - val_loss: 1.1580\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 1.0864 - val_loss: 1.0533\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 1.0522 - val_loss: 1.0715\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 1.0240 - val_loss: 1.0725\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 680us/step - loss: 1.0013 - val_loss: 1.1054\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.9851 - val_loss: 1.0271\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.9866 - val_loss: 1.0441\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.9649 - val_loss: 0.9835\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.9689 - val_loss: 0.9933\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.9491 - val_loss: 0.9774\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.9221 - val_loss: 1.0736\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.9241 - val_loss: 0.9963\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.9051 - val_loss: 0.9661\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8993 - val_loss: 0.9686\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9017 - val_loss: 0.9740\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.8928 - val_loss: 1.0191\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.8866 - val_loss: 0.9388\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8551 - val_loss: 0.9425\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.8639 - val_loss: 0.9170\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.8608 - val_loss: 0.9016\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.8516 - val_loss: 0.9115\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.8376 - val_loss: 0.9107\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.8588 - val_loss: 0.9138\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.8278 - val_loss: 0.8674\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.8106 - val_loss: 0.9009\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.8251 - val_loss: 0.8790\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.8089 - val_loss: 0.8979\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.8042 - val_loss: 0.8547\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.7816 - val_loss: 0.9079\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.7981 - val_loss: 0.8750\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.7683 - val_loss: 0.8713\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7716 - val_loss: 0.8229\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7467 - val_loss: 0.8296\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7411 - val_loss: 0.7821\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7479 - val_loss: 0.8094\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.7403 - val_loss: 0.7657\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7333 - val_loss: 0.7641\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7274 - val_loss: 0.7744\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.7009 - val_loss: 0.7573\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6971 - val_loss: 0.7387\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6934 - val_loss: 0.7577\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7025 - val_loss: 0.7362\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6855 - val_loss: 0.7466\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6782 - val_loss: 0.7612\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6870 - val_loss: 0.7272\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6711 - val_loss: 0.7627\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6658 - val_loss: 0.7086\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6528 - val_loss: 0.7240\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6606 - val_loss: 0.7149\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6562 - val_loss: 0.7110\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6543 - val_loss: 0.7126\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.6467 - val_loss: 0.6883\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6356 - val_loss: 0.6767\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6333 - val_loss: 0.6822\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6580 - val_loss: 0.6744\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6402 - val_loss: 0.6666\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6288 - val_loss: 0.6992\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6330 - val_loss: 0.6856\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6244 - val_loss: 0.6489\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6352 - val_loss: 0.6898\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6275 - val_loss: 0.6687\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6198 - val_loss: 0.6811\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6200 - val_loss: 0.6626\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6274 - val_loss: 0.6593\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6176 - val_loss: 0.6623\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6151 - val_loss: 0.6420\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6077 - val_loss: 0.6470\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6077 - val_loss: 0.6365\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6065 - val_loss: 0.6384\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6075 - val_loss: 0.6653\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6008 - val_loss: 0.6276\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6043 - val_loss: 0.6367\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6194 - val_loss: 0.6983\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6115 - val_loss: 0.6430\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6007 - val_loss: 0.6448\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6053 - val_loss: 0.6405\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6056 - val_loss: 0.6195\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6046 - val_loss: 0.6392\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5920 - val_loss: 0.6222\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5936 - val_loss: 0.6182\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5872 - val_loss: 0.6234\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5898 - val_loss: 0.6275\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5880 - val_loss: 0.6217\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5986 - val_loss: 0.6240\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5892 - val_loss: 0.6097\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5821 - val_loss: 0.6329\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5741 - val_loss: 0.6152\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5842 - val_loss: 0.6210\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5828 - val_loss: 0.6007\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5769 - val_loss: 0.6178\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5866 - val_loss: 0.6005\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5803 - val_loss: 0.6014\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5821 - val_loss: 0.6181\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5769 - val_loss: 0.6125\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5826 - val_loss: 0.6179\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5779 - val_loss: 0.6003\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5726 - val_loss: 0.6012\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5824 - val_loss: 0.6019\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5860 - val_loss: 0.6590\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5875 - val_loss: 0.6374\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5847 - val_loss: 0.6213\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5905 - val_loss: 0.6230\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5730 - val_loss: 0.6046\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5738 - val_loss: 0.6192\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5794 - val_loss: 0.6070\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5764 - val_loss: 0.6247\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5710 - val_loss: 0.6054\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5657 - val_loss: 0.5962\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5735 - val_loss: 0.6033\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5656 - val_loss: 0.6057\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5662 - val_loss: 0.6260\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5776 - val_loss: 0.6051\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5662 - val_loss: 0.6165\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5705 - val_loss: 0.6182\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5662 - val_loss: 0.5885\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5630 - val_loss: 0.6182\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5602 - val_loss: 0.5847\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5630 - val_loss: 0.5922\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5650 - val_loss: 0.5941\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5602 - val_loss: 0.6004\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5574 - val_loss: 0.5931\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5627 - val_loss: 0.6001\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5638 - val_loss: 0.6073\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5706 - val_loss: 0.6055\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5613 - val_loss: 0.5880\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5592 - val_loss: 0.5853\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5556 - val_loss: 0.6077\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5781 - val_loss: 0.6192\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5636 - val_loss: 0.5682\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5661 - val_loss: 0.5855\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5611 - val_loss: 0.5799\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5475 - val_loss: 0.5733\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5557 - val_loss: 0.6057\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5615 - val_loss: 0.5776\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5616 - val_loss: 0.5883\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5575 - val_loss: 0.5939\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5534 - val_loss: 0.5887\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5625 - val_loss: 0.5833\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5662 - val_loss: 0.5751\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5493 - val_loss: 0.5866\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5506 - val_loss: 0.5729\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5535 - val_loss: 0.5848\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5521 - val_loss: 0.5726\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5470 - val_loss: 0.6059\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5467 - val_loss: 0.5758\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5453 - val_loss: 0.5781\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5567 - val_loss: 0.5827\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5530 - val_loss: 0.5830\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5468 - val_loss: 0.5866\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5480 - val_loss: 0.5709\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5503 - val_loss: 0.6333\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5580 - val_loss: 0.5990\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5685 - val_loss: 0.5818\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5479 - val_loss: 0.5652\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5471 - val_loss: 0.5856\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5548 - val_loss: 0.6098\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5505 - val_loss: 0.5801\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5433 - val_loss: 0.6052\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5501 - val_loss: 0.5653\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5482 - val_loss: 0.5839\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5420 - val_loss: 0.5771\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5384 - val_loss: 0.5662\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5330 - val_loss: 0.5702\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5608 - val_loss: 0.5798\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5531 - val_loss: 0.5727\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5428 - val_loss: 0.5841\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5480 - val_loss: 0.6080\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5389 - val_loss: 0.5876\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5396 - val_loss: 0.5779\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5429 - val_loss: 0.5795\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5385 - val_loss: 0.5820\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5445 - val_loss: 0.5770\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5386 - val_loss: 0.5617\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5347 - val_loss: 0.5787\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5444 - val_loss: 0.5805\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5484 - val_loss: 0.5702\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5427 - val_loss: 0.5821\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5395 - val_loss: 0.5727\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5453 - val_loss: 0.5747\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5335 - val_loss: 0.5955\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5419 - val_loss: 0.5826\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5392 - val_loss: 0.5625\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5319 - val_loss: 0.5802\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5342 - val_loss: 0.5602\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5262 - val_loss: 0.5629\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5260 - val_loss: 0.5677\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5277 - val_loss: 0.5643\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5409 - val_loss: 0.5588\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5424 - val_loss: 0.5782\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5366 - val_loss: 0.5681\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5376 - val_loss: 0.5661\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5337 - val_loss: 0.5570\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5360 - val_loss: 0.5635\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5318 - val_loss: 0.5821\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5309 - val_loss: 0.5717\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5354 - val_loss: 0.5543\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5225 - val_loss: 0.5783\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5296 - val_loss: 0.5520\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5359 - val_loss: 0.5932\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5379 - val_loss: 0.5661\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5297 - val_loss: 0.5621\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5283 - val_loss: 0.5554\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5237 - val_loss: 0.5561\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5275 - val_loss: 0.5638\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5429 - val_loss: 0.5694\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5247 - val_loss: 0.5575\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5263 - val_loss: 0.5802\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5318 - val_loss: 0.5677\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5415 - val_loss: 0.5737\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5370 - val_loss: 0.5621\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5514 - val_loss: 0.5744\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5318 - val_loss: 0.5569\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5372 - val_loss: 0.5563\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5237 - val_loss: 0.5699\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5415 - val_loss: 0.5768\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5328 - val_loss: 0.5637\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5348 - val_loss: 0.5674\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5317 - val_loss: 0.5701\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5307 - val_loss: 0.5633\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5260 - val_loss: 0.5553\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5268 - val_loss: 0.5617\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5302 - val_loss: 0.5671\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5302 - val_loss: 0.5602\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5311 - val_loss: 0.5619\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5389 - val_loss: 0.5791\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5278 - val_loss: 0.5466\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5241 - val_loss: 0.5556\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5245 - val_loss: 0.5482\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5250 - val_loss: 0.5751\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5239 - val_loss: 0.5513\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5158 - val_loss: 0.5602\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5234 - val_loss: 0.5544\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5212 - val_loss: 0.5439\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5203 - val_loss: 0.5538\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5312 - val_loss: 0.5588\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5484 - val_loss: 0.5584\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5318 - val_loss: 0.5531\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5269 - val_loss: 0.5632\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5313 - val_loss: 0.5493\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5230 - val_loss: 0.5506\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5155 - val_loss: 0.5761\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5219 - val_loss: 0.5813\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5327 - val_loss: 0.5655\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5188 - val_loss: 0.5566\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5186 - val_loss: 0.5513\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5261 - val_loss: 0.5730\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5221 - val_loss: 0.5509\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5230 - val_loss: 0.5525\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5188 - val_loss: 0.5592\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5271 - val_loss: 0.5724\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5238 - val_loss: 0.5478\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5148 - val_loss: 0.5653\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5229 - val_loss: 0.5587\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5193 - val_loss: 0.5625\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5316 - val_loss: 0.5505\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5271 - val_loss: 0.5549\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5168 - val_loss: 0.5522\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5147 - val_loss: 0.5498\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5190 - val_loss: 0.5407\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5177 - val_loss: 0.5567\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5172 - val_loss: 0.5649\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5142 - val_loss: 0.5814\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5221 - val_loss: 0.5419\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5251 - val_loss: 0.5899\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5278 - val_loss: 0.5754\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5215 - val_loss: 0.5519\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5237 - val_loss: 0.5601\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5244 - val_loss: 0.5579\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5160 - val_loss: 0.5511\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5159 - val_loss: 0.5545\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5123 - val_loss: 0.5503\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5230 - val_loss: 0.5552\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5247 - val_loss: 0.5530\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5179 - val_loss: 0.5445\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5149 - val_loss: 0.5506\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5217 - val_loss: 0.5524\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5204 - val_loss: 0.5485\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5183 - val_loss: 0.5537\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5098 - val_loss: 0.5539\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5213 - val_loss: 0.5511\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5173 - val_loss: 0.5622\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5160 - val_loss: 0.5537\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5130 - val_loss: 0.5458\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5157 - val_loss: 0.6121\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5242 - val_loss: 0.5612\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5160 - val_loss: 0.5364\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5301 - val_loss: 0.5560\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5158 - val_loss: 0.5387\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5195 - val_loss: 0.5710\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5133 - val_loss: 0.5682\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5141 - val_loss: 0.5474\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5072 - val_loss: 0.5463\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5147 - val_loss: 0.5683\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5127 - val_loss: 0.5491\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5199 - val_loss: 0.5552\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5093 - val_loss: 0.5705\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5128 - val_loss: 0.5489\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5232 - val_loss: 0.5381\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5166 - val_loss: 0.5348\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5147 - val_loss: 0.5488\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5148 - val_loss: 0.5604\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5148 - val_loss: 0.5429\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5090 - val_loss: 0.5559\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5201 - val_loss: 0.5588\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5136 - val_loss: 0.5447\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5049 - val_loss: 0.5406\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5068 - val_loss: 0.5565\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5220 - val_loss: 0.5399\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5188 - val_loss: 0.5437\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5083 - val_loss: 0.5476\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5127 - val_loss: 0.5458\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5115 - val_loss: 0.5475\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5099 - val_loss: 0.5361\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5121 - val_loss: 0.5580\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5102 - val_loss: 0.5307\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5058 - val_loss: 0.5548\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5112 - val_loss: 0.5459\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5121 - val_loss: 0.5374\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5051 - val_loss: 0.5589\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5188 - val_loss: 0.5468\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5159 - val_loss: 0.5645\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5172 - val_loss: 0.5495\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5112 - val_loss: 0.5583\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5157 - val_loss: 0.5481\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5129 - val_loss: 0.5324\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5116 - val_loss: 0.5516\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5121 - val_loss: 0.5463\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5168 - val_loss: 0.5490\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5078 - val_loss: 0.5602\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5090 - val_loss: 0.5405\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5068 - val_loss: 0.5324\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5235 - val_loss: 0.5510\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5122 - val_loss: 0.5515\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5057 - val_loss: 0.5389\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5065 - val_loss: 0.5537\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5143 - val_loss: 0.5581\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5094 - val_loss: 0.5502\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5091 - val_loss: 0.5507\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5148 - val_loss: 0.5422\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.5117 - val_loss: 0.5425\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5050 - val_loss: 0.5467\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5071 - val_loss: 0.5514\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5014 - val_loss: 0.5388\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5097 - val_loss: 0.5442\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5130 - val_loss: 0.5521\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5139 - val_loss: 0.5483\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5156 - val_loss: 0.5464\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5171 - val_loss: 0.5501\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5179 - val_loss: 0.5654\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5161 - val_loss: 0.5479\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5094 - val_loss: 0.5429\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5002 - val_loss: 0.5406\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5099 - val_loss: 0.5281\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5018 - val_loss: 0.5478\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5154 - val_loss: 0.5765\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5136 - val_loss: 0.5365\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5033 - val_loss: 0.5444\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5051 - val_loss: 0.5488\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5081 - val_loss: 0.5763\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5060 - val_loss: 0.5393\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5015 - val_loss: 0.5328\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5045 - val_loss: 0.5427\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5093 - val_loss: 0.5405\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5013 - val_loss: 0.5360\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5042 - val_loss: 0.5562\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5214 - val_loss: 0.5501\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5152 - val_loss: 0.5568\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5106 - val_loss: 0.5391\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5074 - val_loss: 0.5456\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5085 - val_loss: 0.5437\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5034 - val_loss: 0.5343\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5048 - val_loss: 0.5430\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5003 - val_loss: 0.5810\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5073 - val_loss: 0.5309\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5016 - val_loss: 0.5402\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.4995 - val_loss: 0.5485\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5019 - val_loss: 0.5904\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5100 - val_loss: 0.5528\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5049 - val_loss: 0.5439\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5119 - val_loss: 0.5864\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5057 - val_loss: 0.5456\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5014 - val_loss: 0.5349\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.4977 - val_loss: 0.5336\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.4966 - val_loss: 0.5368\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5009 - val_loss: 0.5561\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5015 - val_loss: 0.5295\n",
      "Epoch 390/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5147 - val_loss: 0.5516\n",
      "Epoch 391/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5064 - val_loss: 0.5386\n",
      "Epoch 392/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5062 - val_loss: 0.5437\n",
      "Epoch 393/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5003 - val_loss: 0.5453\n",
      "Epoch 394/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5029 - val_loss: 0.5430\n",
      "Epoch 395/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5162 - val_loss: 0.5362\n",
      "Epoch 396/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.4964 - val_loss: 0.5378\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 6.7232 - val_loss: 3.0508\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 2.0865 - val_loss: 1.5644\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 1.3904 - val_loss: 1.2493\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 1.1865 - val_loss: 1.1198\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 1.1357 - val_loss: 1.1349\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 1.0979 - val_loss: 1.0842\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 1.0439 - val_loss: 1.0567\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 1.0248 - val_loss: 1.0065\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 1.0087 - val_loss: 1.0001\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.9927 - val_loss: 0.9508\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.9508 - val_loss: 0.9347\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9332 - val_loss: 0.9152\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.9163 - val_loss: 0.9321\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.9231 - val_loss: 0.9552\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 791us/step - loss: 0.9163 - val_loss: 0.9388\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 670us/step - loss: 0.8779 - val_loss: 0.8666\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.8497 - val_loss: 0.8274\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.8356 - val_loss: 0.8128\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.8104 - val_loss: 0.7674\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7868 - val_loss: 0.7512\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7793 - val_loss: 0.8577\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.7885 - val_loss: 0.7421\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.7550 - val_loss: 0.6905\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7442 - val_loss: 0.6918\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7236 - val_loss: 0.6986\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7279 - val_loss: 0.6970\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7295 - val_loss: 0.6715\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.7151 - val_loss: 0.6347\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7021 - val_loss: 0.6954\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.7119 - val_loss: 0.6407\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6881 - val_loss: 0.6418\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6703 - val_loss: 0.6120\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6674 - val_loss: 0.6190\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6657 - val_loss: 0.6448\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6779 - val_loss: 0.6017\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6518 - val_loss: 0.5917\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6538 - val_loss: 0.6126\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6616 - val_loss: 0.5985\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6634 - val_loss: 0.5940\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6482 - val_loss: 0.5962\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6566 - val_loss: 0.6033\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6429 - val_loss: 0.5980\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6486 - val_loss: 0.5898\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6408 - val_loss: 0.6063\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6242 - val_loss: 0.5605\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6342 - val_loss: 0.5763\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6445 - val_loss: 0.5982\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6349 - val_loss: 0.5837\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6306 - val_loss: 0.5599\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6301 - val_loss: 0.6491\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6324 - val_loss: 0.6087\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6405 - val_loss: 0.6410\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6332 - val_loss: 0.5846\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6238 - val_loss: 0.5409\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6157 - val_loss: 0.5569\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6252 - val_loss: 0.5685\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 563us/step - loss: 0.6226 - val_loss: 0.6041\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6288 - val_loss: 0.5546\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6144 - val_loss: 0.5372\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6146 - val_loss: 0.5912\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6129 - val_loss: 0.5578\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6198 - val_loss: 0.5570\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6236 - val_loss: 0.5638\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6093 - val_loss: 0.5478\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6171 - val_loss: 0.5970\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6134 - val_loss: 0.5510\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6020 - val_loss: 0.5555\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6009 - val_loss: 0.5505\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6192 - val_loss: 0.6250\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6109 - val_loss: 0.5406\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6103 - val_loss: 0.5651\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6050 - val_loss: 0.5281\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6100 - val_loss: 0.5261\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6058 - val_loss: 0.5988\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6225 - val_loss: 0.5527\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6188 - val_loss: 0.5647\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6035 - val_loss: 0.5382\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6042 - val_loss: 0.5430\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5952 - val_loss: 0.5660\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5956 - val_loss: 0.5557\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5830 - val_loss: 0.5250\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5986 - val_loss: 0.5469\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6074 - val_loss: 0.5403\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5970 - val_loss: 0.5926\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5930 - val_loss: 0.5419\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5913 - val_loss: 0.5193\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5978 - val_loss: 0.5501\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5906 - val_loss: 0.5591\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5919 - val_loss: 0.5318\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5885 - val_loss: 0.5295\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5863 - val_loss: 0.5359\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5981 - val_loss: 0.5664\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5948 - val_loss: 0.5593\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5822 - val_loss: 0.5583\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5922 - val_loss: 0.5549\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6015 - val_loss: 0.6291\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5941 - val_loss: 0.5080\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5822 - val_loss: 0.5245\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5837 - val_loss: 0.5497\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5941 - val_loss: 0.5272\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5796 - val_loss: 0.5275\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5917 - val_loss: 0.5023\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5785 - val_loss: 0.5210\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5787 - val_loss: 0.5256\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5864 - val_loss: 0.5040\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5811 - val_loss: 0.5114\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5777 - val_loss: 0.5322\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5803 - val_loss: 0.5331\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5845 - val_loss: 0.5341\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5906 - val_loss: 0.5377\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5735 - val_loss: 0.5125\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5786 - val_loss: 0.5282\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5731 - val_loss: 0.5184\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5858 - val_loss: 0.5317\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5748 - val_loss: 0.5070\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5728 - val_loss: 0.5136\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5767 - val_loss: 0.4950\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5800 - val_loss: 0.5296\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5839 - val_loss: 0.5244\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5703 - val_loss: 0.5072\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5779 - val_loss: 0.5169\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5675 - val_loss: 0.4941\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5752 - val_loss: 0.5090\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5703 - val_loss: 0.5169\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5767 - val_loss: 0.5111\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5716 - val_loss: 0.5278\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5704 - val_loss: 0.4944\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5716 - val_loss: 0.5105\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5753 - val_loss: 0.5289\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5718 - val_loss: 0.4896\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5759 - val_loss: 0.5087\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5651 - val_loss: 0.5370\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5695 - val_loss: 0.5431\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5651 - val_loss: 0.5092\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5662 - val_loss: 0.4911\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5691 - val_loss: 0.5173\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5790 - val_loss: 0.4991\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5713 - val_loss: 0.4865\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5664 - val_loss: 0.5215\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5692 - val_loss: 0.5131\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5703 - val_loss: 0.5012\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5669 - val_loss: 0.4874\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5732 - val_loss: 0.5442\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5682 - val_loss: 0.4946\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5567 - val_loss: 0.5559\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5680 - val_loss: 0.5048\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5697 - val_loss: 0.4907\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5657 - val_loss: 0.5274\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5674 - val_loss: 0.5199\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5683 - val_loss: 0.5166\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5611 - val_loss: 0.5182\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5760 - val_loss: 0.5210\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5594 - val_loss: 0.4971\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5660 - val_loss: 0.4892\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5752 - val_loss: 0.5128\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5592 - val_loss: 0.5102\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5606 - val_loss: 0.4858\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5518 - val_loss: 0.4894\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5675 - val_loss: 0.5146\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5567 - val_loss: 0.4818\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5640 - val_loss: 0.4938\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5540 - val_loss: 0.5327\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5521 - val_loss: 0.5004\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5560 - val_loss: 0.5183\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5585 - val_loss: 0.4731\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5572 - val_loss: 0.5098\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5555 - val_loss: 0.4983\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5569 - val_loss: 0.5488\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5603 - val_loss: 0.4880\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5546 - val_loss: 0.5052\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5540 - val_loss: 0.4833\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5532 - val_loss: 0.4865\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5541 - val_loss: 0.5066\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5567 - val_loss: 0.4954\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5545 - val_loss: 0.5052\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5555 - val_loss: 0.5031\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5568 - val_loss: 0.5214\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5614 - val_loss: 0.5119\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5570 - val_loss: 0.4854\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5489 - val_loss: 0.4987\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5505 - val_loss: 0.4791\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5468 - val_loss: 0.5000\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5677 - val_loss: 0.5250\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5517 - val_loss: 0.5029\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5536 - val_loss: 0.4824\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5503 - val_loss: 0.5233\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5503 - val_loss: 0.4948\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5562 - val_loss: 0.4959\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5551 - val_loss: 0.5161\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5608 - val_loss: 0.4736\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5461 - val_loss: 0.4631\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5623 - val_loss: 0.4852\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5446 - val_loss: 0.4894\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5520 - val_loss: 0.4917\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5577 - val_loss: 0.4846\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5616 - val_loss: 0.5098\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5541 - val_loss: 0.4756\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5451 - val_loss: 0.4878\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5422 - val_loss: 0.4976\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5440 - val_loss: 0.4918\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5465 - val_loss: 0.5240\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5502 - val_loss: 0.4788\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5441 - val_loss: 0.4858\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5514 - val_loss: 0.4928\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5427 - val_loss: 0.5075\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5597 - val_loss: 0.4783\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5453 - val_loss: 0.4765\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5438 - val_loss: 0.5273\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5478 - val_loss: 0.4846\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5481 - val_loss: 0.4751\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5621 - val_loss: 0.5118\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5433 - val_loss: 0.4882\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5409 - val_loss: 0.4721\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5425 - val_loss: 0.4808\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5457 - val_loss: 0.5205\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5525 - val_loss: 0.4881\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5579 - val_loss: 0.4945\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5526 - val_loss: 0.4701\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5478 - val_loss: 0.5324\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5606 - val_loss: 0.5338\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5570 - val_loss: 0.4939\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5452 - val_loss: 0.4935\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5394 - val_loss: 0.4581\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5478 - val_loss: 0.5169\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5464 - val_loss: 0.4716\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5455 - val_loss: 0.4655\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5426 - val_loss: 0.4743\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5416 - val_loss: 0.4905\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5450 - val_loss: 0.4794\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5390 - val_loss: 0.4649\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5408 - val_loss: 0.4970\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5456 - val_loss: 0.4801\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5430 - val_loss: 0.4937\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5514 - val_loss: 0.4693\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5412 - val_loss: 0.4528\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5467 - val_loss: 0.4945\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5440 - val_loss: 0.4894\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5438 - val_loss: 0.4677\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5401 - val_loss: 0.4747\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5440 - val_loss: 0.4662\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5340 - val_loss: 0.4665\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5395 - val_loss: 0.4912\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5401 - val_loss: 0.4834\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5481 - val_loss: 0.4730\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5341 - val_loss: 0.4719\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5330 - val_loss: 0.4640\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5378 - val_loss: 0.4916\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5412 - val_loss: 0.4642\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5420 - val_loss: 0.4755\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5342 - val_loss: 0.4797\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5399 - val_loss: 0.4668\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5381 - val_loss: 0.4756\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5508 - val_loss: 0.4680\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5376 - val_loss: 0.5011\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5380 - val_loss: 0.4503\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5359 - val_loss: 0.4548\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5381 - val_loss: 0.5102\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5413 - val_loss: 0.4928\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5360 - val_loss: 0.5104\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5457 - val_loss: 0.4851\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5300 - val_loss: 0.4773\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5366 - val_loss: 0.4679\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5350 - val_loss: 0.4575\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5431 - val_loss: 0.5319\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5403 - val_loss: 0.4713\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5351 - val_loss: 0.4896\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5333 - val_loss: 0.4706\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5367 - val_loss: 0.4841\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5335 - val_loss: 0.4824\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5373 - val_loss: 0.4635\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5350 - val_loss: 0.4693\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5456 - val_loss: 0.4604\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5394 - val_loss: 0.4650\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5348 - val_loss: 0.4679\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5293 - val_loss: 0.4730\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5413 - val_loss: 0.4539\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5394 - val_loss: 0.4701\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5427 - val_loss: 0.4809\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5457 - val_loss: 0.4855\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5358 - val_loss: 0.4606\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5456 - val_loss: 0.4834\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5315 - val_loss: 0.4707\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5313 - val_loss: 0.4935\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5442 - val_loss: 0.4802\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5397 - val_loss: 0.4665\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5371 - val_loss: 0.5059\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5433 - val_loss: 0.4836\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5343 - val_loss: 0.4959\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5290 - val_loss: 0.4589\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5296 - val_loss: 0.4584\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5248 - val_loss: 0.4703\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5388 - val_loss: 0.4696\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5392 - val_loss: 0.4699\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5331 - val_loss: 0.4788\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5318 - val_loss: 0.4677\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 5.7261 - val_loss: 2.8640\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 2.0297 - val_loss: 1.2788\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 1.3354 - val_loss: 1.1370\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 1.1928 - val_loss: 1.0560\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.1056 - val_loss: 1.0755\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 1.0590 - val_loss: 0.9765\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 1.0022 - val_loss: 0.9829\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9927 - val_loss: 0.9004\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.9690 - val_loss: 0.9424\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.9653 - val_loss: 0.9574\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.9329 - val_loss: 0.8250\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.9068 - val_loss: 0.9518\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9251 - val_loss: 0.9079\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.8926 - val_loss: 0.7706\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.8855 - val_loss: 0.8347\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.8658 - val_loss: 0.8403\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 768us/step - loss: 0.8648 - val_loss: 0.7606\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 940us/step - loss: 0.8410 - val_loss: 0.8022\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.8498 - val_loss: 0.7984\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.8311 - val_loss: 0.8258\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.8372 - val_loss: 0.7467\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.8201 - val_loss: 0.7676\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.8173 - val_loss: 0.8046\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.8218 - val_loss: 0.7332\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7929 - val_loss: 0.7094\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.7816 - val_loss: 0.7155\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7749 - val_loss: 0.7016\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.7839 - val_loss: 0.6933\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7840 - val_loss: 0.6859\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7757 - val_loss: 0.7001\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.7530 - val_loss: 0.6751\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.7520 - val_loss: 0.6695\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.7411 - val_loss: 0.6896\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.7474 - val_loss: 0.6793\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7366 - val_loss: 0.6850\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.7351 - val_loss: 0.6375\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 565us/step - loss: 0.7224 - val_loss: 0.6802\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.7176 - val_loss: 0.6354\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 557us/step - loss: 0.7125 - val_loss: 0.6839\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7108 - val_loss: 0.6247\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7015 - val_loss: 0.6137\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7024 - val_loss: 0.6180\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7105 - val_loss: 0.5943\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6920 - val_loss: 0.6143\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.6832 - val_loss: 0.6008\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6789 - val_loss: 0.6328\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6881 - val_loss: 0.6037\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6847 - val_loss: 0.6036\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6728 - val_loss: 0.5830\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6799 - val_loss: 0.6066\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6724 - val_loss: 0.5920\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6791 - val_loss: 0.5726\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6567 - val_loss: 0.5674\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6574 - val_loss: 0.5981\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6809 - val_loss: 0.5825\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6548 - val_loss: 0.5588\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6546 - val_loss: 0.5796\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6603 - val_loss: 0.5873\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6593 - val_loss: 0.5748\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6477 - val_loss: 0.5531\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6499 - val_loss: 0.5641\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6505 - val_loss: 0.5854\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6469 - val_loss: 0.5647\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6299 - val_loss: 0.5637\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6258 - val_loss: 0.5489\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6394 - val_loss: 0.5673\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6269 - val_loss: 0.5571\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6314 - val_loss: 0.5403\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6265 - val_loss: 0.5425\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6237 - val_loss: 0.5648\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.6563 - val_loss: 0.5805\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6226 - val_loss: 0.5394\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6223 - val_loss: 0.5165\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6267 - val_loss: 0.5614\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.6178 - val_loss: 0.5347\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6172 - val_loss: 0.5243\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6117 - val_loss: 0.5589\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.6075 - val_loss: 0.5304\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6028 - val_loss: 0.5099\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.6081 - val_loss: 0.5669\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6211 - val_loss: 0.5793\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.6275 - val_loss: 0.5472\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6096 - val_loss: 0.5531\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6044 - val_loss: 0.5082\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6147 - val_loss: 0.5362\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6098 - val_loss: 0.5213\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6137 - val_loss: 0.5604\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6140 - val_loss: 0.5137\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5967 - val_loss: 0.5443\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5951 - val_loss: 0.5202\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5987 - val_loss: 0.5246\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5958 - val_loss: 0.5244\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5916 - val_loss: 0.5080\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5928 - val_loss: 0.5191\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5954 - val_loss: 0.5149\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6021 - val_loss: 0.5163\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5958 - val_loss: 0.5165\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5878 - val_loss: 0.5503\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5825 - val_loss: 0.5224\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5858 - val_loss: 0.5235\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5895 - val_loss: 0.5404\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5875 - val_loss: 0.5115\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5956 - val_loss: 0.5083\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5859 - val_loss: 0.5225\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5923 - val_loss: 0.4935\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5814 - val_loss: 0.5104\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5785 - val_loss: 0.5028\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5808 - val_loss: 0.5138\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5767 - val_loss: 0.5044\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5805 - val_loss: 0.5403\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5813 - val_loss: 0.5437\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5894 - val_loss: 0.5379\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5877 - val_loss: 0.5137\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5987 - val_loss: 0.5257\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5895 - val_loss: 0.5109\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5833 - val_loss: 0.5224\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5733 - val_loss: 0.5219\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5760 - val_loss: 0.4943\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5794 - val_loss: 0.4988\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5763 - val_loss: 0.5293\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5732 - val_loss: 0.5132\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5736 - val_loss: 0.5124\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5740 - val_loss: 0.5037\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5684 - val_loss: 0.5302\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5889 - val_loss: 0.5026\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5812 - val_loss: 0.5133\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5875 - val_loss: 0.5317\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5808 - val_loss: 0.5127\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5663 - val_loss: 0.4900\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5813 - val_loss: 0.4995\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5842 - val_loss: 0.4942\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5730 - val_loss: 0.4980\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5744 - val_loss: 0.5028\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5613 - val_loss: 0.4824\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5672 - val_loss: 0.5012\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5690 - val_loss: 0.4859\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5771 - val_loss: 0.5166\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5821 - val_loss: 0.4917\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5789 - val_loss: 0.4787\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5786 - val_loss: 0.4838\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5645 - val_loss: 0.4880\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5619 - val_loss: 0.5043\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5596 - val_loss: 0.4965\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5737 - val_loss: 0.4973\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5663 - val_loss: 0.4849\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5662 - val_loss: 0.4948\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5633 - val_loss: 0.5066\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5601 - val_loss: 0.4730\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5751 - val_loss: 0.5234\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5747 - val_loss: 0.5048\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5669 - val_loss: 0.4739\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5694 - val_loss: 0.5047\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5594 - val_loss: 0.4849\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5571 - val_loss: 0.4698\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5767 - val_loss: 0.4995\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5726 - val_loss: 0.4957\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5672 - val_loss: 0.4794\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5648 - val_loss: 0.5011\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5629 - val_loss: 0.4971\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5605 - val_loss: 0.4621\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5567 - val_loss: 0.4701\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5606 - val_loss: 0.4671\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5515 - val_loss: 0.4868\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5579 - val_loss: 0.4853\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5492 - val_loss: 0.5082\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5745 - val_loss: 0.4795\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5599 - val_loss: 0.4911\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5639 - val_loss: 0.5149\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5569 - val_loss: 0.4687\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5498 - val_loss: 0.4625\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5520 - val_loss: 0.4660\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5709 - val_loss: 0.4806\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5630 - val_loss: 0.5107\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5589 - val_loss: 0.4864\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5637 - val_loss: 0.4641\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5487 - val_loss: 0.4732\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5561 - val_loss: 0.4709\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5560 - val_loss: 0.4861\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5497 - val_loss: 0.4572\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5622 - val_loss: 0.5013\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5544 - val_loss: 0.4874\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5548 - val_loss: 0.5046\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5636 - val_loss: 0.4638\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5566 - val_loss: 0.4725\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5554 - val_loss: 0.4652\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5528 - val_loss: 0.4671\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5495 - val_loss: 0.4809\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5487 - val_loss: 0.5137\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5523 - val_loss: 0.4668\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5601 - val_loss: 0.4876\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5508 - val_loss: 0.4820\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5493 - val_loss: 0.4715\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5461 - val_loss: 0.4675\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5391 - val_loss: 0.4661\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5577 - val_loss: 0.5071\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5505 - val_loss: 0.4646\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5487 - val_loss: 0.4676\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5542 - val_loss: 0.4772\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5507 - val_loss: 0.4614\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5516 - val_loss: 0.5137\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5535 - val_loss: 0.4781\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5458 - val_loss: 0.5022\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5472 - val_loss: 0.4876\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5518 - val_loss: 0.4763\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5457 - val_loss: 0.4644\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 940us/step - loss: 0.5438 - val_loss: 0.4847\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5441 - val_loss: 0.4696\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5411 - val_loss: 0.4792\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5408 - val_loss: 0.5013\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5380 - val_loss: 0.4724\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5435 - val_loss: 0.4749\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5394 - val_loss: 0.4848\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5459 - val_loss: 0.4684\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5394 - val_loss: 0.4918\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5392 - val_loss: 0.4689\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5373 - val_loss: 0.4828\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5469 - val_loss: 0.4860\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5483 - val_loss: 0.4567\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5454 - val_loss: 0.4535\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5528 - val_loss: 0.4959\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5494 - val_loss: 0.4705\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5412 - val_loss: 0.4754\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5432 - val_loss: 0.4743\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5405 - val_loss: 0.4799\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5388 - val_loss: 0.4626\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5420 - val_loss: 0.4876\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5371 - val_loss: 0.4532\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5492 - val_loss: 0.4556\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5386 - val_loss: 0.4548\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5325 - val_loss: 0.4742\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5353 - val_loss: 0.4781\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5380 - val_loss: 0.4569\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5456 - val_loss: 0.4609\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5354 - val_loss: 0.4555\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5360 - val_loss: 0.4577\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5364 - val_loss: 0.4733\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5437 - val_loss: 0.4993\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5462 - val_loss: 0.4715\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5403 - val_loss: 0.4766\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5405 - val_loss: 0.4448\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5424 - val_loss: 0.4778\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5550 - val_loss: 0.4588\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5350 - val_loss: 0.4748\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5389 - val_loss: 0.4891\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5319 - val_loss: 0.4646\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5410 - val_loss: 0.4680\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5364 - val_loss: 0.4705\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5355 - val_loss: 0.4661\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5358 - val_loss: 0.4710\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5345 - val_loss: 0.4654\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5384 - val_loss: 0.4678\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5405 - val_loss: 0.5000\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5324 - val_loss: 0.4413\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5282 - val_loss: 0.4671\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 560us/step - loss: 0.5301 - val_loss: 0.4675\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5315 - val_loss: 0.4748\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5355 - val_loss: 0.4608\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5359 - val_loss: 0.4601\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5371 - val_loss: 0.4511\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5374 - val_loss: 0.4737\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5322 - val_loss: 0.4618\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5302 - val_loss: 0.4506\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5377 - val_loss: 0.4562\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5253 - val_loss: 0.4853\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5315 - val_loss: 0.4584\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5261 - val_loss: 0.4595\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5298 - val_loss: 0.4590\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5291 - val_loss: 0.4586\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5334 - val_loss: 0.4648\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5366 - val_loss: 0.4676\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5258 - val_loss: 0.4633\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5343 - val_loss: 0.4418\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5389 - val_loss: 0.4386\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5281 - val_loss: 0.4418\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5199 - val_loss: 0.4576\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5265 - val_loss: 0.4684\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5297 - val_loss: 0.4986\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5308 - val_loss: 0.4726\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5324 - val_loss: 0.4623\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5311 - val_loss: 0.4871\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5309 - val_loss: 0.4583\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5317 - val_loss: 0.4627\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5249 - val_loss: 0.4701\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5249 - val_loss: 0.4681\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5329 - val_loss: 0.4538\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5315 - val_loss: 0.4745\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5363 - val_loss: 0.4809\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5508 - val_loss: 0.4533\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5524 - val_loss: 0.4864\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5453 - val_loss: 0.4660\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5390 - val_loss: 0.4563\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5269 - val_loss: 0.4446\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5334 - val_loss: 0.4618\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5344 - val_loss: 0.4565\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5214 - val_loss: 0.4531\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5251 - val_loss: 0.4592\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5207 - val_loss: 0.4744\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5235 - val_loss: 0.4387\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5239 - val_loss: 0.4718\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5206 - val_loss: 0.4479\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5226 - val_loss: 0.4793\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5214 - val_loss: 0.4544\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5239 - val_loss: 0.4570\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5153 - val_loss: 0.4490\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5209 - val_loss: 0.4838\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5282 - val_loss: 0.4386\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5282 - val_loss: 0.4478\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5245 - val_loss: 0.4424\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5202 - val_loss: 0.4555\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5264 - val_loss: 0.4636\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5215 - val_loss: 0.4538\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5347 - val_loss: 0.4676\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5273 - val_loss: 0.4622\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5203 - val_loss: 0.4549\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5344 - val_loss: 0.4677\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5355 - val_loss: 0.4543\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5217 - val_loss: 0.4629\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5280 - val_loss: 0.4445\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5312 - val_loss: 0.4608\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5182 - val_loss: 0.4476\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5203 - val_loss: 0.4601\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5247 - val_loss: 0.4400\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5181 - val_loss: 0.4645\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5194 - val_loss: 0.4375\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5306 - val_loss: 0.4746\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5221 - val_loss: 0.4372\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5205 - val_loss: 0.4464\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5181 - val_loss: 0.4409\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5255 - val_loss: 0.4418\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5229 - val_loss: 0.4416\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5200 - val_loss: 0.4371\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5145 - val_loss: 0.4519\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5177 - val_loss: 0.4487\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5163 - val_loss: 0.4512\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5306 - val_loss: 0.4415\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5224 - val_loss: 0.4463\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5210 - val_loss: 0.4780\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5206 - val_loss: 0.4422\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5199 - val_loss: 0.4460\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5218 - val_loss: 0.4386\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5099 - val_loss: 0.4384\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5127 - val_loss: 0.4482\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5144 - val_loss: 0.4533\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5167 - val_loss: 0.4536\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5176 - val_loss: 0.4466\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5273 - val_loss: 0.4456\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5154 - val_loss: 0.4475\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5207 - val_loss: 0.4765\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5172 - val_loss: 0.4408\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5226 - val_loss: 0.4496\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5114 - val_loss: 0.4527\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5188 - val_loss: 0.4533\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5216 - val_loss: 0.4449\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5206 - val_loss: 0.4377\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5140 - val_loss: 0.4387\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5096 - val_loss: 0.4494\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5243 - val_loss: 0.4324\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5224 - val_loss: 0.4553\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5350 - val_loss: 0.4704\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5230 - val_loss: 0.4430\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5181 - val_loss: 0.4382\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5188 - val_loss: 0.4336\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5120 - val_loss: 0.4537\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5164 - val_loss: 0.4693\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5283 - val_loss: 0.4450\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5126 - val_loss: 0.4323\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5111 - val_loss: 0.4560\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5149 - val_loss: 0.4408\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5224 - val_loss: 0.4427\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5150 - val_loss: 0.4397\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5126 - val_loss: 0.4298\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5227 - val_loss: 0.4526\n",
      "Epoch 373/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5218 - val_loss: 0.4322\n",
      "Epoch 374/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5161 - val_loss: 0.4612\n",
      "Epoch 375/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5130 - val_loss: 0.4335\n",
      "Epoch 376/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5091 - val_loss: 0.4475\n",
      "Epoch 377/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5163 - val_loss: 0.4347\n",
      "Epoch 378/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5101 - val_loss: 0.4521\n",
      "Epoch 379/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5162 - val_loss: 0.4450\n",
      "Epoch 380/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5188 - val_loss: 0.4634\n",
      "Epoch 381/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5207 - val_loss: 0.5083\n",
      "Epoch 382/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5330 - val_loss: 0.4526\n",
      "Epoch 383/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5146 - val_loss: 0.4420\n",
      "Epoch 384/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5095 - val_loss: 0.4507\n",
      "Epoch 385/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5171 - val_loss: 0.4547\n",
      "Epoch 386/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5132 - val_loss: 0.4283\n",
      "Epoch 387/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5081 - val_loss: 0.4365\n",
      "Epoch 388/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5080 - val_loss: 0.4442\n",
      "Epoch 389/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5071 - val_loss: 0.4343\n",
      "Epoch 390/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5075 - val_loss: 0.4439\n",
      "Epoch 391/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5136 - val_loss: 0.4390\n",
      "Epoch 392/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5177 - val_loss: 0.4378\n",
      "Epoch 393/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5149 - val_loss: 0.4708\n",
      "Epoch 394/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5214 - val_loss: 0.4329\n",
      "Epoch 395/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5081 - val_loss: 0.4472\n",
      "Epoch 396/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5088 - val_loss: 0.4316\n",
      "Epoch 397/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5117 - val_loss: 0.4574\n",
      "Epoch 398/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5168 - val_loss: 0.4650\n",
      "Epoch 399/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5106 - val_loss: 0.4369\n",
      "Epoch 400/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5215 - val_loss: 0.4940\n",
      "Epoch 401/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5376 - val_loss: 0.4312\n",
      "Epoch 402/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5147 - val_loss: 0.4616\n",
      "Epoch 403/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5071 - val_loss: 0.4364\n",
      "Epoch 404/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5130 - val_loss: 0.4375\n",
      "Epoch 405/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5147 - val_loss: 0.4654\n",
      "Epoch 406/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5135 - val_loss: 0.4696\n",
      "Epoch 407/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5157 - val_loss: 0.4314\n",
      "Epoch 408/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5054 - val_loss: 0.4470\n",
      "Epoch 409/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5138 - val_loss: 0.4626\n",
      "Epoch 410/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5210 - val_loss: 0.4316\n",
      "Epoch 411/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5129 - val_loss: 0.4436\n",
      "Epoch 412/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5061 - val_loss: 0.4366\n",
      "Epoch 413/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5141 - val_loss: 0.4303\n",
      "Epoch 414/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5092 - val_loss: 0.4351\n",
      "Epoch 415/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5114 - val_loss: 0.4435\n",
      "Epoch 416/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5048 - val_loss: 0.4280\n",
      "Epoch 417/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5058 - val_loss: 0.4460\n",
      "Epoch 418/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5136 - val_loss: 0.4591\n",
      "Epoch 419/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5041 - val_loss: 0.4269\n",
      "Epoch 420/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5063 - val_loss: 0.4414\n",
      "Epoch 421/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5108 - val_loss: 0.4302\n",
      "Epoch 422/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5117 - val_loss: 0.4545\n",
      "Epoch 423/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5131 - val_loss: 0.4510\n",
      "Epoch 424/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5095 - val_loss: 0.4436\n",
      "Epoch 425/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5090 - val_loss: 0.4820\n",
      "Epoch 426/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5303 - val_loss: 0.4473\n",
      "Epoch 427/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5070 - val_loss: 0.4339\n",
      "Epoch 428/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5124 - val_loss: 0.4452\n",
      "Epoch 429/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5088 - val_loss: 0.4236\n",
      "Epoch 430/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5123 - val_loss: 0.4310\n",
      "Epoch 431/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.5102 - val_loss: 0.4242\n",
      "Epoch 432/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5051 - val_loss: 0.4521\n",
      "Epoch 433/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5063 - val_loss: 0.4444\n",
      "Epoch 434/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5031 - val_loss: 0.4262\n",
      "Epoch 435/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5091 - val_loss: 0.4505\n",
      "Epoch 436/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5117 - val_loss: 0.4263\n",
      "Epoch 437/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5072 - val_loss: 0.4422\n",
      "Epoch 438/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5138 - val_loss: 0.4415\n",
      "Epoch 439/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5146 - val_loss: 0.4307\n",
      "Epoch 440/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5092 - val_loss: 0.4515\n",
      "Epoch 441/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5097 - val_loss: 0.4362\n",
      "Epoch 442/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5060 - val_loss: 0.4396\n",
      "Epoch 443/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5117 - val_loss: 0.4492\n",
      "Epoch 444/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5110 - val_loss: 0.4351\n",
      "Epoch 445/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5131 - val_loss: 0.4641\n",
      "Epoch 446/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5102 - val_loss: 0.4410\n",
      "Epoch 447/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5027 - val_loss: 0.4418\n",
      "Epoch 448/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5071 - val_loss: 0.4301\n",
      "Epoch 449/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5158 - val_loss: 0.4343\n",
      "Epoch 450/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5174 - val_loss: 0.4537\n",
      "Epoch 451/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5078 - val_loss: 0.4381\n",
      "Epoch 452/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5116 - val_loss: 0.4313\n",
      "Epoch 453/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5084 - val_loss: 0.4256\n",
      "Epoch 454/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5076 - val_loss: 0.4388\n",
      "Epoch 455/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5002 - val_loss: 0.4343\n",
      "Epoch 456/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5015 - val_loss: 0.4284\n",
      "Epoch 457/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5025 - val_loss: 0.4409\n",
      "Epoch 458/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5020 - val_loss: 0.4405\n",
      "Epoch 459/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5079 - val_loss: 0.4620\n",
      "Epoch 460/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5061 - val_loss: 0.4601\n",
      "Epoch 461/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5028 - val_loss: 0.4257\n",
      "Epoch 462/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5035 - val_loss: 0.4455\n",
      "Epoch 463/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5125 - val_loss: 0.4441\n",
      "Epoch 464/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5065 - val_loss: 0.4253\n",
      "Epoch 465/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5012 - val_loss: 0.4300\n",
      "Epoch 466/3000\n",
      "33/33 [==============================] - 0s 565us/step - loss: 0.5005 - val_loss: 0.4234\n",
      "Epoch 467/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5135 - val_loss: 0.4533\n",
      "Epoch 468/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5071 - val_loss: 0.4271\n",
      "Epoch 469/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5022 - val_loss: 0.4178\n",
      "Epoch 470/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5089 - val_loss: 0.4307\n",
      "Epoch 471/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5059 - val_loss: 0.4278\n",
      "Epoch 472/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5034 - val_loss: 0.4279\n",
      "Epoch 473/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.5055 - val_loss: 0.4346\n",
      "Epoch 474/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5103 - val_loss: 0.4465\n",
      "Epoch 475/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5061 - val_loss: 0.4392\n",
      "Epoch 476/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5091 - val_loss: 0.4384\n",
      "Epoch 477/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5025 - val_loss: 0.4317\n",
      "Epoch 478/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5034 - val_loss: 0.4463\n",
      "Epoch 479/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5059 - val_loss: 0.4249\n",
      "Epoch 480/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5052 - val_loss: 0.4337\n",
      "Epoch 481/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5062 - val_loss: 0.4555\n",
      "Epoch 482/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5047 - val_loss: 0.4353\n",
      "Epoch 483/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5044 - val_loss: 0.4353\n",
      "Epoch 484/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5034 - val_loss: 0.4207\n",
      "Epoch 485/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5043 - val_loss: 0.4402\n",
      "Epoch 486/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5013 - val_loss: 0.4319\n",
      "Epoch 487/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5000 - val_loss: 0.4236\n",
      "Epoch 488/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5070 - val_loss: 0.4494\n",
      "Epoch 489/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5116 - val_loss: 0.4791\n",
      "Epoch 490/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5158 - val_loss: 0.4450\n",
      "Epoch 491/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5124 - val_loss: 0.4339\n",
      "Epoch 492/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5047 - val_loss: 0.4348\n",
      "Epoch 493/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5005 - val_loss: 0.4373\n",
      "Epoch 494/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5014 - val_loss: 0.4266\n",
      "Epoch 495/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5008 - val_loss: 0.4238\n",
      "Epoch 496/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5106 - val_loss: 0.4371\n",
      "Epoch 497/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5198 - val_loss: 0.4208\n",
      "Epoch 498/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5096 - val_loss: 0.4278\n",
      "Epoch 499/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.4995 - val_loss: 0.4279\n",
      "Epoch 500/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.4995 - val_loss: 0.4418\n",
      "Epoch 501/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5070 - val_loss: 0.4423\n",
      "Epoch 502/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.4996 - val_loss: 0.4527\n",
      "Epoch 503/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5016 - val_loss: 0.4375\n",
      "Epoch 504/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5023 - val_loss: 0.4293\n",
      "Epoch 505/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5031 - val_loss: 0.4366\n",
      "Epoch 506/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5090 - val_loss: 0.4320\n",
      "Epoch 507/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5045 - val_loss: 0.4239\n",
      "Epoch 508/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.4973 - val_loss: 0.4303\n",
      "Epoch 509/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5077 - val_loss: 0.4280\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.3834 - val_loss: 1.7209\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 1.5592 - val_loss: 1.2981\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 1.0852 - val_loss: 1.2238\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 1.0234 - val_loss: 1.1034\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.9813 - val_loss: 1.0880\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.9491 - val_loss: 1.0765\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.9319 - val_loss: 1.0562\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.8989 - val_loss: 1.0232\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.8941 - val_loss: 1.0520\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8851 - val_loss: 1.0882\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.8806 - val_loss: 0.9995\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.8540 - val_loss: 0.9866\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.8522 - val_loss: 0.9626\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.8282 - val_loss: 0.9598\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.8226 - val_loss: 0.9582\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.8150 - val_loss: 0.9394\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.8022 - val_loss: 0.9443\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.8062 - val_loss: 0.9590\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.7925 - val_loss: 0.9177\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.7883 - val_loss: 0.8815\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7832 - val_loss: 0.8694\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7583 - val_loss: 0.9002\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7567 - val_loss: 0.9003\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.7496 - val_loss: 0.9135\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7414 - val_loss: 0.8482\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7382 - val_loss: 0.8477\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7311 - val_loss: 0.8112\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7409 - val_loss: 0.8408\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.7188 - val_loss: 0.8484\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.7086 - val_loss: 0.7712\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6958 - val_loss: 0.7882\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.7017 - val_loss: 0.8151\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6920 - val_loss: 0.7702\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6797 - val_loss: 0.8029\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6671 - val_loss: 0.7514\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.6637 - val_loss: 0.7569\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.6672 - val_loss: 0.8125\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6598 - val_loss: 0.7369\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6492 - val_loss: 0.7625\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6614 - val_loss: 0.7966\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6575 - val_loss: 0.7524\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6392 - val_loss: 0.7116\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6334 - val_loss: 0.7413\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6331 - val_loss: 0.6944\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6193 - val_loss: 0.7315\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.6195 - val_loss: 0.7071\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6326 - val_loss: 0.6942\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6185 - val_loss: 0.6858\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6150 - val_loss: 0.7239\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6171 - val_loss: 0.7198\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6082 - val_loss: 0.6889\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6047 - val_loss: 0.6966\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6106 - val_loss: 0.7117\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5985 - val_loss: 0.6761\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5927 - val_loss: 0.6779\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5942 - val_loss: 0.6903\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5943 - val_loss: 0.6862\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6006 - val_loss: 0.6547\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5904 - val_loss: 0.7076\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5817 - val_loss: 0.6661\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5923 - val_loss: 0.6829\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5876 - val_loss: 0.6679\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5897 - val_loss: 0.6790\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.6129 - val_loss: 0.7120\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5824 - val_loss: 0.6986\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5951 - val_loss: 0.6637\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5849 - val_loss: 0.6642\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5775 - val_loss: 0.6535\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5738 - val_loss: 0.6729\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5803 - val_loss: 0.6482\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5725 - val_loss: 0.6629\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5686 - val_loss: 0.6363\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5756 - val_loss: 0.7432\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5973 - val_loss: 0.6452\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5720 - val_loss: 0.6469\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5738 - val_loss: 0.6364\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5598 - val_loss: 0.6588\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5612 - val_loss: 0.6399\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5667 - val_loss: 0.6393\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5709 - val_loss: 0.6932\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5737 - val_loss: 0.6734\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5725 - val_loss: 0.6527\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5606 - val_loss: 0.6531\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5570 - val_loss: 0.6250\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5617 - val_loss: 0.6879\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5681 - val_loss: 0.6650\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5588 - val_loss: 0.6403\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5569 - val_loss: 0.6749\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5692 - val_loss: 0.6310\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5636 - val_loss: 0.6521\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5632 - val_loss: 0.6401\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5652 - val_loss: 0.6243\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5524 - val_loss: 0.6440\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5552 - val_loss: 0.6276\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5604 - val_loss: 0.6368\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5627 - val_loss: 0.6141\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5475 - val_loss: 0.6313\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5535 - val_loss: 0.6680\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5502 - val_loss: 0.6293\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5471 - val_loss: 0.6324\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5572 - val_loss: 0.6231\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5592 - val_loss: 0.6227\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5510 - val_loss: 0.6381\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5553 - val_loss: 0.6456\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5485 - val_loss: 0.6643\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5559 - val_loss: 0.6599\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5499 - val_loss: 0.6711\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5413 - val_loss: 0.6402\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5521 - val_loss: 0.6538\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5486 - val_loss: 0.6206\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5515 - val_loss: 0.6035\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5437 - val_loss: 0.6724\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5414 - val_loss: 0.6820\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5462 - val_loss: 0.6222\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5429 - val_loss: 0.6622\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5541 - val_loss: 0.6480\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5479 - val_loss: 0.6226\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5438 - val_loss: 0.6851\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5317 - val_loss: 0.6244\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5486 - val_loss: 0.6131\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5394 - val_loss: 0.6221\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5376 - val_loss: 0.6167\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5374 - val_loss: 0.6590\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5428 - val_loss: 0.6226\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5380 - val_loss: 0.6271\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5533 - val_loss: 0.6034\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5474 - val_loss: 0.6131\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5307 - val_loss: 0.6318\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5336 - val_loss: 0.6268\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5326 - val_loss: 0.6280\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5406 - val_loss: 0.6011\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5260 - val_loss: 0.6118\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5295 - val_loss: 0.5981\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5490 - val_loss: 0.6213\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5335 - val_loss: 0.6161\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5306 - val_loss: 0.6375\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5330 - val_loss: 0.6184\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5281 - val_loss: 0.6176\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5352 - val_loss: 0.7101\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5443 - val_loss: 0.6201\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5296 - val_loss: 0.6066\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5307 - val_loss: 0.6161\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5401 - val_loss: 0.6247\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5302 - val_loss: 0.6035\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5195 - val_loss: 0.6003\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5331 - val_loss: 0.6329\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5371 - val_loss: 0.6181\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5259 - val_loss: 0.5958\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5327 - val_loss: 0.6109\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5364 - val_loss: 0.5994\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5283 - val_loss: 0.6511\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5291 - val_loss: 0.6326\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5235 - val_loss: 0.5974\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5265 - val_loss: 0.5994\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5271 - val_loss: 0.6098\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5335 - val_loss: 0.6328\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5410 - val_loss: 0.5986\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5299 - val_loss: 0.6055\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5238 - val_loss: 0.6031\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5286 - val_loss: 0.6512\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5198 - val_loss: 0.6137\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5241 - val_loss: 0.6071\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5345 - val_loss: 0.6025\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5250 - val_loss: 0.5819\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5271 - val_loss: 0.5997\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5241 - val_loss: 0.6111\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5172 - val_loss: 0.6327\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5168 - val_loss: 0.6703\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5268 - val_loss: 0.5883\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5094 - val_loss: 0.6341\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5194 - val_loss: 0.6255\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5207 - val_loss: 0.5978\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5205 - val_loss: 0.6063\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5180 - val_loss: 0.6055\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5211 - val_loss: 0.5910\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5269 - val_loss: 0.6421\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5194 - val_loss: 0.5953\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5270 - val_loss: 0.6220\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5146 - val_loss: 0.6044\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5125 - val_loss: 0.5907\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5105 - val_loss: 0.5936\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5218 - val_loss: 0.5934\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5143 - val_loss: 0.5910\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5062 - val_loss: 0.5966\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5183 - val_loss: 0.6149\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5232 - val_loss: 0.6206\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5146 - val_loss: 0.6544\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5221 - val_loss: 0.6242\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5185 - val_loss: 0.6128\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5156 - val_loss: 0.5936\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5091 - val_loss: 0.6036\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5127 - val_loss: 0.6077\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5159 - val_loss: 0.6018\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 659us/step - loss: 0.5107 - val_loss: 0.6250\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.6146\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5078 - val_loss: 0.6057\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5106 - val_loss: 0.6069\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5032 - val_loss: 0.6036\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5171 - val_loss: 0.6480\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5099 - val_loss: 0.6290\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5112 - val_loss: 0.6043\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5223 - val_loss: 0.5919\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5177 - val_loss: 0.6281\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5049 - val_loss: 0.6197\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 6.5027 - val_loss: 2.1505\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 654us/step - loss: 1.8511 - val_loss: 1.3170\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 1.2507 - val_loss: 1.1376\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 1.1671 - val_loss: 1.1159\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 1.1022 - val_loss: 1.0823\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 1.0579 - val_loss: 1.0244\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 1.0429 - val_loss: 1.0164\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 1.0155 - val_loss: 0.9572\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 1.0014 - val_loss: 1.0010\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.9938 - val_loss: 0.9828\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.9584 - val_loss: 0.9144\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.9563 - val_loss: 0.9223\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.9255 - val_loss: 0.8956\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.9193 - val_loss: 0.9059\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.9159 - val_loss: 0.8960\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 664us/step - loss: 0.8960 - val_loss: 0.8751\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.8757 - val_loss: 0.8534\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8665 - val_loss: 0.8342\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 661us/step - loss: 0.8608 - val_loss: 0.8370\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.8365 - val_loss: 0.8124\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.8300 - val_loss: 0.8681\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.8404 - val_loss: 0.8062\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.8105 - val_loss: 0.8026\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.8153 - val_loss: 0.7725\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7956 - val_loss: 0.7986\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7939 - val_loss: 0.7795\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.7610 - val_loss: 0.7511\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.7583 - val_loss: 0.7559\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.7623 - val_loss: 0.7776\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7605 - val_loss: 0.7375\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.7358 - val_loss: 0.7252\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.7336 - val_loss: 0.7579\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.7288 - val_loss: 0.7372\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7155 - val_loss: 0.7319\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.7149 - val_loss: 0.7192\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.7023 - val_loss: 0.7282\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6929 - val_loss: 0.7151\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6877 - val_loss: 0.7137\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6806 - val_loss: 0.7357\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6889 - val_loss: 0.6943\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6765 - val_loss: 0.7244\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6773 - val_loss: 0.6947\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6705 - val_loss: 0.6879\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6638 - val_loss: 0.6877\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6635 - val_loss: 0.7214\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6561 - val_loss: 0.6788\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.6565 - val_loss: 0.6807\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6612 - val_loss: 0.7064\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6489 - val_loss: 0.6811\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6576 - val_loss: 0.7216\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6430 - val_loss: 0.6808\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6373 - val_loss: 0.6788\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6383 - val_loss: 0.6769\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6316 - val_loss: 0.7290\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6292 - val_loss: 0.6456\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6292 - val_loss: 0.6774\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6286 - val_loss: 0.7519\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6325 - val_loss: 0.6713\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6282 - val_loss: 0.6469\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6298 - val_loss: 0.6804\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6251 - val_loss: 0.7155\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6453 - val_loss: 0.6705\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6063 - val_loss: 0.6637\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6136 - val_loss: 0.6597\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6247 - val_loss: 0.6875\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 819us/step - loss: 0.6226 - val_loss: 0.6759\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.6167 - val_loss: 0.6538\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.6032 - val_loss: 0.6500\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6036 - val_loss: 0.6617\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6022 - val_loss: 0.6565\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6005 - val_loss: 0.6462\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5983 - val_loss: 0.6605\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5932 - val_loss: 0.6424\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5935 - val_loss: 0.6576\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5936 - val_loss: 0.6612\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5968 - val_loss: 0.6552\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5852 - val_loss: 0.6349\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5950 - val_loss: 0.6188\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6050 - val_loss: 0.7147\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6102 - val_loss: 0.6342\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6098 - val_loss: 0.6613\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6181 - val_loss: 0.6610\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5989 - val_loss: 0.6521\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5985 - val_loss: 0.6362\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5874 - val_loss: 0.6353\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5898 - val_loss: 0.6534\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5948 - val_loss: 0.6658\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5915 - val_loss: 0.6686\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5918 - val_loss: 0.6157\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5814 - val_loss: 0.6420\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5925 - val_loss: 0.6472\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5859 - val_loss: 0.6460\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5760 - val_loss: 0.6120\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5807 - val_loss: 0.6253\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5899 - val_loss: 0.6203\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5739 - val_loss: 0.6562\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 564us/step - loss: 0.5924 - val_loss: 0.6301\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5810 - val_loss: 0.6581\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5886 - val_loss: 0.6128\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5842 - val_loss: 0.6649\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5790 - val_loss: 0.6264\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5769 - val_loss: 0.6149\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5793 - val_loss: 0.6337\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5753 - val_loss: 0.6537\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5797 - val_loss: 0.6818\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5903 - val_loss: 0.6465\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5683 - val_loss: 0.6180\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5655 - val_loss: 0.6894\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5734 - val_loss: 0.6500\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5648 - val_loss: 0.6257\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5734 - val_loss: 0.6299\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5710 - val_loss: 0.6115\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5722 - val_loss: 0.6568\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5672 - val_loss: 0.6289\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5902 - val_loss: 0.6359\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5724 - val_loss: 0.6587\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5719 - val_loss: 0.6127\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5699 - val_loss: 0.6239\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5842 - val_loss: 0.6494\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5731 - val_loss: 0.6020\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5769 - val_loss: 0.6207\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5731 - val_loss: 0.6347\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5729 - val_loss: 0.6390\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5618 - val_loss: 0.6069\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5572 - val_loss: 0.6317\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5590 - val_loss: 0.6191\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5633 - val_loss: 0.6283\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5578 - val_loss: 0.6169\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5647 - val_loss: 0.6023\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5537 - val_loss: 0.6374\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5550 - val_loss: 0.6260\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5475 - val_loss: 0.6055\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5740 - val_loss: 0.6100\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5549 - val_loss: 0.6338\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5617 - val_loss: 0.6336\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5537 - val_loss: 0.5949\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5483 - val_loss: 0.6095\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5483 - val_loss: 0.6437\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5580 - val_loss: 0.6017\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5493 - val_loss: 0.6151\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5548 - val_loss: 0.6097\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5633 - val_loss: 0.6236\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5556 - val_loss: 0.6654\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5725 - val_loss: 0.6025\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5507 - val_loss: 0.5959\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5515 - val_loss: 0.6019\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5530 - val_loss: 0.5917\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5607 - val_loss: 0.6554\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5475 - val_loss: 0.6379\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5619 - val_loss: 0.5987\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5442 - val_loss: 0.6143\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5451 - val_loss: 0.5936\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5562 - val_loss: 0.6115\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5471 - val_loss: 0.6178\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5538 - val_loss: 0.6084\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5480 - val_loss: 0.6463\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5465 - val_loss: 0.6265\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5541 - val_loss: 0.6148\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5558 - val_loss: 0.5970\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5539 - val_loss: 0.6091\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5569 - val_loss: 0.5984\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5444 - val_loss: 0.5846\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5463 - val_loss: 0.6196\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5534 - val_loss: 0.6113\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5396 - val_loss: 0.6239\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5538 - val_loss: 0.6363\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5475 - val_loss: 0.6045\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5376 - val_loss: 0.6289\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5524 - val_loss: 0.6039\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5395 - val_loss: 0.5980\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5513 - val_loss: 0.5834\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5467 - val_loss: 0.5903\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5501 - val_loss: 0.5878\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5422 - val_loss: 0.5911\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5347 - val_loss: 0.6002\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5390 - val_loss: 0.5842\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5459 - val_loss: 0.6595\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5394 - val_loss: 0.6038\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5432 - val_loss: 0.5879\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5382 - val_loss: 0.6108\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5381 - val_loss: 0.5794\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5449 - val_loss: 0.5984\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5417 - val_loss: 0.6224\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5445 - val_loss: 0.6040\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5559 - val_loss: 0.6404\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5586 - val_loss: 0.5996\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5471 - val_loss: 0.6144\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5433 - val_loss: 0.5859\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5385 - val_loss: 0.6112\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5375 - val_loss: 0.5904\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5340 - val_loss: 0.5767\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5282 - val_loss: 0.6036\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5554 - val_loss: 0.6227\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5443 - val_loss: 0.5818\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5287 - val_loss: 0.5768\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5387 - val_loss: 0.5903\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5270 - val_loss: 0.6039\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5331 - val_loss: 0.6001\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5382 - val_loss: 0.5838\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5403 - val_loss: 0.5938\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5405 - val_loss: 0.6013\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5333 - val_loss: 0.5842\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5274 - val_loss: 0.5972\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5324 - val_loss: 0.6044\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5405 - val_loss: 0.5944\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5343 - val_loss: 0.5775\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5410 - val_loss: 0.6061\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5332 - val_loss: 0.5844\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5311 - val_loss: 0.5667\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5360 - val_loss: 0.6247\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5453 - val_loss: 0.5767\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5454 - val_loss: 0.5786\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5411 - val_loss: 0.5778\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5227 - val_loss: 0.5975\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5299 - val_loss: 0.5971\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5343 - val_loss: 0.6085\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5374 - val_loss: 0.5748\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5274 - val_loss: 0.5675\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5242 - val_loss: 0.5817\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5231 - val_loss: 0.5977\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5285 - val_loss: 0.5687\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5240 - val_loss: 0.5723\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5264 - val_loss: 0.6035\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5323 - val_loss: 0.5675\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5260 - val_loss: 0.5864\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5329 - val_loss: 0.5911\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5224 - val_loss: 0.5866\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5427 - val_loss: 0.6068\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5309 - val_loss: 0.5521\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5292 - val_loss: 0.5650\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5213 - val_loss: 0.5862\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5269 - val_loss: 0.5829\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5311 - val_loss: 0.5941\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5288 - val_loss: 0.5854\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5276 - val_loss: 0.5873\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5170 - val_loss: 0.5689\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5273 - val_loss: 0.5587\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5212 - val_loss: 0.5944\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5301 - val_loss: 0.5891\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5292 - val_loss: 0.5719\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5227 - val_loss: 0.6082\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5200 - val_loss: 0.5771\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5394 - val_loss: 0.5631\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5227 - val_loss: 0.5748\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5256 - val_loss: 0.5920\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5379 - val_loss: 0.5758\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5162 - val_loss: 0.5841\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5231 - val_loss: 0.5731\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5152 - val_loss: 0.5579\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5201 - val_loss: 0.6153\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5382 - val_loss: 0.5891\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5245 - val_loss: 0.5677\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5333 - val_loss: 0.6069\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5248 - val_loss: 0.5573\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5281 - val_loss: 0.5731\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5234 - val_loss: 0.5668\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5146 - val_loss: 0.6095\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5369 - val_loss: 0.5773\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5232 - val_loss: 0.6032\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5336 - val_loss: 0.5620\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5217 - val_loss: 0.5782\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5180 - val_loss: 0.5787\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5259 - val_loss: 0.5572\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5194 - val_loss: 0.5871\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5179 - val_loss: 0.5614\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5223 - val_loss: 0.5866\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5169 - val_loss: 0.5696\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5236 - val_loss: 0.5573\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5183 - val_loss: 0.5769\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 5.1474 - val_loss: 1.6721\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 663us/step - loss: 1.6309 - val_loss: 1.3614\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 1.3093 - val_loss: 1.2445\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 1.1940 - val_loss: 1.1320\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 1.1526 - val_loss: 1.1323\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 1.1269 - val_loss: 1.0884\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 1.0763 - val_loss: 1.0319\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.0469 - val_loss: 0.9791\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 1.0286 - val_loss: 0.9790\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.9880 - val_loss: 0.9617\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.9901 - val_loss: 1.0020\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.9790 - val_loss: 0.9533\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.9549 - val_loss: 0.9314\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.9420 - val_loss: 0.9086\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.9295 - val_loss: 0.9005\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.9146 - val_loss: 0.8625\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.9052 - val_loss: 0.8684\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.8659 - val_loss: 0.8423\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.8768 - val_loss: 0.8853\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.8536 - val_loss: 0.8179\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.8587 - val_loss: 0.8742\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.8289 - val_loss: 0.8774\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8240 - val_loss: 0.8451\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.8028 - val_loss: 0.8138\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.8066 - val_loss: 0.8042\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7858 - val_loss: 0.7921\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7752 - val_loss: 0.7656\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7832 - val_loss: 0.7906\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.7701 - val_loss: 0.7966\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.7768 - val_loss: 0.7761\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7387 - val_loss: 0.7417\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7345 - val_loss: 0.7658\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.7257 - val_loss: 0.8387\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7158 - val_loss: 0.7391\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7109 - val_loss: 0.7189\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.7298 - val_loss: 0.7075\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7210 - val_loss: 0.6990\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.7053 - val_loss: 0.6967\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6850 - val_loss: 0.7167\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6923 - val_loss: 0.7092\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6736 - val_loss: 0.7103\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6732 - val_loss: 0.8631\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6651 - val_loss: 0.7989\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6543 - val_loss: 0.6731\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6472 - val_loss: 0.7152\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6577 - val_loss: 0.7545\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6369 - val_loss: 0.6918\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6387 - val_loss: 0.6840\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6444 - val_loss: 0.6989\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6199 - val_loss: 0.6933\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6239 - val_loss: 0.6892\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6209 - val_loss: 0.7435\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6306 - val_loss: 0.6418\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6275 - val_loss: 0.6622\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6027 - val_loss: 0.6487\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6083 - val_loss: 0.6567\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6074 - val_loss: 0.6695\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6044 - val_loss: 0.6490\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6001 - val_loss: 0.6693\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6174 - val_loss: 0.6331\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6008 - val_loss: 0.6785\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5940 - val_loss: 0.6346\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5891 - val_loss: 0.6355\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6011 - val_loss: 0.6432\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6107 - val_loss: 0.6270\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6070 - val_loss: 0.6788\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5863 - val_loss: 0.6336\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5894 - val_loss: 0.6661\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6069 - val_loss: 0.6497\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5815 - val_loss: 0.6380\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5798 - val_loss: 0.6563\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5933 - val_loss: 0.6355\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5800 - val_loss: 0.6474\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 643us/step - loss: 0.5737 - val_loss: 0.6421\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5686 - val_loss: 0.6133\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5722 - val_loss: 0.6434\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5845 - val_loss: 0.6191\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5724 - val_loss: 0.6877\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5781 - val_loss: 0.6263\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5632 - val_loss: 0.6234\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5770 - val_loss: 0.6576\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5782 - val_loss: 0.6699\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5827 - val_loss: 0.6276\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5784 - val_loss: 0.6000\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5705 - val_loss: 0.6270\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5639 - val_loss: 0.6093\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5614 - val_loss: 0.6346\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.5677 - val_loss: 0.6287\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5666 - val_loss: 0.5867\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5733 - val_loss: 0.6199\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5621 - val_loss: 0.6330\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5724 - val_loss: 0.6483\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5826 - val_loss: 0.6345\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5549 - val_loss: 0.6042\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5803 - val_loss: 0.6097\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5773 - val_loss: 0.5882\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5579 - val_loss: 0.5984\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5681 - val_loss: 0.6039\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5609 - val_loss: 0.6010\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5619 - val_loss: 0.6115\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5726 - val_loss: 0.5975\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5622 - val_loss: 0.6105\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5582 - val_loss: 0.6102\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5642 - val_loss: 0.6060\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5592 - val_loss: 0.6618\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5417 - val_loss: 0.5820\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5564 - val_loss: 0.6005\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5506 - val_loss: 0.5995\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5451 - val_loss: 0.6140\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5665 - val_loss: 0.6210\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5551 - val_loss: 0.6030\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5695 - val_loss: 0.6131\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5736 - val_loss: 0.6110\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5550 - val_loss: 0.6042\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5496 - val_loss: 0.6093\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5470 - val_loss: 0.5966\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5507 - val_loss: 0.5928\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5519 - val_loss: 0.6289\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5529 - val_loss: 0.5980\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5388 - val_loss: 0.5702\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5388 - val_loss: 0.5794\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5388 - val_loss: 0.5928\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5343 - val_loss: 0.5772\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5445 - val_loss: 0.5833\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5418 - val_loss: 0.6200\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5376 - val_loss: 0.6042\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5347 - val_loss: 0.6320\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5415 - val_loss: 0.6007\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5356 - val_loss: 0.5976\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5426 - val_loss: 0.5918\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5535 - val_loss: 0.5923\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5380 - val_loss: 0.6314\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5569 - val_loss: 0.6002\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5322 - val_loss: 0.5828\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5442 - val_loss: 0.5853\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5282 - val_loss: 0.6034\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5362 - val_loss: 0.6063\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5394 - val_loss: 0.5978\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5382 - val_loss: 0.6041\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5353 - val_loss: 0.5705\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5372 - val_loss: 0.5830\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5405 - val_loss: 0.5985\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5410 - val_loss: 0.5609\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5436 - val_loss: 0.5940\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5370 - val_loss: 0.5910\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5320 - val_loss: 0.5958\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5392 - val_loss: 0.5998\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5330 - val_loss: 0.6163\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5303 - val_loss: 0.5928\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5395 - val_loss: 0.6058\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5351 - val_loss: 0.5668\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5377 - val_loss: 0.5755\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5258 - val_loss: 0.5996\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5356 - val_loss: 0.5837\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5319 - val_loss: 0.5860\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5374 - val_loss: 0.6124\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5346 - val_loss: 0.6261\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5499 - val_loss: 0.5820\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5314 - val_loss: 0.5927\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5330 - val_loss: 0.6047\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5129 - val_loss: 0.5737\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5277 - val_loss: 0.5719\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5224 - val_loss: 0.5692\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5331 - val_loss: 0.6105\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5411 - val_loss: 0.5903\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5424 - val_loss: 0.5975\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5248 - val_loss: 0.6343\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5313 - val_loss: 0.6347\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5223 - val_loss: 0.5677\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5249 - val_loss: 0.5851\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5282 - val_loss: 0.5684\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5232 - val_loss: 0.5711\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5260 - val_loss: 0.5627\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5166 - val_loss: 0.5614\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5296 - val_loss: 0.5875\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5260 - val_loss: 0.5871\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5188 - val_loss: 0.5684\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5215 - val_loss: 0.5728\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5214 - val_loss: 0.5758\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5240 - val_loss: 0.5768\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5199 - val_loss: 0.5711\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5187 - val_loss: 0.5611\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5157 - val_loss: 0.5706\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 7.2137 - val_loss: 2.7665\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 2.2599 - val_loss: 1.5914\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.3852 - val_loss: 1.4233\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.2240 - val_loss: 1.3177\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 1.1540 - val_loss: 1.2654\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 1.1011 - val_loss: 1.2307\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.0613 - val_loss: 1.1876\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.0363 - val_loss: 1.1368\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.0219 - val_loss: 1.2244\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.9993 - val_loss: 1.0735\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.9675 - val_loss: 1.1002\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.9452 - val_loss: 0.9997\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.9206 - val_loss: 1.0161\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.8978 - val_loss: 0.9944\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.8734 - val_loss: 0.9533\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.8510 - val_loss: 0.9580\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.8446 - val_loss: 0.8959\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8240 - val_loss: 0.9093\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8127 - val_loss: 0.8338\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7800 - val_loss: 0.8500\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.7786 - val_loss: 0.7649\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.7508 - val_loss: 0.8092\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7408 - val_loss: 0.7660\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.7241 - val_loss: 0.7280\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.7219 - val_loss: 0.7183\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.7215 - val_loss: 0.7413\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.7081 - val_loss: 0.6846\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6917 - val_loss: 0.7009\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.7120 - val_loss: 0.7008\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6886 - val_loss: 0.7124\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6941 - val_loss: 0.6664\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6819 - val_loss: 0.6409\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6591 - val_loss: 0.6724\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6691 - val_loss: 0.6926\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6560 - val_loss: 0.6318\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6430 - val_loss: 0.6234\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6488 - val_loss: 0.6768\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6474 - val_loss: 0.6226\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6310 - val_loss: 0.6404\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6369 - val_loss: 0.6215\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6402 - val_loss: 0.6304\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 646us/step - loss: 0.6392 - val_loss: 0.6577\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6241 - val_loss: 0.6427\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6313 - val_loss: 0.6088\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6241 - val_loss: 0.6381\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6241 - val_loss: 0.6135\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6223 - val_loss: 0.6146\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6267 - val_loss: 0.6280\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.6100 - val_loss: 0.6059\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6129 - val_loss: 0.6209\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6233 - val_loss: 0.6413\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.6202 - val_loss: 0.6247\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6071 - val_loss: 0.6232\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6149 - val_loss: 0.6375\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6148 - val_loss: 0.6199\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5985 - val_loss: 0.6057\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6009 - val_loss: 0.6006\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6139 - val_loss: 0.5843\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6075 - val_loss: 0.6187\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6138 - val_loss: 0.5899\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.6044 - val_loss: 0.6136\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5931 - val_loss: 0.5971\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5968 - val_loss: 0.6031\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5980 - val_loss: 0.6413\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5980 - val_loss: 0.6484\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5976 - val_loss: 0.5972\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5911 - val_loss: 0.6161\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5965 - val_loss: 0.5842\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5830 - val_loss: 0.5968\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5871 - val_loss: 0.6042\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6027 - val_loss: 0.5942\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5836 - val_loss: 0.6136\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 665us/step - loss: 0.5947 - val_loss: 0.5979\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5934 - val_loss: 0.5983\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5882 - val_loss: 0.6050\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.6006 - val_loss: 0.5851\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 648us/step - loss: 0.6005 - val_loss: 0.6340\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5872 - val_loss: 0.5973\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5816 - val_loss: 0.6114\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5817 - val_loss: 0.6055\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5754 - val_loss: 0.5630\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 781us/step - loss: 0.5805 - val_loss: 0.5818\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 791us/step - loss: 0.5814 - val_loss: 0.6222\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5843 - val_loss: 0.6009\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5774 - val_loss: 0.5969\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5790 - val_loss: 0.5703\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 644us/step - loss: 0.5802 - val_loss: 0.6030\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5645 - val_loss: 0.5960\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5856 - val_loss: 0.5768\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.5639 - val_loss: 0.5958\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5714 - val_loss: 0.5668\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5745 - val_loss: 0.5665\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5684 - val_loss: 0.6024\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 666us/step - loss: 0.5668 - val_loss: 0.5949\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 674us/step - loss: 0.5718 - val_loss: 0.5705\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5716 - val_loss: 0.5634\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5725 - val_loss: 0.5739\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5661 - val_loss: 0.5519\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5746 - val_loss: 0.5571\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5744 - val_loss: 0.5802\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5747 - val_loss: 0.6057\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5785 - val_loss: 0.5706\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5694 - val_loss: 0.5747\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5632 - val_loss: 0.5633\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5754 - val_loss: 0.5721\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5844 - val_loss: 0.5881\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5708 - val_loss: 0.5467\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5538 - val_loss: 0.5757\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5679 - val_loss: 0.5538\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5636 - val_loss: 0.5685\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5760 - val_loss: 0.5570\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5606 - val_loss: 0.5596\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5504 - val_loss: 0.5500\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5549 - val_loss: 0.5641\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5551 - val_loss: 0.5522\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5634 - val_loss: 0.5849\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5580 - val_loss: 0.5756\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5544 - val_loss: 0.5896\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5534 - val_loss: 0.5610\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5494 - val_loss: 0.5724\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5504 - val_loss: 0.5614\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5580 - val_loss: 0.5607\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5534 - val_loss: 0.5616\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5670 - val_loss: 0.5623\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5461 - val_loss: 0.5593\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5512 - val_loss: 0.5867\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5615 - val_loss: 0.5571\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5646 - val_loss: 0.5459\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5507 - val_loss: 0.5686\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5469 - val_loss: 0.5522\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5408 - val_loss: 0.5517\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5492 - val_loss: 0.5402\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5443 - val_loss: 0.5636\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5643 - val_loss: 0.5812\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5590 - val_loss: 0.5557\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5599 - val_loss: 0.5667\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5561 - val_loss: 0.5729\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5496 - val_loss: 0.5652\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5503 - val_loss: 0.5419\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 565us/step - loss: 0.5348 - val_loss: 0.5485\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5484 - val_loss: 0.5817\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 642us/step - loss: 0.5550 - val_loss: 0.5713\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5488 - val_loss: 0.5472\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5378 - val_loss: 0.5399\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5386 - val_loss: 0.5518\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5390 - val_loss: 0.5712\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5449 - val_loss: 0.5632\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5523 - val_loss: 0.5763\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5461 - val_loss: 0.5674\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5486 - val_loss: 0.5618\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5421 - val_loss: 0.5570\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5460 - val_loss: 0.5515\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5549 - val_loss: 0.5834\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5571 - val_loss: 0.5641\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5656 - val_loss: 0.5539\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5402 - val_loss: 0.5378\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5542 - val_loss: 0.5393\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5407 - val_loss: 0.5690\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5495 - val_loss: 0.5787\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5344 - val_loss: 0.5688\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5387 - val_loss: 0.5391\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5340 - val_loss: 0.5605\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5282 - val_loss: 0.5321\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5363 - val_loss: 0.5411\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5383 - val_loss: 0.5599\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5348 - val_loss: 0.5714\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5426 - val_loss: 0.5853\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5302 - val_loss: 0.5326\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5303 - val_loss: 0.5545\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5340 - val_loss: 0.5574\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5393 - val_loss: 0.5480\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5370 - val_loss: 0.5473\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5404 - val_loss: 0.5318\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5362 - val_loss: 0.5759\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5381 - val_loss: 0.5459\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5359 - val_loss: 0.5556\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5342 - val_loss: 0.5394\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5312 - val_loss: 0.5391\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5328 - val_loss: 0.5427\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5282 - val_loss: 0.5406\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5355 - val_loss: 0.5473\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5398 - val_loss: 0.5510\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5346 - val_loss: 0.5549\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5283 - val_loss: 0.5485\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5256 - val_loss: 0.5447\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5279 - val_loss: 0.5425\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5285 - val_loss: 0.5469\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5346 - val_loss: 0.5473\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5244 - val_loss: 0.5227\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.5343 - val_loss: 0.5912\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5350 - val_loss: 0.5399\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5281 - val_loss: 0.5546\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5373 - val_loss: 0.5430\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5256 - val_loss: 0.5267\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5380 - val_loss: 0.5386\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5304 - val_loss: 0.5338\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5297 - val_loss: 0.5515\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5319 - val_loss: 0.5387\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.5306 - val_loss: 0.5455\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5333 - val_loss: 0.5296\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5212 - val_loss: 0.5412\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5265 - val_loss: 0.5490\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5236 - val_loss: 0.5330\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5195 - val_loss: 0.5516\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5246 - val_loss: 0.5482\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5271 - val_loss: 0.5674\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5323 - val_loss: 0.5364\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5362 - val_loss: 0.5385\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5292 - val_loss: 0.5297\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5250 - val_loss: 0.5375\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5234 - val_loss: 0.5200\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5164 - val_loss: 0.5399\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5306 - val_loss: 0.5315\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5244 - val_loss: 0.5555\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5213 - val_loss: 0.5602\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5297 - val_loss: 0.5533\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5249 - val_loss: 0.5351\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5326 - val_loss: 0.5581\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5223 - val_loss: 0.5346\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5142 - val_loss: 0.5240\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5235 - val_loss: 0.5309\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5174 - val_loss: 0.5354\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5283 - val_loss: 0.5455\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5233 - val_loss: 0.5486\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 907us/step - loss: 0.5158 - val_loss: 0.5376\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5147 - val_loss: 0.5246\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5133 - val_loss: 0.5190\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5250 - val_loss: 0.5607\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5225 - val_loss: 0.5463\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5231 - val_loss: 0.5367\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5228 - val_loss: 0.5384\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5224 - val_loss: 0.5286\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5145 - val_loss: 0.5257\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5215 - val_loss: 0.5430\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5222 - val_loss: 0.5302\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5251 - val_loss: 0.5142\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5156 - val_loss: 0.5411\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5193 - val_loss: 0.5200\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5271 - val_loss: 0.5167\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5139 - val_loss: 0.5412\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5320 - val_loss: 0.5441\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5161 - val_loss: 0.5154\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5086 - val_loss: 0.5215\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5130 - val_loss: 0.5287\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5127 - val_loss: 0.5433\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5097 - val_loss: 0.5247\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5192 - val_loss: 0.5283\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5234 - val_loss: 0.5249\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5132 - val_loss: 0.5284\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5185 - val_loss: 0.5333\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5099 - val_loss: 0.5262\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5082 - val_loss: 0.5210\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5194 - val_loss: 0.5370\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5211 - val_loss: 0.5267\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5121 - val_loss: 0.5337\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5134 - val_loss: 0.5215\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5105 - val_loss: 0.5202\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5195 - val_loss: 0.5257\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5255 - val_loss: 0.5253\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5202 - val_loss: 0.5137\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5131 - val_loss: 0.5291\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5131 - val_loss: 0.5214\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5134 - val_loss: 0.5281\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5092 - val_loss: 0.5224\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5206 - val_loss: 0.5206\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5102 - val_loss: 0.5312\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5110 - val_loss: 0.5376\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5081 - val_loss: 0.5185\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5208 - val_loss: 0.5331\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5158 - val_loss: 0.5228\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5117 - val_loss: 0.5197\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5003 - val_loss: 0.5274\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5099 - val_loss: 0.5230\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5092 - val_loss: 0.5241\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5145 - val_loss: 0.5172\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5209 - val_loss: 0.5197\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5116 - val_loss: 0.5223\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5079 - val_loss: 0.5107\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5040 - val_loss: 0.5171\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5039 - val_loss: 0.5079\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5093 - val_loss: 0.5413\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5124 - val_loss: 0.5314\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5122 - val_loss: 0.5215\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5208 - val_loss: 0.5471\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5099 - val_loss: 0.5340\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5059 - val_loss: 0.5372\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5043 - val_loss: 0.5350\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5052 - val_loss: 0.5155\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5089 - val_loss: 0.5239\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5139 - val_loss: 0.5290\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5085 - val_loss: 0.5219\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5082 - val_loss: 0.5200\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5068 - val_loss: 0.5274\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5097 - val_loss: 0.5080\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5096 - val_loss: 0.5121\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5089 - val_loss: 0.5142\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5072 - val_loss: 0.5324\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5061 - val_loss: 0.5047\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5074 - val_loss: 0.5174\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5052 - val_loss: 0.5207\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5039 - val_loss: 0.5310\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5119 - val_loss: 0.5075\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5102 - val_loss: 0.5516\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5030 - val_loss: 0.5112\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5145 - val_loss: 0.5146\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5111 - val_loss: 0.5087\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5026 - val_loss: 0.5132\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5150 - val_loss: 0.5003\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.4988 - val_loss: 0.5128\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5030 - val_loss: 0.5125\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5084 - val_loss: 0.5046\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5052 - val_loss: 0.5132\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5088 - val_loss: 0.5206\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5049 - val_loss: 0.5134\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5114 - val_loss: 0.5279\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5063 - val_loss: 0.5149\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.4965 - val_loss: 0.5105\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5004 - val_loss: 0.5226\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5009 - val_loss: 0.5168\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5165 - val_loss: 0.5036\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5159 - val_loss: 0.5100\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5029 - val_loss: 0.5063\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5031 - val_loss: 0.5139\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5072 - val_loss: 0.5321\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.4995 - val_loss: 0.5200\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5003 - val_loss: 0.5417\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5016 - val_loss: 0.5346\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5042 - val_loss: 0.5168\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5088 - val_loss: 0.5120\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.4936 - val_loss: 0.4978\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5020 - val_loss: 0.5233\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5088 - val_loss: 0.5215\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5029 - val_loss: 0.5233\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5024 - val_loss: 0.5132\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.4981 - val_loss: 0.5055\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.4987 - val_loss: 0.5216\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5018 - val_loss: 0.5031\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.4992 - val_loss: 0.5218\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.4975 - val_loss: 0.5050\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5022 - val_loss: 0.5088\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.4938 - val_loss: 0.5069\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5016 - val_loss: 0.5185\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.4984 - val_loss: 0.5201\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.4977 - val_loss: 0.5153\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5028 - val_loss: 0.5054\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5005 - val_loss: 0.5338\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5162 - val_loss: 0.5581\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5057 - val_loss: 0.5113\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5042 - val_loss: 0.5197\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5004 - val_loss: 0.5074\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.4941 - val_loss: 0.5202\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.4995 - val_loss: 0.5007\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.4971 - val_loss: 0.5137\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5045 - val_loss: 0.5131\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5049 - val_loss: 0.5130\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.4967 - val_loss: 0.5368\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.4972 - val_loss: 0.5027\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.4963 - val_loss: 0.5017\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.4909 - val_loss: 0.5240\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.4890 - val_loss: 0.4991\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.4993 - val_loss: 0.5056\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.4976 - val_loss: 0.5081\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.4989 - val_loss: 0.5151\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.4933 - val_loss: 0.5136\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5009 - val_loss: 0.4992\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.4970 - val_loss: 0.5195\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.4913 - val_loss: 0.5065\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.4905 - val_loss: 0.5032\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5042 - val_loss: 0.5213\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5005 - val_loss: 0.4996\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 7.0063 - val_loss: 2.5461\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 2.1152 - val_loss: 1.5570\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 1.3914 - val_loss: 1.2519\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.2357 - val_loss: 1.2601\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 1.1683 - val_loss: 1.0362\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.1268 - val_loss: 1.0115\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 1.0877 - val_loss: 1.0778\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 1.0688 - val_loss: 1.0687\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.0455 - val_loss: 0.9694\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 1.0275 - val_loss: 0.9525\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 1.0062 - val_loss: 1.0295\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.9978 - val_loss: 0.9405\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.9778 - val_loss: 0.9091\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.9837 - val_loss: 0.8777\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.9522 - val_loss: 0.9157\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.9404 - val_loss: 0.9249\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.9250 - val_loss: 0.9876\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.8985 - val_loss: 0.8555\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8861 - val_loss: 0.8686\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 673us/step - loss: 0.9095 - val_loss: 0.8399\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.8594 - val_loss: 0.7909\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.8398 - val_loss: 0.8081\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 632us/step - loss: 0.8342 - val_loss: 0.8654\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.8241 - val_loss: 0.7966\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.8225 - val_loss: 0.7621\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.7950 - val_loss: 0.7665\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7724 - val_loss: 0.7468\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7761 - val_loss: 0.7620\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.7536 - val_loss: 0.7221\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.7462 - val_loss: 0.7374\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7244 - val_loss: 0.7737\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.7416 - val_loss: 0.7337\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.7149 - val_loss: 0.7317\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.7210 - val_loss: 0.6931\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7010 - val_loss: 0.7069\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6979 - val_loss: 0.7526\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.7252 - val_loss: 0.6888\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6961 - val_loss: 0.7106\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6913 - val_loss: 0.7337\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6952 - val_loss: 0.6880\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6781 - val_loss: 0.6865\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6848 - val_loss: 0.6833\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6976 - val_loss: 0.7484\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.6920 - val_loss: 0.7037\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6754 - val_loss: 0.7074\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6765 - val_loss: 0.7058\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6709 - val_loss: 0.7018\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6852 - val_loss: 0.6864\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6753 - val_loss: 0.6754\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6777 - val_loss: 0.6725\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6695 - val_loss: 0.6726\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6658 - val_loss: 0.6839\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.6630 - val_loss: 0.7085\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6528 - val_loss: 0.6803\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6581 - val_loss: 0.6819\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6487 - val_loss: 0.6880\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6585 - val_loss: 0.7143\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6618 - val_loss: 0.7400\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6568 - val_loss: 0.7051\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6498 - val_loss: 0.6691\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6459 - val_loss: 0.6760\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6462 - val_loss: 0.6627\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6443 - val_loss: 0.6741\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6386 - val_loss: 0.6750\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6348 - val_loss: 0.6651\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6408 - val_loss: 0.6778\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.6380 - val_loss: 0.6592\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6349 - val_loss: 0.6424\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6413 - val_loss: 0.7039\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6417 - val_loss: 0.6814\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6373 - val_loss: 0.6670\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6336 - val_loss: 0.6704\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6354 - val_loss: 0.6532\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6246 - val_loss: 0.6544\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6293 - val_loss: 0.6859\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6333 - val_loss: 0.6873\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.6375 - val_loss: 0.6812\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6257 - val_loss: 0.6624\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6278 - val_loss: 0.6552\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6201 - val_loss: 0.7007\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6266 - val_loss: 0.6592\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6240 - val_loss: 0.7041\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6360 - val_loss: 0.6591\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6369 - val_loss: 0.6644\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6291 - val_loss: 0.6582\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6304 - val_loss: 0.6409\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6127 - val_loss: 0.6244\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6173 - val_loss: 0.6905\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6168 - val_loss: 0.6660\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6205 - val_loss: 0.6684\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6187 - val_loss: 0.6384\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6166 - val_loss: 0.6787\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6297 - val_loss: 0.6717\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6242 - val_loss: 0.6842\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6093 - val_loss: 0.6521\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6145 - val_loss: 0.6489\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6143 - val_loss: 0.6601\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6201 - val_loss: 0.6317\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6082 - val_loss: 0.6399\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6077 - val_loss: 0.6763\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6129 - val_loss: 0.6310\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6088 - val_loss: 0.6578\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6117 - val_loss: 0.6577\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6149 - val_loss: 0.6443\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6109 - val_loss: 0.6956\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6049 - val_loss: 0.6586\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6106 - val_loss: 0.6444\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6053 - val_loss: 0.6422\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6088 - val_loss: 0.6276\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6025 - val_loss: 0.6300\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6020 - val_loss: 0.6444\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6153 - val_loss: 0.6310\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6057 - val_loss: 0.6545\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5923 - val_loss: 0.6431\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5961 - val_loss: 0.6775\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6041 - val_loss: 0.6424\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5944 - val_loss: 0.6432\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5914 - val_loss: 0.6316\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5961 - val_loss: 0.6740\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6299 - val_loss: 0.6346\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6046 - val_loss: 0.6590\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5992 - val_loss: 0.6450\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5966 - val_loss: 0.6233\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6026 - val_loss: 0.6643\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6176 - val_loss: 0.6207\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5960 - val_loss: 0.6478\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6054 - val_loss: 0.6293\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5929 - val_loss: 0.6167\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6111 - val_loss: 0.6576\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6111 - val_loss: 0.6533\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6061 - val_loss: 0.6598\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5981 - val_loss: 0.6867\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6108 - val_loss: 0.6156\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5846 - val_loss: 0.6075\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5954 - val_loss: 0.6308\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5839 - val_loss: 0.6363\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5937 - val_loss: 0.6282\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6009 - val_loss: 0.6125\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6013 - val_loss: 0.6348\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5912 - val_loss: 0.6299\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5999 - val_loss: 0.6504\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5890 - val_loss: 0.6246\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5907 - val_loss: 0.6456\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5902 - val_loss: 0.6310\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5964 - val_loss: 0.6222\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5879 - val_loss: 0.6805\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5963 - val_loss: 0.6321\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5829 - val_loss: 0.6227\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5915 - val_loss: 0.6380\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6098 - val_loss: 0.6285\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5862 - val_loss: 0.6302\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5841 - val_loss: 0.6655\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5868 - val_loss: 0.6200\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5852 - val_loss: 0.6384\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5838 - val_loss: 0.6319\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5906 - val_loss: 0.6187\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5864 - val_loss: 0.6130\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5924 - val_loss: 0.6203\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5820 - val_loss: 0.6204\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5851 - val_loss: 0.6095\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5821 - val_loss: 0.6278\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5801 - val_loss: 0.6210\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5876 - val_loss: 0.6906\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5821 - val_loss: 0.6225\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5799 - val_loss: 0.6282\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5878 - val_loss: 0.6552\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5816 - val_loss: 0.6187\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5895 - val_loss: 0.6232\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5939 - val_loss: 0.5960\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5802 - val_loss: 0.6106\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5963 - val_loss: 0.6148\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5864 - val_loss: 0.6181\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5800 - val_loss: 0.6184\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5731 - val_loss: 0.6006\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5782 - val_loss: 0.6391\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5842 - val_loss: 0.6419\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5829 - val_loss: 0.6201\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5791 - val_loss: 0.6373\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5866 - val_loss: 0.6137\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5750 - val_loss: 0.6181\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.5755 - val_loss: 0.6209\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5855 - val_loss: 0.5999\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5769 - val_loss: 0.6548\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5725 - val_loss: 0.6311\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5775 - val_loss: 0.6015\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5689 - val_loss: 0.6094\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5746 - val_loss: 0.6635\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5741 - val_loss: 0.6156\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5704 - val_loss: 0.6216\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5870 - val_loss: 0.6144\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5718 - val_loss: 0.6309\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5714 - val_loss: 0.6164\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5801 - val_loss: 0.6034\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5799 - val_loss: 0.6140\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5801 - val_loss: 0.6223\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5874 - val_loss: 0.6152\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5701 - val_loss: 0.6103\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5826 - val_loss: 0.6415\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5683 - val_loss: 0.6113\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5826 - val_loss: 0.6254\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5712 - val_loss: 0.6267\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5699 - val_loss: 0.6260\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5747 - val_loss: 0.6290\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5726 - val_loss: 0.6038\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5794 - val_loss: 0.6028\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5682 - val_loss: 0.5908\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5604 - val_loss: 0.6143\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5847 - val_loss: 0.6346\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5822 - val_loss: 0.6227\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5810 - val_loss: 0.5959\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5618 - val_loss: 0.6041\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5785 - val_loss: 0.6123\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5693 - val_loss: 0.6121\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5734 - val_loss: 0.6111\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5692 - val_loss: 0.6052\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5695 - val_loss: 0.6242\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.5689 - val_loss: 0.6374\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5713 - val_loss: 0.6053\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5595 - val_loss: 0.6015\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5712 - val_loss: 0.6135\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5640 - val_loss: 0.5990\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5764 - val_loss: 0.6044\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5674 - val_loss: 0.6169\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5698 - val_loss: 0.6190\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5733 - val_loss: 0.6043\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5597 - val_loss: 0.6181\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5671 - val_loss: 0.6096\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5652 - val_loss: 0.6072\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5696 - val_loss: 0.6144\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5675 - val_loss: 0.6210\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5697 - val_loss: 0.5901\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5644 - val_loss: 0.5949\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5660 - val_loss: 0.6104\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5655 - val_loss: 0.6019\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5635 - val_loss: 0.6410\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5675 - val_loss: 0.6005\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5684 - val_loss: 0.6140\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5646 - val_loss: 0.6007\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5719 - val_loss: 0.5982\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5622 - val_loss: 0.6153\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5721 - val_loss: 0.6028\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5637 - val_loss: 0.5987\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5546 - val_loss: 0.6035\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5633 - val_loss: 0.6091\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 702us/step - loss: 0.5672 - val_loss: 0.6218\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 676us/step - loss: 0.5682 - val_loss: 0.5891\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5556 - val_loss: 0.6175\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5630 - val_loss: 0.6138\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5572 - val_loss: 0.6430\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5681 - val_loss: 0.6084\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5619 - val_loss: 0.5899\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5709 - val_loss: 0.6371\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5632 - val_loss: 0.5918\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5645 - val_loss: 0.6060\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5640 - val_loss: 0.5941\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5554 - val_loss: 0.6099\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5626 - val_loss: 0.6158\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5635 - val_loss: 0.6068\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5721 - val_loss: 0.6387\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5722 - val_loss: 0.6073\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5662 - val_loss: 0.5962\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5574 - val_loss: 0.6087\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5742 - val_loss: 0.6169\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5620 - val_loss: 0.5932\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5642 - val_loss: 0.6018\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5550 - val_loss: 0.5942\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5576 - val_loss: 0.5811\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5670 - val_loss: 0.6187\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5661 - val_loss: 0.5793\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5573 - val_loss: 0.6119\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5603 - val_loss: 0.6014\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5674 - val_loss: 0.6393\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5565 - val_loss: 0.6008\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5634 - val_loss: 0.6138\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5541 - val_loss: 0.5981\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 563us/step - loss: 0.5655 - val_loss: 0.5979\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5548 - val_loss: 0.6096\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5517 - val_loss: 0.5915\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5559 - val_loss: 0.6085\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5576 - val_loss: 0.6234\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5616 - val_loss: 0.5940\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5530 - val_loss: 0.5964\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5649 - val_loss: 0.5867\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5585 - val_loss: 0.5963\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5584 - val_loss: 0.6265\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5601 - val_loss: 0.6140\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5598 - val_loss: 0.5971\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5588 - val_loss: 0.6089\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5559 - val_loss: 0.5899\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5497 - val_loss: 0.6119\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 571us/step - loss: 0.5485 - val_loss: 0.6240\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5635 - val_loss: 0.6016\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5595 - val_loss: 0.6013\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5649 - val_loss: 0.5934\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5517 - val_loss: 0.5915\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5536 - val_loss: 0.5998\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5573 - val_loss: 0.5829\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5535 - val_loss: 0.6025\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5588 - val_loss: 0.5888\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5612 - val_loss: 0.5917\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5544 - val_loss: 0.6059\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5501 - val_loss: 0.6166\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5616 - val_loss: 0.6001\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5511 - val_loss: 0.6006\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5572 - val_loss: 0.5814\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5590 - val_loss: 0.6062\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5622 - val_loss: 0.6133\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5562 - val_loss: 0.6361\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5598 - val_loss: 0.6117\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 7.9578 - val_loss: 2.6982\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 1.9573 - val_loss: 1.4120\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.3509 - val_loss: 1.2057\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 1.2049 - val_loss: 1.1214\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 1.1406 - val_loss: 1.1632\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 1.0984 - val_loss: 1.0735\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 1.0645 - val_loss: 1.0416\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 1.0224 - val_loss: 1.0030\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.9961 - val_loss: 0.9935\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9763 - val_loss: 0.9757\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.9557 - val_loss: 0.9617\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.9383 - val_loss: 0.9379\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.9297 - val_loss: 0.9510\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.9018 - val_loss: 0.9167\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.9102 - val_loss: 0.8877\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.9031 - val_loss: 0.8718\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.8991 - val_loss: 0.9181\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.8889 - val_loss: 0.9310\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.8520 - val_loss: 0.8641\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.8422 - val_loss: 0.8087\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.8421 - val_loss: 0.8502\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.8304 - val_loss: 0.8393\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.8258 - val_loss: 0.7824\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7956 - val_loss: 0.7751\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.7947 - val_loss: 0.7488\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.7904 - val_loss: 0.7817\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.7758 - val_loss: 0.7566\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.7954 - val_loss: 0.7777\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7554 - val_loss: 0.7463\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.7528 - val_loss: 0.7217\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.7487 - val_loss: 0.7120\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.7372 - val_loss: 0.7979\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.7441 - val_loss: 0.7325\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.7224 - val_loss: 0.7293\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.7218 - val_loss: 0.6873\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.7198 - val_loss: 0.7424\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.7340 - val_loss: 0.7078\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.7343 - val_loss: 0.6706\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.7090 - val_loss: 0.6608\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7016 - val_loss: 0.6634\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.7036 - val_loss: 0.6685\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6944 - val_loss: 0.6577\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6955 - val_loss: 0.6776\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7002 - val_loss: 0.6554\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.7052 - val_loss: 0.6733\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.7158 - val_loss: 0.6634\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.6997 - val_loss: 0.6660\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6818 - val_loss: 0.6530\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6769 - val_loss: 0.6614\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6775 - val_loss: 0.6837\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6739 - val_loss: 0.6475\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6877 - val_loss: 0.6877\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6759 - val_loss: 0.6602\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6858 - val_loss: 0.6689\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6748 - val_loss: 0.6490\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6667 - val_loss: 0.6508\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6670 - val_loss: 0.6613\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6804 - val_loss: 0.6428\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6830 - val_loss: 0.6441\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6577 - val_loss: 0.6577\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 651us/step - loss: 0.6552 - val_loss: 0.6427\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6596 - val_loss: 0.6415\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6497 - val_loss: 0.6633\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6829 - val_loss: 0.6137\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6568 - val_loss: 0.6401\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6546 - val_loss: 0.6503\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6566 - val_loss: 0.6680\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6533 - val_loss: 0.6186\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6392 - val_loss: 0.6716\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.6532 - val_loss: 0.6116\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6464 - val_loss: 0.6387\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6496 - val_loss: 0.6397\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6441 - val_loss: 0.6540\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6380 - val_loss: 0.6141\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6496 - val_loss: 0.6248\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6462 - val_loss: 0.5910\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6409 - val_loss: 0.6516\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6565 - val_loss: 0.6166\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6321 - val_loss: 0.6060\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6494 - val_loss: 0.6461\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 904us/step - loss: 0.6442 - val_loss: 0.6480\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 682us/step - loss: 0.6415 - val_loss: 0.6001\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.6469 - val_loss: 0.6139\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6410 - val_loss: 0.6087\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.6280 - val_loss: 0.6121\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6328 - val_loss: 0.5880\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6253 - val_loss: 0.6418\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6346 - val_loss: 0.5970\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6318 - val_loss: 0.6080\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6295 - val_loss: 0.6052\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.6347 - val_loss: 0.5943\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6360 - val_loss: 0.6235\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6407 - val_loss: 0.6339\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6312 - val_loss: 0.6141\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6512 - val_loss: 0.6395\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.6376 - val_loss: 0.6225\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6196 - val_loss: 0.6478\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6264 - val_loss: 0.6335\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.6275 - val_loss: 0.5998\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6364 - val_loss: 0.6198\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6281 - val_loss: 0.5819\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6161 - val_loss: 0.6128\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6299 - val_loss: 0.5979\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6270 - val_loss: 0.6472\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6361 - val_loss: 0.6141\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6177 - val_loss: 0.5999\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6277 - val_loss: 0.5938\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.6202 - val_loss: 0.6049\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6168 - val_loss: 0.5945\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.6074 - val_loss: 0.6178\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6136 - val_loss: 0.6006\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6149 - val_loss: 0.5875\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6147 - val_loss: 0.6289\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6271 - val_loss: 0.6150\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.6241 - val_loss: 0.5977\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6093 - val_loss: 0.5719\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6186 - val_loss: 0.6002\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6175 - val_loss: 0.6056\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6203 - val_loss: 0.6046\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6247 - val_loss: 0.5906\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6103 - val_loss: 0.5981\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6239 - val_loss: 0.6096\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6107 - val_loss: 0.5921\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6204 - val_loss: 0.5802\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6041 - val_loss: 0.5759\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.6131 - val_loss: 0.5913\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6027 - val_loss: 0.5840\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6143 - val_loss: 0.6068\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6109 - val_loss: 0.5959\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6243 - val_loss: 0.6143\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6091 - val_loss: 0.6155\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6281 - val_loss: 0.5984\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5963 - val_loss: 0.5936\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6065 - val_loss: 0.5728\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6160 - val_loss: 0.5838\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6204 - val_loss: 0.5924\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.6115 - val_loss: 0.5804\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6100 - val_loss: 0.5981\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6079 - val_loss: 0.5626\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6201 - val_loss: 0.6051\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5991 - val_loss: 0.5902\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5984 - val_loss: 0.5776\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6125 - val_loss: 0.5849\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6089 - val_loss: 0.5869\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6058 - val_loss: 0.5842\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5939 - val_loss: 0.5732\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5969 - val_loss: 0.6121\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.6058 - val_loss: 0.5939\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5966 - val_loss: 0.5912\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5988 - val_loss: 0.5958\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6039 - val_loss: 0.5937\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6173 - val_loss: 0.5703\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5960 - val_loss: 0.6014\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5953 - val_loss: 0.5696\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6007 - val_loss: 0.5966\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5986 - val_loss: 0.6222\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6141 - val_loss: 0.5773\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6014 - val_loss: 0.5839\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5905 - val_loss: 0.5669\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5922 - val_loss: 0.5782\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6088 - val_loss: 0.5909\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5920 - val_loss: 0.6018\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5876 - val_loss: 0.5827\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6019 - val_loss: 0.5826\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5962 - val_loss: 0.5685\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5952 - val_loss: 0.6061\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6012 - val_loss: 0.5722\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5943 - val_loss: 0.5821\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5969 - val_loss: 0.5705\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5800 - val_loss: 0.5631\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6125 - val_loss: 0.6139\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6119 - val_loss: 0.5880\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5900 - val_loss: 0.5583\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5938 - val_loss: 0.6381\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5900 - val_loss: 0.5517\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5903 - val_loss: 0.5823\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6051 - val_loss: 0.6190\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6047 - val_loss: 0.5630\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5945 - val_loss: 0.6243\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6200 - val_loss: 0.5575\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5890 - val_loss: 0.5858\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5925 - val_loss: 0.5549\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5898 - val_loss: 0.5745\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 576us/step - loss: 0.5923 - val_loss: 0.5755\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5922 - val_loss: 0.5628\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5926 - val_loss: 0.6020\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5932 - val_loss: 0.5955\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6092 - val_loss: 0.5673\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5887 - val_loss: 0.5782\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5844 - val_loss: 0.5746\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5808 - val_loss: 0.5663\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6008 - val_loss: 0.5558\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5957 - val_loss: 0.5690\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5889 - val_loss: 0.5829\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5839 - val_loss: 0.5730\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6088 - val_loss: 0.5454\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5948 - val_loss: 0.5847\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5862 - val_loss: 0.5570\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5722 - val_loss: 0.5747\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5820 - val_loss: 0.5883\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5785 - val_loss: 0.5756\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5844 - val_loss: 0.6030\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5941 - val_loss: 0.5659\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5937 - val_loss: 0.5698\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6000 - val_loss: 0.5565\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5871 - val_loss: 0.5619\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5921 - val_loss: 0.5798\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5850 - val_loss: 0.5818\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5989 - val_loss: 0.5596\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5804 - val_loss: 0.5549\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5804 - val_loss: 0.6022\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5900 - val_loss: 0.5529\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5933 - val_loss: 0.5472\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5864 - val_loss: 0.5641\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5834 - val_loss: 0.5750\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5912 - val_loss: 0.5604\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5835 - val_loss: 0.5562\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5838 - val_loss: 0.5512\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5868 - val_loss: 0.5848\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5903 - val_loss: 0.5517\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5773 - val_loss: 0.5557\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5946 - val_loss: 0.6104\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5851 - val_loss: 0.5552\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5787 - val_loss: 0.6176\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5927 - val_loss: 0.5528\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5727 - val_loss: 0.5824\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5794 - val_loss: 0.5768\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5873 - val_loss: 0.5509\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6000 - val_loss: 0.5884\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5918 - val_loss: 0.5523\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5785 - val_loss: 0.5506\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5679 - val_loss: 0.5769\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5761 - val_loss: 0.5478\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5864 - val_loss: 0.5611\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5926 - val_loss: 0.5380\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5824 - val_loss: 0.5464\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5800 - val_loss: 0.5452\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5737 - val_loss: 0.5494\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5890 - val_loss: 0.5437\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5756 - val_loss: 0.5500\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5738 - val_loss: 0.5479\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5630 - val_loss: 0.5537\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5766 - val_loss: 0.5516\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5743 - val_loss: 0.5540\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5820 - val_loss: 0.5560\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5766 - val_loss: 0.5777\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5772 - val_loss: 0.5390\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5844 - val_loss: 0.5705\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5662 - val_loss: 0.5431\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5678 - val_loss: 0.5685\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5742 - val_loss: 0.6120\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5833 - val_loss: 0.6014\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5770 - val_loss: 0.5857\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5748 - val_loss: 0.5392\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5751 - val_loss: 0.5479\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5733 - val_loss: 0.5404\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5745 - val_loss: 0.5512\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5787 - val_loss: 0.5463\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5689 - val_loss: 0.5782\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5748 - val_loss: 0.5433\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5675 - val_loss: 0.5447\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5722 - val_loss: 0.5686\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5747 - val_loss: 0.5457\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5736 - val_loss: 0.5904\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5800 - val_loss: 0.5405\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5743 - val_loss: 0.5716\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5810 - val_loss: 0.5750\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5710 - val_loss: 0.5843\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5702 - val_loss: 0.5848\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5722 - val_loss: 0.5350\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5703 - val_loss: 0.5315\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5629 - val_loss: 0.5415\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5696 - val_loss: 0.5724\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5784 - val_loss: 0.5808\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5765 - val_loss: 0.5687\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5676 - val_loss: 0.5484\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5660 - val_loss: 0.5538\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5730 - val_loss: 0.5626\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5814 - val_loss: 0.5378\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5629 - val_loss: 0.5803\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5726 - val_loss: 0.5623\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5635 - val_loss: 0.5443\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5661 - val_loss: 0.5442\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5723 - val_loss: 0.5479\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5800 - val_loss: 0.5361\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5698 - val_loss: 0.5563\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5764 - val_loss: 0.5361\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5614 - val_loss: 0.5428\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5664 - val_loss: 0.5739\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5610 - val_loss: 0.5805\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5716 - val_loss: 0.5710\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5685 - val_loss: 0.5394\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5746 - val_loss: 0.5559\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5685 - val_loss: 0.5437\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5593 - val_loss: 0.5662\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5697 - val_loss: 0.5557\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5688 - val_loss: 0.5497\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5802 - val_loss: 0.5400\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5748 - val_loss: 0.5603\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5682 - val_loss: 0.5311\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5638 - val_loss: 0.5652\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5707 - val_loss: 0.5673\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5622 - val_loss: 0.5393\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5628 - val_loss: 0.5462\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5617 - val_loss: 0.5454\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5697 - val_loss: 0.5546\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5628 - val_loss: 0.5492\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5714 - val_loss: 0.5350\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5572 - val_loss: 0.5460\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5617 - val_loss: 0.5512\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5579 - val_loss: 0.5605\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5614 - val_loss: 0.5432\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5540 - val_loss: 0.5312\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5657 - val_loss: 0.5786\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5646 - val_loss: 0.5530\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5602 - val_loss: 0.5684\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5587 - val_loss: 0.5382\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5626 - val_loss: 0.5524\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5614 - val_loss: 0.5406\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5629 - val_loss: 0.5590\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5547 - val_loss: 0.5614\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5690 - val_loss: 0.5486\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5599 - val_loss: 0.5609\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5576 - val_loss: 0.5511\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5568 - val_loss: 0.5474\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5620 - val_loss: 0.5725\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5686 - val_loss: 0.5440\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5547 - val_loss: 0.5537\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5640 - val_loss: 0.5471\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5651 - val_loss: 0.5411\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5742 - val_loss: 0.5848\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5620 - val_loss: 0.5238\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5614 - val_loss: 0.5523\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5568 - val_loss: 0.5288\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5538 - val_loss: 0.5534\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5596 - val_loss: 0.5453\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5494 - val_loss: 0.5547\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5714 - val_loss: 0.5923\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5694 - val_loss: 0.5441\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5624 - val_loss: 0.5532\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5539 - val_loss: 0.5573\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5737 - val_loss: 0.5571\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5555 - val_loss: 0.5441\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5594 - val_loss: 0.5466\n",
      "Epoch 345/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5553 - val_loss: 0.5537\n",
      "Epoch 346/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5583 - val_loss: 0.5740\n",
      "Epoch 347/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5561 - val_loss: 0.5688\n",
      "Epoch 348/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5588 - val_loss: 0.5295\n",
      "Epoch 349/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5554 - val_loss: 0.5734\n",
      "Epoch 350/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5522 - val_loss: 0.5492\n",
      "Epoch 351/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5547 - val_loss: 0.5559\n",
      "Epoch 352/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5556 - val_loss: 0.6056\n",
      "Epoch 353/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5680 - val_loss: 0.5365\n",
      "Epoch 354/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5563 - val_loss: 0.5522\n",
      "Epoch 355/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5574 - val_loss: 0.5466\n",
      "Epoch 356/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5632 - val_loss: 0.5575\n",
      "Epoch 357/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5633 - val_loss: 0.5553\n",
      "Epoch 358/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5565 - val_loss: 0.5406\n",
      "Epoch 359/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 0.5526 - val_loss: 0.5373\n",
      "Epoch 360/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5683 - val_loss: 0.5424\n",
      "Epoch 361/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5570 - val_loss: 0.5371\n",
      "Epoch 362/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5563 - val_loss: 0.5292\n",
      "Epoch 363/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5539 - val_loss: 0.5303\n",
      "Epoch 364/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5594 - val_loss: 0.5380\n",
      "Epoch 365/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5594 - val_loss: 0.5365\n",
      "Epoch 366/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5573 - val_loss: 0.5341\n",
      "Epoch 367/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5562 - val_loss: 0.5364\n",
      "Epoch 368/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5604 - val_loss: 0.5353\n",
      "Epoch 369/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5518 - val_loss: 0.5413\n",
      "Epoch 370/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5541 - val_loss: 0.5433\n",
      "Epoch 371/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5501 - val_loss: 0.5521\n",
      "Epoch 372/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5591 - val_loss: 0.5329\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 7.7074 - val_loss: 3.0268\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 2.0743 - val_loss: 1.3966\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 1.3221 - val_loss: 1.2624\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 1.1806 - val_loss: 1.1517\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 1.1270 - val_loss: 1.1036\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 1.0885 - val_loss: 1.0655\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 1.0404 - val_loss: 1.0755\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 628us/step - loss: 1.0389 - val_loss: 0.9337\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 1.0013 - val_loss: 0.9431\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.9750 - val_loss: 0.8633\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.9509 - val_loss: 0.9293\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.9358 - val_loss: 0.8500\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.9183 - val_loss: 0.8594\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8959 - val_loss: 0.8185\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.8830 - val_loss: 0.8137\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.8586 - val_loss: 0.7883\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.8568 - val_loss: 0.8712\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.8616 - val_loss: 0.7917\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.8305 - val_loss: 0.7526\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.8219 - val_loss: 0.8003\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.8116 - val_loss: 0.7820\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.8145 - val_loss: 0.8626\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.7887 - val_loss: 0.7432\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.7843 - val_loss: 0.7194\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.7756 - val_loss: 0.7243\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7678 - val_loss: 0.6895\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7636 - val_loss: 0.7720\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7517 - val_loss: 0.6800\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.7383 - val_loss: 0.7742\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.7406 - val_loss: 0.6956\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.7115 - val_loss: 0.6658\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.7127 - val_loss: 0.6526\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 573us/step - loss: 0.7167 - val_loss: 0.7263\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.7014 - val_loss: 0.6910\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.7130 - val_loss: 0.7043\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.7028 - val_loss: 0.6759\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6954 - val_loss: 0.6582\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6949 - val_loss: 0.6626\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6768 - val_loss: 0.7060\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6985 - val_loss: 0.6460\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6881 - val_loss: 0.6699\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6787 - val_loss: 0.6604\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6732 - val_loss: 0.6156\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6854 - val_loss: 0.6515\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6740 - val_loss: 0.6959\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.6799 - val_loss: 0.6564\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.6646 - val_loss: 0.6269\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6507 - val_loss: 0.7258\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6597 - val_loss: 0.6848\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6559 - val_loss: 0.6633\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6534 - val_loss: 0.6287\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6470 - val_loss: 0.6028\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6525 - val_loss: 0.6324\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.6564 - val_loss: 0.5992\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6438 - val_loss: 0.6956\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6464 - val_loss: 0.6764\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.6386 - val_loss: 0.6251\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.6461 - val_loss: 0.6177\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.6385 - val_loss: 0.5912\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6462 - val_loss: 0.6079\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6306 - val_loss: 0.6075\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6264 - val_loss: 0.6026\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6343 - val_loss: 0.6005\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6365 - val_loss: 0.6600\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6484 - val_loss: 0.6043\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.6408 - val_loss: 0.5929\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6226 - val_loss: 0.5721\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6166 - val_loss: 0.6005\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6218 - val_loss: 0.6480\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6339 - val_loss: 0.5998\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6247 - val_loss: 0.5886\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6152 - val_loss: 0.5940\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.6269 - val_loss: 0.5764\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6172 - val_loss: 0.5928\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.6178 - val_loss: 0.6483\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6088 - val_loss: 0.5751\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.6134 - val_loss: 0.6059\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6211 - val_loss: 0.5821\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6039 - val_loss: 0.6116\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6084 - val_loss: 0.6043\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6122 - val_loss: 0.5694\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6043 - val_loss: 0.5752\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6085 - val_loss: 0.6123\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6031 - val_loss: 0.6205\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6214 - val_loss: 0.5705\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.6089 - val_loss: 0.6737\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6137 - val_loss: 0.6062\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6198 - val_loss: 0.6023\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6020 - val_loss: 0.5861\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6090 - val_loss: 0.5893\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6103 - val_loss: 0.6147\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6040 - val_loss: 0.6133\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5927 - val_loss: 0.5616\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5891 - val_loss: 0.5814\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5967 - val_loss: 0.5688\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5943 - val_loss: 0.5980\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.6028 - val_loss: 0.5874\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5924 - val_loss: 0.5743\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5954 - val_loss: 0.6142\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6075 - val_loss: 0.5688\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5881 - val_loss: 0.6044\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5905 - val_loss: 0.6056\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5986 - val_loss: 0.5987\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.6065 - val_loss: 0.5854\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5932 - val_loss: 0.6006\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6032 - val_loss: 0.6159\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5941 - val_loss: 0.5804\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5874 - val_loss: 0.6392\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5886 - val_loss: 0.5717\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5928 - val_loss: 0.5924\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5922 - val_loss: 0.5729\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6096 - val_loss: 0.6154\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5835 - val_loss: 0.5779\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5871 - val_loss: 0.5579\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5784 - val_loss: 0.5544\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5902 - val_loss: 0.6266\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5926 - val_loss: 0.6069\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5894 - val_loss: 0.6312\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5919 - val_loss: 0.6391\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5853 - val_loss: 0.5830\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5836 - val_loss: 0.5697\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5904 - val_loss: 0.6082\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5733 - val_loss: 0.5722\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5806 - val_loss: 0.5826\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5862 - val_loss: 0.5934\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5930 - val_loss: 0.5808\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5796 - val_loss: 0.5674\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5868 - val_loss: 0.5602\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5779 - val_loss: 0.6333\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5806 - val_loss: 0.5758\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5779 - val_loss: 0.5646\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5752 - val_loss: 0.5545\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5855 - val_loss: 0.6012\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5898 - val_loss: 0.6038\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5780 - val_loss: 0.5785\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5763 - val_loss: 0.5557\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5908 - val_loss: 0.5723\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 629us/step - loss: 0.5732 - val_loss: 0.6131\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5730 - val_loss: 0.5291\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5754 - val_loss: 0.5412\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5675 - val_loss: 0.5806\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5795 - val_loss: 0.5707\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5730 - val_loss: 0.5599\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5722 - val_loss: 0.6817\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 645us/step - loss: 0.5810 - val_loss: 0.5796\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5748 - val_loss: 0.5667\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5750 - val_loss: 0.5452\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5619 - val_loss: 0.5636\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5838 - val_loss: 0.5516\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5860 - val_loss: 0.5644\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5876 - val_loss: 0.5844\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5669 - val_loss: 0.5371\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5666 - val_loss: 0.5697\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5635 - val_loss: 0.5797\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5638 - val_loss: 0.5796\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5687 - val_loss: 0.5356\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5693 - val_loss: 0.5930\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5657 - val_loss: 0.6085\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5817 - val_loss: 0.5796\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5667 - val_loss: 0.5328\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5713 - val_loss: 0.5587\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5588 - val_loss: 0.5783\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 568us/step - loss: 0.5582 - val_loss: 0.5462\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5644 - val_loss: 0.5541\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5617 - val_loss: 0.5348\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5706 - val_loss: 0.5506\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5741 - val_loss: 0.5476\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5752 - val_loss: 0.5407\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5574 - val_loss: 0.5411\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5504 - val_loss: 0.5413\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5707 - val_loss: 0.5774\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5575 - val_loss: 0.5461\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5580 - val_loss: 0.5440\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5596 - val_loss: 0.6038\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5695 - val_loss: 0.5367\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5594 - val_loss: 0.5546\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5608 - val_loss: 0.5595\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.5678 - val_loss: 0.5369\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5512 - val_loss: 0.5362\n",
      "Epoch 1/3000\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 6.2785 - val_loss: 2.1730\n",
      "Epoch 2/3000\n",
      "33/33 [==============================] - 0s 652us/step - loss: 1.8613 - val_loss: 1.0749\n",
      "Epoch 3/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.2940 - val_loss: 1.0750\n",
      "Epoch 4/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 1.2016 - val_loss: 0.9790\n",
      "Epoch 5/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 1.1573 - val_loss: 0.9571\n",
      "Epoch 6/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 1.0944 - val_loss: 0.9212\n",
      "Epoch 7/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 1.0580 - val_loss: 0.7907\n",
      "Epoch 8/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 1.0349 - val_loss: 0.7704\n",
      "Epoch 9/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 1.0172 - val_loss: 0.8683\n",
      "Epoch 10/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.9971 - val_loss: 0.7888\n",
      "Epoch 11/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.9763 - val_loss: 0.7857\n",
      "Epoch 12/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.9520 - val_loss: 0.8195\n",
      "Epoch 13/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.9194 - val_loss: 0.7596\n",
      "Epoch 14/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.8933 - val_loss: 0.7641\n",
      "Epoch 15/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.8750 - val_loss: 0.7232\n",
      "Epoch 16/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.8525 - val_loss: 0.6865\n",
      "Epoch 17/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.8504 - val_loss: 0.7112\n",
      "Epoch 18/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.8395 - val_loss: 0.7319\n",
      "Epoch 19/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.8181 - val_loss: 0.7106\n",
      "Epoch 20/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.7990 - val_loss: 0.6626\n",
      "Epoch 21/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.7797 - val_loss: 0.6897\n",
      "Epoch 22/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.7771 - val_loss: 0.6493\n",
      "Epoch 23/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.7670 - val_loss: 0.6504\n",
      "Epoch 24/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.7600 - val_loss: 0.6655\n",
      "Epoch 25/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.7399 - val_loss: 0.6159\n",
      "Epoch 26/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.7373 - val_loss: 0.6231\n",
      "Epoch 27/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.7282 - val_loss: 0.5821\n",
      "Epoch 28/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.7128 - val_loss: 0.6331\n",
      "Epoch 29/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.7091 - val_loss: 0.5904\n",
      "Epoch 30/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.7010 - val_loss: 0.6420\n",
      "Epoch 31/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.7042 - val_loss: 0.6061\n",
      "Epoch 32/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.6977 - val_loss: 0.6546\n",
      "Epoch 33/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.6889 - val_loss: 0.6188\n",
      "Epoch 34/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.6893 - val_loss: 0.5871\n",
      "Epoch 35/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6928 - val_loss: 0.6469\n",
      "Epoch 36/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6770 - val_loss: 0.5831\n",
      "Epoch 37/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6707 - val_loss: 0.6291\n",
      "Epoch 38/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6646 - val_loss: 0.5671\n",
      "Epoch 39/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.6725 - val_loss: 0.5853\n",
      "Epoch 40/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.6684 - val_loss: 0.5914\n",
      "Epoch 41/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.6708 - val_loss: 0.5939\n",
      "Epoch 42/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.6597 - val_loss: 0.5769\n",
      "Epoch 43/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6506 - val_loss: 0.5698\n",
      "Epoch 44/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6648 - val_loss: 0.5762\n",
      "Epoch 45/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6570 - val_loss: 0.5941\n",
      "Epoch 46/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.6467 - val_loss: 0.5899\n",
      "Epoch 47/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6363 - val_loss: 0.5459\n",
      "Epoch 48/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6460 - val_loss: 0.5428\n",
      "Epoch 49/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6496 - val_loss: 0.5805\n",
      "Epoch 50/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.6347 - val_loss: 0.5437\n",
      "Epoch 51/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.6322 - val_loss: 0.5763\n",
      "Epoch 52/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.6475 - val_loss: 0.5733\n",
      "Epoch 53/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6366 - val_loss: 0.5492\n",
      "Epoch 54/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6172 - val_loss: 0.5642\n",
      "Epoch 55/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6328 - val_loss: 0.5366\n",
      "Epoch 56/3000\n",
      "33/33 [==============================] - 0s 570us/step - loss: 0.6293 - val_loss: 0.6130\n",
      "Epoch 57/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.6279 - val_loss: 0.5801\n",
      "Epoch 58/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.6292 - val_loss: 0.5511\n",
      "Epoch 59/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6242 - val_loss: 0.5566\n",
      "Epoch 60/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.6271 - val_loss: 0.5944\n",
      "Epoch 61/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.6486 - val_loss: 0.6090\n",
      "Epoch 62/3000\n",
      "33/33 [==============================] - 0s 569us/step - loss: 0.6437 - val_loss: 0.6134\n",
      "Epoch 63/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.6316 - val_loss: 0.5430\n",
      "Epoch 64/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.6226 - val_loss: 0.5504\n",
      "Epoch 65/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.6113 - val_loss: 0.5685\n",
      "Epoch 66/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.6210 - val_loss: 0.5503\n",
      "Epoch 67/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6178 - val_loss: 0.5399\n",
      "Epoch 68/3000\n",
      "33/33 [==============================] - 0s 633us/step - loss: 0.6086 - val_loss: 0.5372\n",
      "Epoch 69/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6132 - val_loss: 0.5928\n",
      "Epoch 70/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.6141 - val_loss: 0.5696\n",
      "Epoch 71/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.6145 - val_loss: 0.5745\n",
      "Epoch 72/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6270 - val_loss: 0.5663\n",
      "Epoch 73/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.6183 - val_loss: 0.5476\n",
      "Epoch 74/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6410 - val_loss: 0.5323\n",
      "Epoch 75/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.6101 - val_loss: 0.5387\n",
      "Epoch 76/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6124 - val_loss: 0.6113\n",
      "Epoch 77/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.6198 - val_loss: 0.5498\n",
      "Epoch 78/3000\n",
      "33/33 [==============================] - 0s 572us/step - loss: 0.6186 - val_loss: 0.5327\n",
      "Epoch 79/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.6046 - val_loss: 0.5354\n",
      "Epoch 80/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.6044 - val_loss: 0.5310\n",
      "Epoch 81/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5952 - val_loss: 0.5324\n",
      "Epoch 82/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5960 - val_loss: 0.5435\n",
      "Epoch 83/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.6012 - val_loss: 0.5702\n",
      "Epoch 84/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.6108 - val_loss: 0.5687\n",
      "Epoch 85/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6090 - val_loss: 0.5328\n",
      "Epoch 86/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5977 - val_loss: 0.5220\n",
      "Epoch 87/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.6014 - val_loss: 0.5994\n",
      "Epoch 88/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.6004 - val_loss: 0.5692\n",
      "Epoch 89/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.6047 - val_loss: 0.5884\n",
      "Epoch 90/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6034 - val_loss: 0.5524\n",
      "Epoch 91/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5986 - val_loss: 0.5397\n",
      "Epoch 92/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.6004 - val_loss: 0.5379\n",
      "Epoch 93/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5836 - val_loss: 0.5314\n",
      "Epoch 94/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5844 - val_loss: 0.5386\n",
      "Epoch 95/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5914 - val_loss: 0.5239\n",
      "Epoch 96/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5875 - val_loss: 0.5503\n",
      "Epoch 97/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5909 - val_loss: 0.5124\n",
      "Epoch 98/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5850 - val_loss: 0.5195\n",
      "Epoch 99/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.6010 - val_loss: 0.5596\n",
      "Epoch 100/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5933 - val_loss: 0.5276\n",
      "Epoch 101/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5922 - val_loss: 0.5146\n",
      "Epoch 102/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5883 - val_loss: 0.5372\n",
      "Epoch 103/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.6008 - val_loss: 0.5461\n",
      "Epoch 104/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5966 - val_loss: 0.5307\n",
      "Epoch 105/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5960 - val_loss: 0.5481\n",
      "Epoch 106/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5870 - val_loss: 0.5224\n",
      "Epoch 107/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5779 - val_loss: 0.5528\n",
      "Epoch 108/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5886 - val_loss: 0.5192\n",
      "Epoch 109/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5902 - val_loss: 0.5389\n",
      "Epoch 110/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5871 - val_loss: 0.5323\n",
      "Epoch 111/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5980 - val_loss: 0.5557\n",
      "Epoch 112/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.6020 - val_loss: 0.5442\n",
      "Epoch 113/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5830 - val_loss: 0.5343\n",
      "Epoch 114/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5903 - val_loss: 0.5507\n",
      "Epoch 115/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5937 - val_loss: 0.5550\n",
      "Epoch 116/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5883 - val_loss: 0.5027\n",
      "Epoch 117/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5811 - val_loss: 0.5167\n",
      "Epoch 118/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5751 - val_loss: 0.5149\n",
      "Epoch 119/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5843 - val_loss: 0.5129\n",
      "Epoch 120/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5826 - val_loss: 0.5062\n",
      "Epoch 121/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5816 - val_loss: 0.5030\n",
      "Epoch 122/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5822 - val_loss: 0.5540\n",
      "Epoch 123/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5828 - val_loss: 0.5245\n",
      "Epoch 124/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5867 - val_loss: 0.5237\n",
      "Epoch 125/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5858 - val_loss: 0.5780\n",
      "Epoch 126/3000\n",
      "33/33 [==============================] - 0s 627us/step - loss: 0.5878 - val_loss: 0.5331\n",
      "Epoch 127/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5909 - val_loss: 0.5293\n",
      "Epoch 128/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5818 - val_loss: 0.5144\n",
      "Epoch 129/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5794 - val_loss: 0.5535\n",
      "Epoch 130/3000\n",
      "33/33 [==============================] - 0s 639us/step - loss: 0.5751 - val_loss: 0.5236\n",
      "Epoch 131/3000\n",
      "33/33 [==============================] - 0s 952us/step - loss: 0.5788 - val_loss: 0.5013\n",
      "Epoch 132/3000\n",
      "33/33 [==============================] - 0s 647us/step - loss: 0.5678 - val_loss: 0.5410\n",
      "Epoch 133/3000\n",
      "33/33 [==============================] - 0s 662us/step - loss: 0.5803 - val_loss: 0.5256\n",
      "Epoch 134/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5748 - val_loss: 0.5257\n",
      "Epoch 135/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5613 - val_loss: 0.5221\n",
      "Epoch 136/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5702 - val_loss: 0.5013\n",
      "Epoch 137/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5841 - val_loss: 0.5331\n",
      "Epoch 138/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5822 - val_loss: 0.5099\n",
      "Epoch 139/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5665 - val_loss: 0.5143\n",
      "Epoch 140/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5631 - val_loss: 0.5044\n",
      "Epoch 141/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5683 - val_loss: 0.5247\n",
      "Epoch 142/3000\n",
      "33/33 [==============================] - 0s 630us/step - loss: 0.5682 - val_loss: 0.5033\n",
      "Epoch 143/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5696 - val_loss: 0.5023\n",
      "Epoch 144/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5659 - val_loss: 0.5183\n",
      "Epoch 145/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5663 - val_loss: 0.5196\n",
      "Epoch 146/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5805 - val_loss: 0.5236\n",
      "Epoch 147/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5800 - val_loss: 0.5149\n",
      "Epoch 148/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5731 - val_loss: 0.5259\n",
      "Epoch 149/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5756 - val_loss: 0.5227\n",
      "Epoch 150/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5783 - val_loss: 0.5205\n",
      "Epoch 151/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5691 - val_loss: 0.5222\n",
      "Epoch 152/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5769 - val_loss: 0.5260\n",
      "Epoch 153/3000\n",
      "33/33 [==============================] - 0s 637us/step - loss: 0.5638 - val_loss: 0.5191\n",
      "Epoch 154/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5572 - val_loss: 0.5197\n",
      "Epoch 155/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5871 - val_loss: 0.5333\n",
      "Epoch 156/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5707 - val_loss: 0.5166\n",
      "Epoch 157/3000\n",
      "33/33 [==============================] - 0s 634us/step - loss: 0.5703 - val_loss: 0.5002\n",
      "Epoch 158/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5746 - val_loss: 0.5270\n",
      "Epoch 159/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5664 - val_loss: 0.5158\n",
      "Epoch 160/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5657 - val_loss: 0.5339\n",
      "Epoch 161/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5604 - val_loss: 0.5061\n",
      "Epoch 162/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5740 - val_loss: 0.5125\n",
      "Epoch 163/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5725 - val_loss: 0.5321\n",
      "Epoch 164/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5746 - val_loss: 0.5219\n",
      "Epoch 165/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5697 - val_loss: 0.5059\n",
      "Epoch 166/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5573 - val_loss: 0.5086\n",
      "Epoch 167/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5587 - val_loss: 0.5011\n",
      "Epoch 168/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5699 - val_loss: 0.5102\n",
      "Epoch 169/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5656 - val_loss: 0.5125\n",
      "Epoch 170/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5812 - val_loss: 0.5310\n",
      "Epoch 171/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5661 - val_loss: 0.5528\n",
      "Epoch 172/3000\n",
      "33/33 [==============================] - 0s 621us/step - loss: 0.5779 - val_loss: 0.5148\n",
      "Epoch 173/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5638 - val_loss: 0.5043\n",
      "Epoch 174/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5610 - val_loss: 0.5203\n",
      "Epoch 175/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5598 - val_loss: 0.4914\n",
      "Epoch 176/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5704 - val_loss: 0.4920\n",
      "Epoch 177/3000\n",
      "33/33 [==============================] - 0s 579us/step - loss: 0.5678 - val_loss: 0.5074\n",
      "Epoch 178/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5490 - val_loss: 0.4909\n",
      "Epoch 179/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5560 - val_loss: 0.5314\n",
      "Epoch 180/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5588 - val_loss: 0.4979\n",
      "Epoch 181/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5548 - val_loss: 0.4907\n",
      "Epoch 182/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5625 - val_loss: 0.5563\n",
      "Epoch 183/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5746 - val_loss: 0.4949\n",
      "Epoch 184/3000\n",
      "33/33 [==============================] - 0s 657us/step - loss: 0.5553 - val_loss: 0.5080\n",
      "Epoch 185/3000\n",
      "33/33 [==============================] - 0s 640us/step - loss: 0.5587 - val_loss: 0.5026\n",
      "Epoch 186/3000\n",
      "33/33 [==============================] - 0s 638us/step - loss: 0.5591 - val_loss: 0.4876\n",
      "Epoch 187/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5516 - val_loss: 0.4937\n",
      "Epoch 188/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5503 - val_loss: 0.5123\n",
      "Epoch 189/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5709 - val_loss: 0.5125\n",
      "Epoch 190/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5500 - val_loss: 0.5048\n",
      "Epoch 191/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5628 - val_loss: 0.5165\n",
      "Epoch 192/3000\n",
      "33/33 [==============================] - 0s 622us/step - loss: 0.5587 - val_loss: 0.4881\n",
      "Epoch 193/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5521 - val_loss: 0.5102\n",
      "Epoch 194/3000\n",
      "33/33 [==============================] - 0s 650us/step - loss: 0.5521 - val_loss: 0.4986\n",
      "Epoch 195/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5590 - val_loss: 0.4990\n",
      "Epoch 196/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5484 - val_loss: 0.5161\n",
      "Epoch 197/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5556 - val_loss: 0.4886\n",
      "Epoch 198/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5605 - val_loss: 0.4977\n",
      "Epoch 199/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5597 - val_loss: 0.4932\n",
      "Epoch 200/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5571 - val_loss: 0.4989\n",
      "Epoch 201/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5497 - val_loss: 0.5009\n",
      "Epoch 202/3000\n",
      "33/33 [==============================] - 0s 618us/step - loss: 0.5576 - val_loss: 0.4887\n",
      "Epoch 203/3000\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.5464 - val_loss: 0.5259\n",
      "Epoch 204/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5646 - val_loss: 0.4884\n",
      "Epoch 205/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5595 - val_loss: 0.5073\n",
      "Epoch 206/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5615 - val_loss: 0.5214\n",
      "Epoch 207/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5554 - val_loss: 0.5003\n",
      "Epoch 208/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5532 - val_loss: 0.4876\n",
      "Epoch 209/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5548 - val_loss: 0.4947\n",
      "Epoch 210/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5485 - val_loss: 0.5108\n",
      "Epoch 211/3000\n",
      "33/33 [==============================] - 0s 626us/step - loss: 0.5522 - val_loss: 0.5074\n",
      "Epoch 212/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5460 - val_loss: 0.4998\n",
      "Epoch 213/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5454 - val_loss: 0.4928\n",
      "Epoch 214/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5507 - val_loss: 0.5036\n",
      "Epoch 215/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5570 - val_loss: 0.4958\n",
      "Epoch 216/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5493 - val_loss: 0.5166\n",
      "Epoch 217/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5516 - val_loss: 0.4824\n",
      "Epoch 218/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5515 - val_loss: 0.4973\n",
      "Epoch 219/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5442 - val_loss: 0.5023\n",
      "Epoch 220/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5407 - val_loss: 0.4760\n",
      "Epoch 221/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5493 - val_loss: 0.4944\n",
      "Epoch 222/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5493 - val_loss: 0.4895\n",
      "Epoch 223/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5440 - val_loss: 0.4963\n",
      "Epoch 224/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5504 - val_loss: 0.5018\n",
      "Epoch 225/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5568 - val_loss: 0.4920\n",
      "Epoch 226/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5471 - val_loss: 0.5243\n",
      "Epoch 227/3000\n",
      "33/33 [==============================] - 0s 635us/step - loss: 0.5577 - val_loss: 0.4841\n",
      "Epoch 228/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5387 - val_loss: 0.4923\n",
      "Epoch 229/3000\n",
      "33/33 [==============================] - 0s 624us/step - loss: 0.5539 - val_loss: 0.4866\n",
      "Epoch 230/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5418 - val_loss: 0.4813\n",
      "Epoch 231/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5469 - val_loss: 0.4836\n",
      "Epoch 232/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5538 - val_loss: 0.4758\n",
      "Epoch 233/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5487 - val_loss: 0.5061\n",
      "Epoch 234/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5543 - val_loss: 0.5154\n",
      "Epoch 235/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5519 - val_loss: 0.4949\n",
      "Epoch 236/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5544 - val_loss: 0.5189\n",
      "Epoch 237/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5438 - val_loss: 0.4980\n",
      "Epoch 238/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5481 - val_loss: 0.4945\n",
      "Epoch 239/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5442 - val_loss: 0.4906\n",
      "Epoch 240/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5483 - val_loss: 0.4926\n",
      "Epoch 241/3000\n",
      "33/33 [==============================] - 0s 631us/step - loss: 0.5434 - val_loss: 0.4979\n",
      "Epoch 242/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5465 - val_loss: 0.5029\n",
      "Epoch 243/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5465 - val_loss: 0.4937\n",
      "Epoch 244/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5364 - val_loss: 0.4923\n",
      "Epoch 245/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5465 - val_loss: 0.5014\n",
      "Epoch 246/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5449 - val_loss: 0.5077\n",
      "Epoch 247/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5401 - val_loss: 0.4945\n",
      "Epoch 248/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5455 - val_loss: 0.5005\n",
      "Epoch 249/3000\n",
      "33/33 [==============================] - 0s 623us/step - loss: 0.5359 - val_loss: 0.4733\n",
      "Epoch 250/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5406 - val_loss: 0.4994\n",
      "Epoch 251/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5531 - val_loss: 0.4955\n",
      "Epoch 252/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5381 - val_loss: 0.4940\n",
      "Epoch 253/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5470 - val_loss: 0.4791\n",
      "Epoch 254/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5418 - val_loss: 0.4889\n",
      "Epoch 255/3000\n",
      "33/33 [==============================] - 0s 589us/step - loss: 0.5499 - val_loss: 0.5020\n",
      "Epoch 256/3000\n",
      "33/33 [==============================] - 0s 607us/step - loss: 0.5493 - val_loss: 0.4991\n",
      "Epoch 257/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5453 - val_loss: 0.4776\n",
      "Epoch 258/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5313 - val_loss: 0.4924\n",
      "Epoch 259/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5418 - val_loss: 0.4934\n",
      "Epoch 260/3000\n",
      "33/33 [==============================] - 0s 590us/step - loss: 0.5360 - val_loss: 0.4796\n",
      "Epoch 261/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5395 - val_loss: 0.4678\n",
      "Epoch 262/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5365 - val_loss: 0.4838\n",
      "Epoch 263/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5450 - val_loss: 0.5405\n",
      "Epoch 264/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5536 - val_loss: 0.4972\n",
      "Epoch 265/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5523 - val_loss: 0.4976\n",
      "Epoch 266/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5421 - val_loss: 0.5181\n",
      "Epoch 267/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5368 - val_loss: 0.4739\n",
      "Epoch 268/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5378 - val_loss: 0.4864\n",
      "Epoch 269/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5360 - val_loss: 0.4861\n",
      "Epoch 270/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5315 - val_loss: 0.4961\n",
      "Epoch 271/3000\n",
      "33/33 [==============================] - 0s 581us/step - loss: 0.5512 - val_loss: 0.4808\n",
      "Epoch 272/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5447 - val_loss: 0.5073\n",
      "Epoch 273/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5735 - val_loss: 0.5417\n",
      "Epoch 274/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5525 - val_loss: 0.4875\n",
      "Epoch 275/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5327 - val_loss: 0.4818\n",
      "Epoch 276/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5397 - val_loss: 0.4724\n",
      "Epoch 277/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5361 - val_loss: 0.4903\n",
      "Epoch 278/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5342 - val_loss: 0.4666\n",
      "Epoch 279/3000\n",
      "33/33 [==============================] - 0s 585us/step - loss: 0.5306 - val_loss: 0.4899\n",
      "Epoch 280/3000\n",
      "33/33 [==============================] - 0s 611us/step - loss: 0.5499 - val_loss: 0.4815\n",
      "Epoch 281/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5426 - val_loss: 0.4858\n",
      "Epoch 282/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5380 - val_loss: 0.4947\n",
      "Epoch 283/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5345 - val_loss: 0.4777\n",
      "Epoch 284/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5373 - val_loss: 0.4873\n",
      "Epoch 285/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5281 - val_loss: 0.4719\n",
      "Epoch 286/3000\n",
      "33/33 [==============================] - 0s 580us/step - loss: 0.5444 - val_loss: 0.4952\n",
      "Epoch 287/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5369 - val_loss: 0.4977\n",
      "Epoch 288/3000\n",
      "33/33 [==============================] - 0s 625us/step - loss: 0.5364 - val_loss: 0.4873\n",
      "Epoch 289/3000\n",
      "33/33 [==============================] - 0s 586us/step - loss: 0.5386 - val_loss: 0.4835\n",
      "Epoch 290/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5289 - val_loss: 0.4855\n",
      "Epoch 291/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5400 - val_loss: 0.4788\n",
      "Epoch 292/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5281 - val_loss: 0.4854\n",
      "Epoch 293/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5352 - val_loss: 0.4866\n",
      "Epoch 294/3000\n",
      "33/33 [==============================] - 0s 617us/step - loss: 0.5277 - val_loss: 0.4893\n",
      "Epoch 295/3000\n",
      "33/33 [==============================] - 0s 612us/step - loss: 0.5312 - val_loss: 0.4933\n",
      "Epoch 296/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5428 - val_loss: 0.4781\n",
      "Epoch 297/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5303 - val_loss: 0.4939\n",
      "Epoch 298/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5340 - val_loss: 0.4871\n",
      "Epoch 299/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5332 - val_loss: 0.4951\n",
      "Epoch 300/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5263 - val_loss: 0.4681\n",
      "Epoch 301/3000\n",
      "33/33 [==============================] - 0s 620us/step - loss: 0.5260 - val_loss: 0.4928\n",
      "Epoch 302/3000\n",
      "33/33 [==============================] - 0s 577us/step - loss: 0.5368 - val_loss: 0.4913\n",
      "Epoch 303/3000\n",
      "33/33 [==============================] - 0s 578us/step - loss: 0.5314 - val_loss: 0.4778\n",
      "Epoch 304/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5430 - val_loss: 0.4636\n",
      "Epoch 305/3000\n",
      "33/33 [==============================] - 0s 595us/step - loss: 0.5276 - val_loss: 0.4848\n",
      "Epoch 306/3000\n",
      "33/33 [==============================] - 0s 619us/step - loss: 0.5250 - val_loss: 0.5007\n",
      "Epoch 307/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5366 - val_loss: 0.4791\n",
      "Epoch 308/3000\n",
      "33/33 [==============================] - 0s 613us/step - loss: 0.5333 - val_loss: 0.4935\n",
      "Epoch 309/3000\n",
      "33/33 [==============================] - 0s 598us/step - loss: 0.5318 - val_loss: 0.4647\n",
      "Epoch 310/3000\n",
      "33/33 [==============================] - 0s 609us/step - loss: 0.5277 - val_loss: 0.4725\n",
      "Epoch 311/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5292 - val_loss: 0.4744\n",
      "Epoch 312/3000\n",
      "33/33 [==============================] - 0s 616us/step - loss: 0.5251 - val_loss: 0.4950\n",
      "Epoch 313/3000\n",
      "33/33 [==============================] - 0s 588us/step - loss: 0.5258 - val_loss: 0.4674\n",
      "Epoch 314/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5311 - val_loss: 0.4717\n",
      "Epoch 315/3000\n",
      "33/33 [==============================] - 0s 614us/step - loss: 0.5419 - val_loss: 0.4932\n",
      "Epoch 316/3000\n",
      "33/33 [==============================] - 0s 591us/step - loss: 0.5272 - val_loss: 0.4873\n",
      "Epoch 317/3000\n",
      "33/33 [==============================] - 0s 567us/step - loss: 0.5305 - val_loss: 0.4720\n",
      "Epoch 318/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5401 - val_loss: 0.4665\n",
      "Epoch 319/3000\n",
      "33/33 [==============================] - 0s 596us/step - loss: 0.5307 - val_loss: 0.5093\n",
      "Epoch 320/3000\n",
      "33/33 [==============================] - 0s 603us/step - loss: 0.5296 - val_loss: 0.4651\n",
      "Epoch 321/3000\n",
      "33/33 [==============================] - 0s 606us/step - loss: 0.5263 - val_loss: 0.4695\n",
      "Epoch 322/3000\n",
      "33/33 [==============================] - 0s 604us/step - loss: 0.5302 - val_loss: 0.4842\n",
      "Epoch 323/3000\n",
      "33/33 [==============================] - 0s 599us/step - loss: 0.5245 - val_loss: 0.4714\n",
      "Epoch 324/3000\n",
      "33/33 [==============================] - 0s 592us/step - loss: 0.5257 - val_loss: 0.5122\n",
      "Epoch 325/3000\n",
      "33/33 [==============================] - 0s 583us/step - loss: 0.5367 - val_loss: 0.4918\n",
      "Epoch 326/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5262 - val_loss: 0.5067\n",
      "Epoch 327/3000\n",
      "33/33 [==============================] - 0s 597us/step - loss: 0.5399 - val_loss: 0.5105\n",
      "Epoch 328/3000\n",
      "33/33 [==============================] - 0s 602us/step - loss: 0.5230 - val_loss: 0.4730\n",
      "Epoch 329/3000\n",
      "33/33 [==============================] - 0s 600us/step - loss: 0.5278 - val_loss: 0.5090\n",
      "Epoch 330/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5361 - val_loss: 0.4693\n",
      "Epoch 331/3000\n",
      "33/33 [==============================] - 0s 601us/step - loss: 0.5341 - val_loss: 0.4851\n",
      "Epoch 332/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5261 - val_loss: 0.4970\n",
      "Epoch 333/3000\n",
      "33/33 [==============================] - 0s 584us/step - loss: 0.5308 - val_loss: 0.4763\n",
      "Epoch 334/3000\n",
      "33/33 [==============================] - 0s 615us/step - loss: 0.5242 - val_loss: 0.4728\n",
      "Epoch 335/3000\n",
      "33/33 [==============================] - 0s 593us/step - loss: 0.5345 - val_loss: 0.5027\n",
      "Epoch 336/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5378 - val_loss: 0.4716\n",
      "Epoch 337/3000\n",
      "33/33 [==============================] - 0s 587us/step - loss: 0.5224 - val_loss: 0.4821\n",
      "Epoch 338/3000\n",
      "33/33 [==============================] - 0s 610us/step - loss: 0.5311 - val_loss: 0.4667\n",
      "Epoch 339/3000\n",
      "33/33 [==============================] - 0s 608us/step - loss: 0.5228 - val_loss: 0.4873\n",
      "Epoch 340/3000\n",
      "33/33 [==============================] - 0s 574us/step - loss: 0.5216 - val_loss: 0.4950\n",
      "Epoch 341/3000\n",
      "33/33 [==============================] - 0s 582us/step - loss: 0.5433 - val_loss: 0.5233\n",
      "Epoch 342/3000\n",
      "33/33 [==============================] - 0s 575us/step - loss: 0.5380 - val_loss: 0.5076\n",
      "Epoch 343/3000\n",
      "33/33 [==============================] - 0s 605us/step - loss: 0.5330 - val_loss: 0.4827\n",
      "Epoch 344/3000\n",
      "33/33 [==============================] - 0s 594us/step - loss: 0.5261 - val_loss: 0.4748\n",
      "Training of wind_speed model is finished.\n"
     ]
    }
   ],
   "source": [
    "# Rolling window\n",
    "for window_start in range(0, total_windows * step_size, step_size):\n",
    "    train_end = window_start + window_size\n",
    "    if train_end > len(X_train):\n",
    "        break\n",
    "\n",
    "    # Split the dataset for this window\n",
    "    X_train_window, y_train_window = X_train[window_start:train_end], y_train[window_start:train_end]\n",
    "\n",
    "    # Build the model\n",
    "    model = build_model(X_train_window.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True, mode='min')\n",
    "    # Fit the model\n",
    "    model.fit(X_train_window, y_train_window, batch_size=10, epochs=3000, verbose=1, validation_split=0.1,\n",
    "              callbacks=[early_stopping])\n",
    "print(f\"Training of {variable} model is finished.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T16:22:59.800257Z",
     "start_time": "2024-07-06T16:19:31.604859Z"
    }
   },
   "id": "3b3817fbe444c401"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# model.save(f'ANNs/{variable}')\n",
    "model = tf.keras.models.load_model(f'ANNs/{variable}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:51:42.256751Z",
     "start_time": "2024-09-02T12:51:42.195006Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performance of the model with test dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "202b872b83d5f2f7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 351us/step\n"
     ]
    }
   ],
   "source": [
    "prediction_test = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:51:43.359314Z",
     "start_time": "2024-09-02T12:51:43.295990Z"
    }
   },
   "id": "57f73d515e31a39d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.6964\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, prediction_test)\n",
    "print(f'R-squared: {r2:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:51:44.821649Z",
     "start_time": "2024-09-02T12:51:44.812171Z"
    }
   },
   "id": "f4bf8aac79710c9f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test.reshape(-1), prediction_test.reshape(-1))\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T12:51:45.923916Z",
     "start_time": "2024-09-02T12:51:45.794839Z"
    }
   },
   "id": "df312eed58a7d119"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "daily_temp_pred = np.mean(prediction_test, axis=1)\n",
    "\n",
    "stats_predicted = {\n",
    "    'mean': daily_temp_pred.mean(),\n",
    "    'std': daily_temp_pred.std(),\n",
    "    'skewness': skew(daily_temp_pred)\n",
    "}\n",
    "\n",
    "stats_real = {\n",
    "    'mean': y_test.mean(axis=1).mean(),\n",
    "    'std': y_test.mean(axis=1).std(),\n",
    "    'skewness': skew(y_test.mean(axis=1))\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T13:03:58.959723Z",
     "start_time": "2024-09-02T13:03:58.917741Z"
    }
   },
   "id": "ef5f52eb68e01819"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Real Daily Means Plot\n",
    "axes[0].hist(y_test.mean(axis=1), color='skyblue', edgecolor='black', alpha=0.7, bins=10)\n",
    "axes[0].tick_params(axis='y', labelsize=14)\n",
    "axes[0].tick_params(axis='x', labelsize=14)\n",
    "axes[0].axvline(stats_real['mean'], color='black', linestyle='dashed', linewidth=2, label=f\"Mean: {stats_real['mean']:.2f}\")\n",
    "axes[0].axvline(stats_real['std'], color='orange', linestyle='dashed', linewidth=2, label=f\"STD: {stats_real['std']:.2f}\")\n",
    "# axes[0].axvline(stats_real['mean'] + stats_real['std'], color='orange', linestyle='dashed', linewidth=2, label=f\"+1 STD: {stats_real['mean'] + stats_real['std']:.2f}\")\n",
    "axes[0].axvline(stats_real['skewness'], color='green', linestyle='dashed', linewidth=2, label=f\"Skewness: {stats_real['skewness']:.2f}\")\n",
    "axes[0].set_title('Expected Daily Distribution of Avg. Temperature',fontsize=14)\n",
    "axes[0].set_xlabel('Value [$\\degree C$ ]',fontsize=14)\n",
    "axes[0].set_ylabel('Frequency',fontsize=14)\n",
    "axes[0].legend(fontsize=14)\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Predicted Daily Means Plot\n",
    "axes[1].hist(daily_temp_pred, color='red', edgecolor='black', alpha=0.7, bins=10)\n",
    "axes[1].tick_params(axis='y', labelsize=14)\n",
    "axes[1].tick_params(axis='x', labelsize=14)\n",
    "axes[1].axvline(stats_predicted['mean'], color='black', linestyle='dashed', linewidth=2, label=f\"Mean: {stats_predicted['mean']:.2f}\")\n",
    "axes[1].axvline(stats_predicted['std'], color='orange', linestyle='dashed', linewidth=2, label=f\"STD: {stats_predicted['std']:.2f}\")\n",
    "# axes[1].axvline(stats_predicted['mean'] + stats_predicted['std'], color='orange', linestyle='dashed', linewidth=2, label=f\"+1 STD: {stats_predicted['mean'] + stats_predicted['std']:.2f}\")\n",
    "axes[1].axvline(stats_predicted['skewness'], color='green', linestyle='dashed', linewidth=2, label=f\"Skewness: {stats_predicted['skewness']:.2f}\")\n",
    "axes[1].set_title('Computed Daily Distribution of Avg. Temperature',fontsize=14)\n",
    "axes[1].set_xlabel('Value [$\\degree C$ ]',fontsize=14)\n",
    "axes[1].set_ylabel('Frequency',fontsize=14)\n",
    "axes[1].legend(fontsize=14)\n",
    "axes[1].grid(True)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/Users/roozbeh/Downloads/temp_stat2028.pdf\", format='pdf',bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T13:04:02.811034Z",
     "start_time": "2024-09-02T13:04:02.239154Z"
    }
   },
   "id": "12cc1faef02c42dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "469bed0d133db7b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
